{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7876159,"sourceType":"datasetVersion","datasetId":1640734}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n\n!pip install /kaggle/input/pytorch-geometric-packages/torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl\n!pip install /kaggle/input/pytorch-geometric-packages/torch_sparse-0.6.18-cp310-cp310-linux_x86_64.whl\n!pip install torch-geometric\n!pip install ogb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-07T16:03:08.285648Z","iopub.execute_input":"2024-09-07T16:03:08.286619Z","iopub.status.idle":"2024-09-07T16:03:40.638238Z","shell.execute_reply.started":"2024-09-07T16:03:08.286564Z","shell.execute_reply":"2024-09-07T16:03:40.636978Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, GINEConv, global_mean_pool\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import QM9\nfrom torch_geometric.transforms import NormalizeFeatures\nimport torch_geometric\nfrom ogb.nodeproppred import PygNodePropPredDataset, Evaluator\nimport torch_geometric.transforms as T\nfrom torch.nn import (\n    BatchNorm1d,\n    Embedding,\n    Linear,\n    ModuleList,\n    ReLU,\n    Sequential,\n)\nfrom typing import Any, Dict, Optional","metadata":{"execution":{"iopub.status.busy":"2024-09-07T16:03:40.640307Z","iopub.execute_input":"2024-09-07T16:03:40.640650Z","iopub.status.idle":"2024-09-07T16:03:46.667871Z","shell.execute_reply.started":"2024-09-07T16:03:40.640614Z","shell.execute_reply":"2024-09-07T16:03:46.666617Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# The following based on the official example of GPSConv: \nhttps://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_gps.py#L34","metadata":{}},{"cell_type":"code","source":"class RedrawProjection:\n    def __init__(self, model: torch.nn.Module,\n                 redraw_interval: Optional[int] = None):\n        self.model = model\n        self.redraw_interval = redraw_interval\n        self.num_last_redraw = 0\n\n    def redraw_projections(self):\n        if not self.model.training or self.redraw_interval is None:\n            return\n        if self.num_last_redraw >= self.redraw_interval:\n            fast_attentions = [\n                module for module in self.model.modules()\n                if isinstance(module, PerformerAttention)\n            ]\n            for fast_attention in fast_attentions:\n                fast_attention.redraw_projection_matrix()\n            self.num_last_redraw = 0\n            return\n        self.num_last_redraw += 1","metadata":{"execution":{"iopub.status.busy":"2024-09-07T16:03:46.669217Z","iopub.execute_input":"2024-09-07T16:03:46.669679Z","iopub.status.idle":"2024-09-07T16:03:46.677603Z","shell.execute_reply.started":"2024-09-07T16:03:46.669644Z","shell.execute_reply":"2024-09-07T16:03:46.676385Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import BatchNorm, GPSConv\n\nclass GPS(torch.nn.Module):\n    def __init__(self, channels: int, pe_dim: int, num_layers: int,\n                 attn_type: str, attn_kwargs: Dict[str, Any]):\n        super().__init__()\n\n        self.node_emb = Embedding(28, channels - pe_dim)\n        self.pe_lin = Linear(3, pe_dim)\n        self.pe_norm = BatchNorm1d(3)\n        self.edge_emb = Embedding(4, channels)\n\n        self.convs = ModuleList()\n        for _ in range(num_layers):\n            nn = Sequential(\n                Linear(channels, channels),\n                ReLU(),\n                Linear(channels, channels),\n            )\n            conv = GPSConv(channels, GINEConv(nn), heads=4,\n                           attn_type=attn_type, attn_kwargs=attn_kwargs)\n            self.convs.append(conv)\n\n        self.mlp = Sequential(\n            Linear(channels, channels // 2),\n            ReLU(),\n            Linear(channels // 2, channels // 4),\n            ReLU(),\n            Linear(channels // 4, 1),\n        )\n        self.redraw_projection = RedrawProjection(\n            self.convs,\n            redraw_interval=1000 if attn_type == 'performer' else None)\n\n    def forward(self, x, pe, edge_index, edge_attr, batch):\n        x_pe = self.pe_norm(pe)\n        # Convert node features to Long tensor for embedding lookup\n        x = x.squeeze(-1).long()  # Ensure x is treated as indices\n        x = torch.cat((self.node_emb(x), self.pe_lin(x_pe)), 1)\n        edge_attr = self.edge_emb(edge_attr)\n\n        for conv in self.convs:\n            x = conv(x, edge_index, batch, edge_attr=edge_attr)\n        x = global_add_pool(x, batch)\n        return self.mlp(x)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-07T16:03:46.680772Z","iopub.execute_input":"2024-09-07T16:03:46.681094Z","iopub.status.idle":"2024-09-07T16:03:46.693931Z","shell.execute_reply.started":"2024-09-07T16:03:46.681063Z","shell.execute_reply":"2024-09-07T16:03:46.692216Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"dataset_name = 'ogbn-arxiv'\n# transform = T.AddRandomWalkPE(walk_length=20, attr_name='pe')\ntransform = T.AddRandomWalkPE(walk_length=3, attr_name='pe')\n\ndataset = PygNodePropPredDataset(name=dataset_name,\n                                 transform=transform)\n# dataset = PygNodePropPredDataset(name=dataset_name,\n#                                  transform=T.ToSparseTensor())\n\ndata = dataset[0]\n\n# Make the adjacency matrix to symmetric\n# data.adj_t = data.adj_t.to_symmetric()\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# If you use GPU, the device should be cuda\nprint('Device: {}'.format(device))\n\ndata = data.to(device)\nsplit_idx = dataset.get_idx_split()\ntrain_idx = split_idx['train'].to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T16:03:46.695334Z","iopub.execute_input":"2024-09-07T16:03:46.695676Z","iopub.status.idle":"2024-09-07T16:04:05.706674Z","shell.execute_reply.started":"2024-09-07T16:03:46.695635Z","shell.execute_reply":"2024-09-07T16:04:05.705752Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n","output_type":"stream"},{"name":"stderr","text":"Downloaded 0.08 GB: 100%|██████████| 81/81 [00:09<00:00,  8.37it/s]\nProcessing...\n","output_type":"stream"},{"name":"stdout","text":"Extracting dataset/arxiv.zip\nLoading necessary files...\nThis might take a while.\nProcessing graphs...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 8176.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Converting graphs into PyG objects...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 304.13it/s]","output_type":"stream"},{"name":"stdout","text":"Saving...\n","output_type":"stream"},{"name":"stderr","text":"\nDone!\n/opt/conda/lib/python3.10/site-packages/ogb/nodeproppred/dataset_pyg.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.data, self.slices = torch.load(self.processed_paths[0])\n/opt/conda/lib/python3.10/site-packages/torch_geometric/utils/sparse.py:268: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n  adj = torch.sparse_csr_tensor(\n","output_type":"stream"},{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"def train(model, data, train_idx, optimizer, loss_fn):\n    model.train()\n    loss = 0\n\n    optimizer.zero_grad()\n    model.redraw_projection.redraw_projections()\n    out = model(data.x, data.pe, data.edge_index, data.edge_attr,\n                    data.batch)\n    loss = loss_fn(out[train_idx], data.y[train_idx].squeeze(1))\n    #########################################\n\n    loss.backward()\n    optimizer.step()\n\n    return loss.item()","metadata":{"execution":{"iopub.status.busy":"2024-09-07T16:04:05.707918Z","iopub.execute_input":"2024-09-07T16:04:05.708230Z","iopub.status.idle":"2024-09-07T16:04:05.714146Z","shell.execute_reply.started":"2024-09-07T16:04:05.708197Z","shell.execute_reply":"2024-09-07T16:04:05.713215Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Test function here\n@torch.no_grad()\ndef test(model, data, split_idx, evaluator, save_model_results=False):\n    # TODO: Implement a function that tests the model by\n    # using the given split_idx and evaluator.\n    model.eval()\n\n    # The output of model on all data\n    out = None\n    out = model(data.x, data.pe, data.edge_index, data.edge_attr,\n                    data.batch)\n\n    y_pred = out.argmax(dim=-1, keepdim=True)\n\n    train_acc = evaluator.eval({\n        'y_true': data.y[split_idx['train']],\n        'y_pred': y_pred[split_idx['train']],\n    })['acc']\n    valid_acc = evaluator.eval({\n        'y_true': data.y[split_idx['valid']],\n        'y_pred': y_pred[split_idx['valid']],\n    })['acc']\n    test_acc = evaluator.eval({\n        'y_true': data.y[split_idx['test']],\n        'y_pred': y_pred[split_idx['test']],\n    })['acc']\n\n    if save_model_results:\n      print (\"Saving Model Predictions\")\n\n      data = {}\n      data['y_pred'] = y_pred.view(-1).cpu().detach().numpy()\n\n      df = pd.DataFrame(data=data)\n      # Save locally as csv\n      df.to_csv('ogbn-arxiv_node.csv', sep=',', index=False)\n\n\n    return train_acc, valid_acc, test_acc","metadata":{"execution":{"iopub.status.busy":"2024-09-07T16:04:05.715271Z","iopub.execute_input":"2024-09-07T16:04:05.715578Z","iopub.status.idle":"2024-09-07T16:04:05.726668Z","shell.execute_reply.started":"2024-09-07T16:04:05.715547Z","shell.execute_reply":"2024-09-07T16:04:05.725839Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Please do not change the args\n\nargs = {\n    'device': device,\n    'num_layers': 3,\n    'hidden_dim': 256,\n    'dropout': 0.5,\n    'lr': 0.01,\n    'epochs': 100,\n    'num_heads': 4,  \n}\nargs","metadata":{"execution":{"iopub.status.busy":"2024-09-07T16:04:05.727695Z","iopub.execute_input":"2024-09-07T16:04:05.728631Z","iopub.status.idle":"2024-09-07T16:04:05.745925Z","shell.execute_reply.started":"2024-09-07T16:04:05.728598Z","shell.execute_reply":"2024-09-07T16:04:05.744909Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'device': 'cuda',\n 'num_layers': 3,\n 'hidden_dim': 256,\n 'dropout': 0.5,\n 'lr': 0.01,\n 'epochs': 100,\n 'num_heads': 4}"},"metadata":{}}]},{"cell_type":"code","source":"attn_kwargs = {'dropout': 0.5}\nmodel = GPS(channels=64, pe_dim=8, num_layers=10, attn_type='multihead',\n            attn_kwargs=attn_kwargs).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T16:04:05.747433Z","iopub.execute_input":"2024-09-07T16:04:05.747920Z","iopub.status.idle":"2024-09-07T16:04:05.858725Z","shell.execute_reply.started":"2024-09-07T16:04:05.747874Z","shell.execute_reply":"2024-09-07T16:04:05.857974Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"evaluator = Evaluator(name='ogbn-arxiv')","metadata":{"execution":{"iopub.status.busy":"2024-09-07T16:04:05.861643Z","iopub.execute_input":"2024-09-07T16:04:05.862068Z","iopub.status.idle":"2024-09-07T16:04:05.869822Z","shell.execute_reply.started":"2024-09-07T16:04:05.862023Z","shell.execute_reply":"2024-09-07T16:04:05.868720Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import copy\n\noptimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\nloss_fn = F.nll_loss\n\nbest_model = None\nbest_valid_acc = 0\n\nfor epoch in range(1, 1 + args[\"epochs\"]):\n    loss = train(model, data, train_idx, optimizer, loss_fn)\n    result = test(model, data, split_idx, evaluator)\n    train_acc, valid_acc, test_acc = result\n    if valid_acc > best_valid_acc:\n        best_valid_acc = valid_acc\n        best_model = copy.deepcopy(model)\n    print(f'Epoch: {epoch:02d}, '\n          f'Loss: {loss:.4f}, '\n          f'Train: {100 * train_acc:.2f}%, '\n          f'Valid: {100 * valid_acc:.2f}% '\n          f'Test: {100 * test_acc:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-09-07T16:04:05.871056Z","iopub.execute_input":"2024-09-07T16:04:05.871438Z","iopub.status.idle":"2024-09-07T16:04:06.916232Z","shell.execute_reply.started":"2024-09-07T16:04:05.871401Z","shell.execute_reply":"2024-09-07T16:04:06.914926Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [89,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [82,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [88,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [81,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [430,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [430,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [430,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [430,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [430,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [430,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [430,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [430,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [429,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [429,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [429,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [429,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [429,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [429,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [429,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [429,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [429,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [429,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [429,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [429,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [429,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [429,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [429,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [429,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m best_valid_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m---> 10\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     result \u001b[38;5;241m=\u001b[39m test(model, data, split_idx, evaluator)\n\u001b[1;32m     12\u001b[0m     train_acc, valid_acc, test_acc \u001b[38;5;241m=\u001b[39m result\n","Cell \u001b[0;32mIn[6], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data, train_idx, optimizer, loss_fn)\u001b[0m\n\u001b[1;32m      5\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mredraw_projection\u001b[38;5;241m.\u001b[39mredraw_projections()\n\u001b[0;32m----> 7\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(out[train_idx], data\u001b[38;5;241m.\u001b[39my[train_idx]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#########################################\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[4], line 41\u001b[0m, in \u001b[0;36mGPS.forward\u001b[0;34m(self, x, pe, edge_index, edge_attr, batch)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Convert node features to Long tensor for embedding lookup\u001b[39;00m\n\u001b[1;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()  \u001b[38;5;66;03m# Ensure x is treated as indices\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_emb(x), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpe_lin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_pe\u001b[49m\u001b[43m)\u001b[49m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     42\u001b[0m edge_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_emb(edge_attr)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`"],"ename":"RuntimeError","evalue":"CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}