{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8942367,"sourceType":"datasetVersion","datasetId":5380713}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n\n!pip install /kaggle/input/pytorch-geometric-packages/torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl\n!pip install /kaggle/input/pytorch-geometric-packages/torch_sparse-0.6.18-cp310-cp310-linux_x86_64.whl\n!pip install torch-geometric\n!pip install ogb","metadata":{"id":"Ai2S5lbCJfcQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\n\nimport torch\nprint(\"PyTorch has version {}\".format(torch.__version__))\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2024-09-16T09:28:56.830903Z","iopub.execute_input":"2024-09-16T09:28:56.831599Z","iopub.status.idle":"2024-09-16T09:28:58.901132Z","shell.execute_reply.started":"2024-09-16T09:28:56.831558Z","shell.execute_reply":"2024-09-16T09:28:58.900163Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"PyTorch has version 2.4.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch_geometric.nn import TransformerConv","metadata":{"execution":{"iopub.status.busy":"2024-09-16T09:28:58.902930Z","iopub.execute_input":"2024-09-16T09:28:58.903372Z","iopub.status.idle":"2024-09-16T09:29:00.722836Z","shell.execute_reply.started":"2024-09-16T09:28:58.903336Z","shell.execute_reply":"2024-09-16T09:29:00.721821Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /opt/conda/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n/opt/conda/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /opt/conda/lib/python3.10/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, GINEConv, global_mean_pool\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import QM9\nfrom torch_geometric.transforms import NormalizeFeatures\nimport torch_geometric\nfrom ogb.nodeproppred import PygNodePropPredDataset, Evaluator\nimport torch_geometric.transforms as T\nfrom torch.nn import (\n    BatchNorm1d,\n    Embedding,\n    Linear,\n    ModuleList,\n    ReLU,\n    Sequential,\n)\nfrom typing import Any, Dict, Optional","metadata":{"execution":{"iopub.status.busy":"2024-09-16T09:29:00.723985Z","iopub.execute_input":"2024-09-16T09:29:00.724489Z","iopub.status.idle":"2024-09-16T09:29:01.574011Z","shell.execute_reply.started":"2024-09-16T09:29:00.724424Z","shell.execute_reply":"2024-09-16T09:29:01.572834Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Dataset and Visualization","metadata":{"id":"IkZ0Y5PyzdXp"}},{"cell_type":"markdown","source":"The dataset under consideration is the \"ogbn-arxiv\" from the Open Graph Benchmark (OGB). This dataset embodies a citation network, mapped as a directed and heterogeneous graph, that captures the inter-relationships between Computer Science (CS) arXiv papers indexed by the Microsoft Academic Graph (MAG). The dataset encompasses:\n\n- Nodes: Representing arXiv papers, where each node is identified with a unique subject area, culminating in 40 distinct subject categories. There are a total of 169,343 nodes, split into training (90,941), validation (29,799), and testing (48,603) sets based on the publication dates. Specifically, papers published up until 2017 are in the training set, those from 2018 are in the validation set, and those from 2019 onwards form the test set.\n- Edges: Representing citation relationships. In this dataset, a directed edge from node A to node B signifies that paper A cites paper B. The dataset contains a total of 1,166,243 such directed edges.\n- Node Features: Each paper (node) is equipped with a 128-dimensional feature vector. This feature vector is derived by averaging the embeddings of the words found in the paper's title and abstract. The word embeddings themselves are generated using the skip-gram model applied to the MAG corpus.","metadata":{"id":"5u0826nOzdXr"}},{"cell_type":"markdown","source":"First, load and preprocess a graph dataset using the PyTorch Geometric library.\n\nThen, print the dataset's properties, such as the number of nodes, features, and the adjacency matrix's non-zero elements (nnz). It also confirms the device being used (CUDA/GPU in this case).\n\n","metadata":{"id":"VqLmHWH5zdXs"}},{"cell_type":"code","source":"# # Import Libraries\n# import torch_geometric.transforms as T # Provides transformation utilities for graph data in PyG\n# from ogb.nodeproppred import PygNodePropPredDataset # load node property prediction datasets from the Open Graph Benchmark\n\n# dataset_name = 'ogbn-arxiv' # define the dataset name\n# # Load the dataset and transform it to sparse tensor, , which is efficient for graph representation\n# dataset = PygNodePropPredDataset(name=dataset_name,\n#                                 transform=T.Compose([T.ToUndirected(),T.ToSparseTensor()]))\n\n# # Prints out basic information about the dataset\n# print('The {} dataset has {} graph'.format(dataset_name, len(dataset)))\n# print(\"{} dataset has {} classes\".format(dataset_name, dataset.num_classes))\n# print(\"{} dataset has {} features\".format(dataset_name, dataset.num_features))\n\n# # Extract the graph from the dataset, which includes node features, labels, and the adjacency matrix\n# data = dataset[0]\n# print(data)\n\n# # Checks if a CUDA-enabled GPU is available. If so, it sets the device to 'cuda' for GPU acceleration, otherwise, it defaults to 'cpu'\n# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n# print('Device: {}'.format(device))\n# # Transfers the graph data (data) to the chosen device\n# data = data.to(device)\n\n# # Data splitting\n# # Retrieves indices for splitting the dataset into training, validation, and test sets\n# split_idx = dataset.get_idx_split()\n# # Extracts and transfers the training indices to the same device (CPU/GPU) as the data\n# train_idx = split_idx['train'].to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eO8sdv8CPp14","outputId":"bf4e10d5-5b97-44ac-b234-c367e9c50ac6","execution":{"iopub.status.busy":"2024-09-16T09:29:01.577954Z","iopub.execute_input":"2024-09-16T09:29:01.579277Z","iopub.status.idle":"2024-09-16T09:29:01.586025Z","shell.execute_reply.started":"2024-09-16T09:29:01.579239Z","shell.execute_reply":"2024-09-16T09:29:01.584359Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"**Visualize the data as networks**: For visualization purposes, we take 1000 nodes with the most citations from the training set, along with their interconnections (9564 edges).\n\nIn the visualization:\n\n- Each node represents a paper.\n- The color of a node indicates its subject area.\n- Edges represent citations between papers.","metadata":{"id":"-1MMbSbnzdXt"}},{"cell_type":"code","source":"# import json\n# import pickle\n# import networkx as nx\n\n# # 1: data preparation\n# # selects nodes ('selected_x') and their labels ('selected_y') from the training set, indexed by 'train_idx'\n# train_x = data.x[train_idx]\n# train_x_idx = [i for i in range(len(train_x))]\n# selected_x = train_idx[train_x_idx]\n# selected_y = data.y[train_idx][train_x_idx]\n\n# # 2: calculates the number of edges for each selected node\n# node_num_edges_dict = {}\n# for i in selected_x:\n#     num_edges = data.adj_t[i.item()].to_dense().to_sparse().indices().shape[1]\n#     # print(\"node\", i.item(), \"has\", num_edges, \"edges\")\n#     node_num_edges_dict[i.item()] = num_edges\n\n# # 3. sorting and selecting top nodes\n# # The top 1000 nodes are selected and stored in top_1000_node\n# sorted_node_num_edges_dict = sorted(node_num_edges_dict.items(), key=lambda x: x[1], reverse=True)\n# with open('sorted_node_num_edges_dict.json', 'w') as fp:\n#     json.dump(sorted_node_num_edges_dict, fp, indent=4)\n# top_1000_node = [i[0] for i in sorted_node_num_edges_dict[:1000]]\n\n# # 4. make into a graph\n# # Nodes are added to G with their corresponding labels ('y' of the node)\n# G = nx.Graph()\n# for node in top_1000_node:\n#     idx = selected_x.tolist().index(node)\n#     label = selected_y[idx].item()\n#     G.add_node(node, label=label)\n\n# # Edges are added between these nodes based on their connections in data.adj_t\n# for node in top_1000_node:\n#     # from data.adj_t get the edges of node i as stored in the graph\n#     edge = data.adj_t[node].to_dense().to_sparse().indices() # [1]?\n#     for j in edge[1]:\n#         if j in top_1000_node:\n#             G.add_edge(node,j.item())\n\n# # 5. summary of the graph\n# print(\"number of nodes:\", G.number_of_nodes())\n# print(\"number of edges:\", G.number_of_edges())\n# print(\"average degree:\", np.mean([G.degree[i] for i in G.nodes]))\n# print(\"average clustering coefficient:\", nx.average_clustering(G))\n\n# # 6. save and load the graph object\n# pickle.dump(G, open('graph_1000_paper.pickle', 'wb'))\n# G = pickle.load(open('graph_1000_paper.pickle', 'rb'))","metadata":{"id":"KME0S1ZLzdXu","execution":{"iopub.status.busy":"2024-09-16T09:29:01.587902Z","iopub.execute_input":"2024-09-16T09:29:01.588205Z","iopub.status.idle":"2024-09-16T09:29:01.596215Z","shell.execute_reply.started":"2024-09-16T09:29:01.588165Z","shell.execute_reply":"2024-09-16T09:29:01.594988Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# # This file (net_vis.py) could be found at https://drive.google.com/file/d/1-BzOouLqeJtP8MYvBS5aXaW7lSpkjFGd/view?usp=sharing.\n# # We do not include this file due to the length of the functions and class.\n# # It is adapted from https://gist.github.com/mogproject/50668d3ca60188c50e6ef3f5f3ace101.\n# %run net_vis.py\n\n# # Creates a list of 40 unique colors from the CSS4 color specifications. These colors will be used to represent different subject areas in the graph\n# import matplotlib.pyplot as plt\n# import matplotlib.colors as mcolors\n# color_list = list(mcolors.CSS4_COLORS.keys())[:40]\n\n# # a dictionary to map labels (subject areas) to nodes\n# # each key is a label, and the value is a list of nodes associated with that label\n# label_node_dict = {}\n# for i in range(selected_y.max().item()+1):\n#     label_node_dict[i] = []\n# for i in range(len(selected_y)):\n#     label_node_dict[selected_y[i].item()].append(selected_x[i].item())\n\n\n# # a dictionary to map colors to labels (subject areas)\n# # each key is a color and its value is a list of nodes that belong to the label associated with that color\n# label_color_dict = {}\n# for i in label_node_dict:\n#     label_color_dict[color_list[i]] = label_node_dict[i]\n\n# # Defines the color of the edges in the graph. In this case, all edges are colored black (#000000)\n# edge_color_dict = {'#000000': G.edges }\n\n# # This function (presumably defined in net_vis.py) takes the graph G, along with the color mappings for nodes and edges\n# vis_graph_design(G, label_color_dict, edge_color_dict)","metadata":{"id":"a9zsra4ozdXu","execution":{"iopub.status.busy":"2024-09-16T09:29:01.597937Z","iopub.execute_input":"2024-09-16T09:29:01.598254Z","iopub.status.idle":"2024-09-16T09:29:01.608161Z","shell.execute_reply.started":"2024-09-16T09:29:01.598221Z","shell.execute_reply":"2024-09-16T09:29:01.606969Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# The Model\n\nNow, we will define the UniMP model with graph transformer layer based on the paper [Masked Label Prediction: Unified Message Passing Model for Semi-Supervised Classification](https://arxiv.org/abs/2009.03509), section 3.\n\nThe UniMP model combines the principles of graph neural networks with Transformer architecture, which allows the model to effectively capture node relationships and feature interactions in the graph, especially for semi-supervised learning on graphs.\n\nUniMp also utilizes the Gated Residual Connection to prevent over-smoothing. This feature allows the model to balance the integration of new features with existing ones. With PyG `TransformerConv` layer, we can easily incorporate this feature when using the graph transformer in just a single line!\n\nDuring our implementation of the UniMP here, we will focus on the graph transformer layer and gated residual. PyG also provides a layer for the masked label prediction strategy utilized by the UniMP model at [here](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.MaskLabel.html). We also refer to Colab 2 starter codes in [CS224W at Stanford](https://web.stanford.edu/class/cs224w/) for our implementation, training, and evalution of the model.\n","metadata":{"id":"gRTFJVUQ0SV1"}},{"cell_type":"markdown","source":"#### PyG Impelemntation:\n\nThe `UniMP` class is a PyTorch implementation of a Graph Neural Network (GNN) model that incorporates Transformer-style convolutional layers. It inherits from `torch.nn.Module`, which is the base class for all neural network modules in PyTorch.\n\n- **Input Parameters**:\n  - `input_dim`: The dimension of input features for each node.\n  - `hidden_dim`: The size of the hidden layers.\n  - `output_dim`: The dimension of the output features (often equal to the number of classes in a classification task).\n  - `num_layers`: The number of layers in the model.\n  - `dropout`: The dropout rate for regularization. It is used to prevent overfitting, helping the learning process remains generalized.\n  - `beta`: A boolean parameter indicating whether to use a gated residual connection (based on equations 5 and 6 from the UniMP paper). The gated residual connection (controlled by the beta parameter) helps preventing overfitting by allowing the model to balance between new and existing node features across layers.\n  - `heads`: The number of heads in the multi-head attention mechanism.\n\n- **Initialization of Layers**:\n  - **Transformer Convolutional Layers** (`conv_layers`): A sequence of `TransformerConv` layers is created. The first layer transforms the input dimension to the hidden dimension, while subsequent layers operate on the hidden dimension. The final layer transforms to the output dimension. The `beta` parameter and `concat` (for the last layer) are set as per the UniMP model design.\n  - **Layer Normalization** (`layerNorm_layers`): Layer normalization is applied to each transformer block (except the last one) to stabilize and speed up training, ensuring that the distribution of the layer inputs does not shift drastically, which can be particularly beneficial in deep networks such as GNN.\n\n**`reset_parameters`**: Resets the parameters of the convolutional and normalization layers, ensuring they are re-initialized when needed.\n\n**`forward`**\n- **Input**:\n  - Takes node features `x`, labels `y` (though not used in the forward pass in this implementation), and edge indices `edge_index`.\n- **Processing through Layers**:\n  - The input features are passed sequentially through the transformer convolutional layers.\n  - After each convolutional layer (except the last), the following operations are applied:\n    - Layer normalization (`LayerNorm`).\n    - ReLU activation function.\n    - Dropout for regularization.\n  - The final layer is processed without layer normalization and ReLU to average the multi-head results for the expected output.\n        ","metadata":{"id":"HP8A7DY6bgc7"}},{"cell_type":"code","source":"class RedrawProjection:\n    def __init__(self, model: torch.nn.Module,\n                 redraw_interval: Optional[int] = None):\n        self.model = model\n        self.redraw_interval = redraw_interval\n        self.num_last_redraw = 0\n\n    def redraw_projections(self):\n        if not self.model.training or self.redraw_interval is None:\n            return\n        if self.num_last_redraw >= self.redraw_interval:\n            fast_attentions = [\n                module for module in self.model.modules()\n                if isinstance(module, PerformerAttention)\n            ]\n            for fast_attention in fast_attentions:\n                fast_attention.redraw_projection_matrix()\n            self.num_last_redraw = 0\n            return\n        self.num_last_redraw += 1","metadata":{"id":"8XKD1S0izdXv","execution":{"iopub.status.busy":"2024-09-16T09:29:01.609653Z","iopub.execute_input":"2024-09-16T09:29:01.609981Z","iopub.status.idle":"2024-09-16T09:29:01.619151Z","shell.execute_reply.started":"2024-09-16T09:29:01.609949Z","shell.execute_reply":"2024-09-16T09:29:01.617935Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import BatchNorm, GPSConv\n\nclass GPS(torch.nn.Module):\n    def __init__(self, channels: int, pe_dim: int, num_layers: int,\n                 attn_type: str, attn_kwargs: Dict[str, Any]):\n        super().__init__()\n\n        self.node_emb = Embedding(28, channels - pe_dim)\n        self.pe_lin = Linear(3, pe_dim)\n        self.pe_norm = BatchNorm1d(3)\n        self.edge_emb = Embedding(4, channels)\n\n        self.convs = ModuleList()\n        for _ in range(num_layers):\n            nn = Sequential(\n                Linear(channels, channels),\n                ReLU(),\n                Linear(channels, channels),\n            )\n            conv = GPSConv(channels, GINEConv(nn), heads=4,\n                           attn_type=attn_type, attn_kwargs=attn_kwargs)\n            self.convs.append(conv)\n\n        self.mlp = Sequential(\n            Linear(channels, channels // 2),\n            ReLU(),\n            Linear(channels // 2, channels // 4),\n            ReLU(),\n            Linear(channels // 4, 1),\n        )\n        self.redraw_projection = RedrawProjection(\n            self.convs,\n            redraw_interval=1000 if attn_type == 'performer' else None)\n\n    def forward(self, x, pe, edge_index, edge_attr, batch):\n        x_pe = self.pe_norm(pe)\n        # Convert node features to Long tensor for embedding lookup\n        x = x.squeeze(-1).long()  # Ensure x is treated as indices\n        x = torch.cat((self.node_emb(x), self.pe_lin(x_pe)), 1)\n        edge_attr = self.edge_emb(edge_attr)\n\n        for conv in self.convs:\n            x = conv(x, edge_index, batch, edge_attr=edge_attr)\n        x = global_add_pool(x, batch)\n        return self.mlp(x)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T09:29:01.620780Z","iopub.execute_input":"2024-09-16T09:29:01.621211Z","iopub.status.idle":"2024-09-16T09:29:01.635519Z","shell.execute_reply.started":"2024-09-16T09:29:01.621176Z","shell.execute_reply":"2024-09-16T09:29:01.634000Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Training and evaluation","metadata":{"id":"ElW1t7vPWDMA"}},{"cell_type":"markdown","source":"The `train` function is called within a training loop, iterating over epochs or until a certain condition is met (like convergence of the loss). Note that we need to handle dataset shuffling as required before passing the data to this function.\n\n- **Parameters**:\n  - `model`: The neural network model to be trained.\n  - `data`: The graph data, which includes node features (`data.x`), labels (`data.y`), and edge indices (`data.edge_index`).\n  - `train_idx`: Indices of nodes in the training set.\n  - `optimizer`: The optimizer used for updating model parameters.\n  - `loss_fn`: The loss function used to compute the training loss.\n\n1. **Set Model to Training Mode**:\n   - `model.train()`: This ensures that the model is in training mode, enabling features like dropout and batch normalization specifically tuned for training.\n\n2. **Zeroing the Gradients**:\n   - `optimizer.zero_grad()`: Clears old gradients from the last step. In PyTorch, gradients accumulate by default, hence they need to be explicitly zeroed out before computing the new gradients.\n\n3. **Forward Pass**:\n   - `out = model(data.x, data.edge_index)`: The model performs a forward pass using the input features, labels, and edge indices. The output `out` is the probability distribution of the model's predictions for each class.\n\n4. **Compute Loss**:\n   - `loss = loss_fn(out[train_idx], torch.flatten(data.y[train_idx]))`: The loss is calculated using the predictions for the training nodes (`out[train_idx]`) and their corresponding true labels (`data.y[train_idx]`). `torch.flatten` is used to ensure the label tensor shape matches the output.\n\n5. **Backward Pass and Optimization Step**:\n   - `loss.backward()`: Performs the backward pass to compute the gradients of the loss with respect to model parameters.\n   - `optimizer.step()`: Updates the model parameters based on the computed gradients.\n\n6. **Return Loss**:\n   - `return loss.item()`: Returns the loss value as a Python float. This is useful for monitoring the training process, such as logging the loss or implementing some stopping criteria.\n\n","metadata":{"id":"mNGHdMwlbgc9"}},{"cell_type":"code","source":"def train(model, data, train_idx, optimizer, loss_fn):\n    \"\"\"\n    Param:\n    - model: The neural network model to be trained.\n    - data: The graph data, which includes node features (`data.x`) and edge\n        indices (`data.edge_index`).\n    - train_idx: Indices of nodes in the training set.\n    - optimizer: The optimizer used for updating model parameters.\n    - loss_fn: The loss function used to compute the training loss.\n    \"\"\"\n    model.train()\n\n    optimizer.zero_grad()\n#     out = model(data.x, data.edge_index)\n    model.redraw_projection.redraw_projections()\n    out = model(data.x, data.pe, data.edge_index, data.edge_attr,\n                    data.batch)\n    loss = loss_fn(out[train_idx], torch.flatten(data.y[train_idx]))\n\n    loss.backward()\n    optimizer.step()\n\n    return loss.item()","metadata":{"id":"jsMYp-hi4ct0","execution":{"iopub.status.busy":"2024-09-16T09:29:01.636672Z","iopub.execute_input":"2024-09-16T09:29:01.637004Z","iopub.status.idle":"2024-09-16T09:29:01.645238Z","shell.execute_reply.started":"2024-09-16T09:29:01.636971Z","shell.execute_reply":"2024-09-16T09:29:01.644105Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"\n- **Decorator `@torch.no_grad()`**: This disables gradient computation during the execution of the function\n- **Parameters**:\n  - `model`: The neural network model to be evaluated.\n  - `data`: The graph data, containing node features (`data.x`), labels (`data.y`), and edge indices (`data.edge_index`).\n  - `split_idx`: A dictionary containing indices for the training, validation, and test sets.\n\n\n1. **Set Model to Evaluation Mode**:\n   - `model.eval()`: Ensures that the model is in evaluation mode, deactivating features like dropout and batch normalization that are only meant for training.\n\n2. **Forward Pass**:\n   - `out = model(data.x, data.edge_index)`: Performs a forward pass of the model to get predictions for the entire dataset.\n\n3. **Accuracy Computation for Each Dataset Split**:\n   - **Training Accuracy**:\n     - `y_pred_train = out[split_idx['train']].argmax(dim=-1)`: Gets the predicted class labels for the training set by selecting the class with the highest predicted score.\n     - `train_acc = ...`: Calculates the training accuracy by comparing the predicted labels with the true labels.\n   - **Validation Accuracy**:\n     - Similar steps are followed to compute the accuracy for the validation set.\n   - **Test Accuracy**:\n     - Similar steps are followed to compute the accuracy for the test set.\n\n4. **Return Accuracies**:\n   - `return train_acc, valid_acc, test_acc`: Returns the computed accuracies for the training, validation, and test sets.","metadata":{"id":"d-ks-6Vjbgc9"}},{"cell_type":"code","source":"@torch.no_grad()\ndef test(model, data, split_idx):\n    \"\"\"\n    Compute the model accuracy for train, validation, and test dataset.\n    Params.\n    - model: The neural network model to be evaluated.\n    - data: The graph data, containing node features (`data.x`),\n        labels (`data.y`), and edge indices (`data.edge_index`).\n    - split_idx: A dictionary containing indices for the training, validation,\n        and test sets.\n    \"\"\"\n    model.eval()\n\n#     out = model(data.x, data.edge_index)\n    out = None\n    out = model(data.x, data.pe, data.edge_index, data.edge_attr,\n                    data.batch)\n    y_pred_train = out[split_idx['train']].argmax(dim=-1, keepdim=False)\n    train_acc = int((y_pred_train == data.y[split_idx['train']]).sum()) / y_pred_train.size(0)\n\n    y_pred_val = out[split_idx['valid']].argmax(dim=-1, keepdim=False)\n    valid_acc = int((y_pred_val == data.y[split_idx['valid']]).sum()) / y_pred_val.size(0)\n\n    y_pred_test = out[split_idx['test']].argmax(dim=-1, keepdim=False)\n    test_acc = int((y_pred_test == data.y[split_idx['test']]).sum()) / y_pred_test.size(0)\n\n    return train_acc, valid_acc, test_acc","metadata":{"id":"fvdFeGrb4lJd","execution":{"iopub.status.busy":"2024-09-16T09:29:01.650530Z","iopub.execute_input":"2024-09-16T09:29:01.650899Z","iopub.status.idle":"2024-09-16T09:29:01.660610Z","shell.execute_reply.started":"2024-09-16T09:29:01.650857Z","shell.execute_reply":"2024-09-16T09:29:01.659473Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Training and testing on undirected graph","metadata":{"id":"_pdj_FZAeRTV"}},{"cell_type":"markdown","source":"First, we apply the model on the undirected graph. To get the undirected graph,\n\n1. **Dataset Loading and Transformation**:\n   - The `ogbn-arxiv` dataset is loaded with a transformation to make it undirected (`T.ToUndirected()`). This transformation is suitable for undirected graphs where each edge is bidirectional.\n2. **Device Setup**: as discussed before\n3. **Data Extraction and Preparation**\n4. **Data Splitting**","metadata":{"id":"EnE79oxkbgc-"}},{"cell_type":"code","source":"# from torch_sparse import set_sparse_backend\n# set_sparse_backend('torch')  # Switch sparse backend to avoid MKL errors\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T09:29:01.662384Z","iopub.execute_input":"2024-09-16T09:29:01.662738Z","iopub.status.idle":"2024-09-16T09:29:01.668150Z","shell.execute_reply.started":"2024-09-16T09:29:01.662693Z","shell.execute_reply":"2024-09-16T09:29:01.666866Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"dataset_name = 'ogbn-arxiv'\n# We transform the graph to an undirected one as during our experiments, we\n# find that the the model does not perform well on original direct graph. The\n# same process on the directed graph is in below.\ntransform = T.AddRandomWalkPE(walk_length=3, attr_name='pe')\n# dataset = PygNodePropPredDataset(name=dataset_name, transform=T.Compose([T.ToUndirected(),transform]))\ndataset = PygNodePropPredDataset(name=dataset_name, transform=transform)\n\nprint('The {} dataset has {} graph'.format(dataset_name, len(dataset)))\nprint(\"{} dataset has {} classes\".format(dataset_name, dataset.num_classes))\n# print(\"{} dataset has {} features\".format(dataset_name, dataset.num_features))\n\n# Make sure that we are using cuda for fast training later.\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint('Device: {}'.format(device))\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DvKND_kB9OeD","outputId":"9f5ea670-9728-463e-fae9-276268a7f995","execution":{"iopub.status.busy":"2024-09-16T09:29:01.669565Z","iopub.execute_input":"2024-09-16T09:29:01.669879Z","iopub.status.idle":"2024-09-16T09:29:01.756367Z","shell.execute_reply.started":"2024-09-16T09:29:01.669848Z","shell.execute_reply":"2024-09-16T09:29:01.755102Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"The ogbn-arxiv dataset has 1 graph\nogbn-arxiv dataset has 40 classes\nDevice: cuda\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/ogb/nodeproppred/dataset_pyg.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.data, self.slices = torch.load(self.processed_paths[0])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Extract the graph.\ndata = dataset[0]","metadata":{"execution":{"iopub.status.busy":"2024-09-16T09:29:01.757764Z","iopub.execute_input":"2024-09-16T09:29:01.758094Z","iopub.status.idle":"2024-09-16T09:29:04.513747Z","shell.execute_reply.started":"2024-09-16T09:29:01.758060Z","shell.execute_reply":"2024-09-16T09:29:04.512851Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch_geometric/utils/sparse.py:277: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n  adj = torch.sparse_csr_tensor(\n","output_type":"stream"}]},{"cell_type":"code","source":"data = data.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T09:29:04.516886Z","iopub.execute_input":"2024-09-16T09:29:04.517284Z","iopub.status.idle":"2024-09-16T09:29:04.677248Z","shell.execute_reply.started":"2024-09-16T09:29:04.517239Z","shell.execute_reply":"2024-09-16T09:29:04.676315Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"data.y = data.y.view(-1) # To avoid CUDA out of memory during evaluations.\n\nsplit_idx = dataset.get_idx_split()\ntrain_idx = split_idx['train'].to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T09:29:04.678550Z","iopub.execute_input":"2024-09-16T09:29:04.678949Z","iopub.status.idle":"2024-09-16T09:29:04.715810Z","shell.execute_reply.started":"2024-09-16T09:29:04.678907Z","shell.execute_reply":"2024-09-16T09:29:04.714940Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"**Model Configuration**:\nThe `UniMP` model is initialized with specified configurations including the number of layers, hidden dimensions, dropout rate, etc. Due to resource limitations, the hidden dimension is set to 64 instead of 128 as mentioned in the paper.\n","metadata":{"id":"unm72yvIbgc-"}},{"cell_type":"code","source":"# Please do not change the args\n\nattn_kwargs = {'dropout': 0.5}\nmodel = GPS(channels=64, pe_dim=8, num_layers=3, attn_type='multihead',\n            attn_kwargs=attn_kwargs).to(device)","metadata":{"id":"ekGxiqLI4sVp","execution":{"iopub.status.busy":"2024-09-16T09:29:04.716997Z","iopub.execute_input":"2024-09-16T09:29:04.717302Z","iopub.status.idle":"2024-09-16T09:29:04.796858Z","shell.execute_reply.started":"2024-09-16T09:29:04.717269Z","shell.execute_reply":"2024-09-16T09:29:04.796048Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"args = {\n    'device': device,\n    'num_layers': 3,\n    'hidden_dim': 256,\n    'dropout': 0.5,\n    'lr': 0.001,\n    'epochs': 100,\n    'num_heads': 2,  \n    \"weight_decay\":0.0005,\n}","metadata":{"execution":{"iopub.status.busy":"2024-09-16T09:29:04.797906Z","iopub.execute_input":"2024-09-16T09:29:04.798182Z","iopub.status.idle":"2024-09-16T09:29:04.802882Z","shell.execute_reply.started":"2024-09-16T09:29:04.798152Z","shell.execute_reply":"2024-09-16T09:29:04.801875Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"\n#### Training Loop\n1. **Model Training**:\n   - For each epoch, the model is trained using the `train` function, which performs forward and backward passes and updates the model parameters.\n   - The loss for each epoch is recorded.\n\n2. **Model Evaluation**:\n   - The `test` function is used to evaluate the model on the training, validation, and test sets at each epoch. The accuracies are recorded.\n\n3. **Model Selection**:\n   - The best performing model on the validation set is saved. This helps in selecting the model that generalizes well.\n\n4. **Logging**:\n   - Training progress is logged every 10 epochs, showing the loss and accuracies.\n\n5. **Epoch Control**:\n   - The number of epochs is controlled by `configs[\"epochs\"]`. The training starts from `epoch_str` (1) and continues for the specified number of epochs (1 + `configs[\"epochs\"]`).\n\n**Loss Function and Optimizer**\n\n- We use cross-entropy loss (`F.cross_entropy`) for multi-class classification tasks, and\n- An Adam optimizer for optimizing the model parameters.\n","metadata":{"id":"ABTe83XPbgc-"}},{"cell_type":"code","source":"import copy\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T09:29:04.804054Z","iopub.execute_input":"2024-09-16T09:29:04.804356Z","iopub.status.idle":"2024-09-16T09:29:04.811817Z","shell.execute_reply.started":"2024-09-16T09:29:04.804324Z","shell.execute_reply":"2024-09-16T09:29:04.810913Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\nloss_fn = F.cross_entropy\n\nbest_model = None\nbest_valid_acc = 0\n\nlosses, train_accs, valid_accs, test_accs = [], [], [], []\n\nepoch_str = 1\nfor epoch in range(epoch_str, epoch_str + args[\"epochs\"]):\n  loss = train(model, data, train_idx, optimizer, loss_fn)\n  result = test(model, data, split_idx)\n  train_acc, valid_acc, test_acc = result\n  if valid_acc > best_valid_acc:\n      best_valid_acc = valid_acc\n      best_model = copy.deepcopy(model)\n  losses.append(loss)\n  train_accs.append(train_acc)\n  valid_accs.append(valid_acc)\n  test_accs.append(test_acc)\n  if epoch % 10 == 0:\n    print(f'Epoch: {epoch:02d}, '\n          f'Loss: {loss:.4f}, '\n          f'Train: {100 * train_acc:.2f}%, '\n          f'Valid: {100 * valid_acc:.2f}% '\n          f'Test: {100 * test_acc:.2f}%')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YR2RsDicTtLS","outputId":"0270139e-b9e7-46f5-9f73-37d3278c6737","execution":{"iopub.status.busy":"2024-09-16T09:29:04.814033Z","iopub.execute_input":"2024-09-16T09:29:04.814508Z","iopub.status.idle":"2024-09-16T09:29:05.801762Z","shell.execute_reply.started":"2024-09-16T09:29:04.814446Z","shell.execute_reply":"2024-09-16T09:29:05.800036Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [46,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [46,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [46,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [46,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [46,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [46,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [46,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [46,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [20,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [19,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [45,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [274,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [273,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m epoch_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch_str, epoch_str \u001b[38;5;241m+\u001b[39m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m---> 11\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m   result \u001b[38;5;241m=\u001b[39m test(model, data, split_idx)\n\u001b[1;32m     13\u001b[0m   train_acc, valid_acc, test_acc \u001b[38;5;241m=\u001b[39m result\n","Cell \u001b[0;32mIn[9], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data, train_idx, optimizer, loss_fn)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#     out = model(data.x, data.edge_index)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     model\u001b[38;5;241m.\u001b[39mredraw_projection\u001b[38;5;241m.\u001b[39mredraw_projections()\n\u001b[0;32m---> 16\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(out[train_idx], torch\u001b[38;5;241m.\u001b[39mflatten(data\u001b[38;5;241m.\u001b[39my[train_idx]))\n\u001b[1;32m     20\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[8], line 41\u001b[0m, in \u001b[0;36mGPS.forward\u001b[0;34m(self, x, pe, edge_index, edge_attr, batch)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Convert node features to Long tensor for embedding lookup\u001b[39;00m\n\u001b[1;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()  \u001b[38;5;66;03m# Ensure x is treated as indices\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_emb(x), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpe_lin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_pe\u001b[49m\u001b[43m)\u001b[49m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     42\u001b[0m edge_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_emb(edge_attr)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`"],"ename":"RuntimeError","evalue":"CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`","output_type":"error"}]},{"cell_type":"code","source":"best_result = test(model, data, split_idx)\ntrain_acc, valid_acc, test_acc = best_result\nprint(f'Best model: '\n      f'Train: {100 * train_acc:.2f}%, '\n      f'Valid: {100 * valid_acc:.2f}% '\n      f'Test: {100 * test_acc:.2f}%')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EketfgVTKoTk","outputId":"a89a11f7-3e71-4fcc-848b-5dde6bdb7baf","execution":{"iopub.status.busy":"2024-09-16T09:29:05.802690Z","iopub.status.idle":"2024-09-16T09:29:05.803205Z","shell.execute_reply.started":"2024-09-16T09:29:05.802939Z","shell.execute_reply":"2024-09-16T09:29:05.802968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.arange(500)\n\nplt.plot(x, train_accs, label = \"Train\")\nplt.plot(x, test_accs, label = \"Test\")\nplt.plot(x, valid_accs, label = \"Val\")\n\nplt.title(\"Train, validation, and test accuracy across epoches\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"id":"57j0kRGxGRip","outputId":"c2b257cc-6dd7-442e-d0c0-bf17d6ac7431","execution":{"iopub.status.busy":"2024-09-16T09:29:05.804797Z","iopub.status.idle":"2024-09-16T09:29:05.805309Z","shell.execute_reply.started":"2024-09-16T09:29:05.805047Z","shell.execute_reply":"2024-09-16T09:29:05.805074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see the accuracy trends.\n\n- Initial Learning Phase (Epochs 1-30): The model starts with low accuracy on all sets (training, validation, test).\n\n- Significant Learning (Epochs 30-100): We found a noticeable improvement in accuracy across all datasets.\n\n- Steady Improvement (Epochs 100-500): The model continues to improve gradually. The rate of improvement slows down as it converges towards its optimal performance given the architecture and data.","metadata":{"id":"__p01B2kbgc_"}},{"cell_type":"code","source":"x = np.arange(500)\n\nplt.plot(x, losses)\n\nplt.title(\"Train loss across epoches\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":510},"id":"8YU-R9zwJz3s","outputId":"845f7c8b-217c-4c59-d290-df65c14fdcd0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The best model yields an accuracy of 72.66% on the training set, 71.37% on the validation set, and 70.28% on the test set. This indicates good generalization as the validation and test accuracies are close to the training accuracy.\n\n- **Overfitting**: The model does not appear to overfit significantly, as the training accuracy is not drastically higher than the validation and test accuracies.\n\n- **Performance plateau**: Around epoch 300, the improvements in accuracy begin to plateau, suggesting that additional training beyond 500 epochs may not yield significant gains.\n\n- **Limitations due to resources**: The reduced hidden dimension (64 instead of 128 as recommended in the original paper) due to resource limitations might have constrained the model's learning capacity.","metadata":{"id":"_iBMwu2xbgc_"}},{"cell_type":"markdown","source":"### Training as directed graph\n\nNow we perform the same training and testing pipeline on the same ogbn-arxiv dataset, but as a directed graph. Interestingly, we found a notable decrease in model performance compared to training on an undirected graph.","metadata":{"id":"jxzt5mLJXAsm"}},{"cell_type":"code","source":"\n# dataset_name = 'ogbn-arxiv'\n# # We do not use sparse tensor for transformer model due to limitation on GPU resourses.\n# dataset = PygNodePropPredDataset(name=dataset_name)\n\n# print('The {} dataset has {} graph'.format(dataset_name, len(dataset)))\n# print(\"{} dataset has {} classes\".format(dataset_name, dataset.num_classes))\n# print(\"{} dataset has {} features\".format(dataset_name, dataset.num_features))\n\n# # Make sure that we are using cuda for fast training later.\n# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n# print('Device: {}'.format(device))\n\n# # Extract the graph\n# data = dataset[0]\n# data = data.to(device)\n# data.y = data.y.view(-1) # To avoid CUDA out of memory during evaluations.\n\n# split_idx = dataset.get_idx_split()\n# train_idx = split_idx['train'].to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XbSZsu_tXECq","outputId":"f7e29267-4895-4e4a-c524-46a5fca27662","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = UniMP(data.num_features, configs['hidden_dim'],\n#             dataset.num_classes, configs['num_layers'],\n#             configs['dropout'], heads=configs['num_heads']).to(device)\n\n# model.reset_parameters()\n\n# optimizer = torch.optim.Adam(model.parameters(), lr=configs['lr'], weight_decay=configs['weight_decay'])\n# loss_fn = F.cross_entropy\n\n# best_model = None\n# best_valid_acc = 0\n\n# losses, train_accs, valid_accs, test_accs = [], [], [], []\n\n# epoch_str = 1\n# for epoch in range(epoch_str, epoch_str + configs[\"epochs\"]):\n#   loss = train(model, data, train_idx, optimizer, loss_fn)\n#   result = test(model, data, split_idx)\n#   train_acc, valid_acc, test_acc = result\n#   if valid_acc > best_valid_acc:\n#       best_valid_acc = valid_acc\n#       best_model = copy.deepcopy(model)\n#   losses.append(loss)\n#   train_accs.append(train_acc)\n#   valid_accs.append(valid_acc)\n#   test_accs.append(test_acc)\n#   if epoch % 10 == 0:\n#     print(f'Epoch: {epoch:02d}, '\n#           f'Loss: {loss:.4f}, '\n#           f'Train: {100 * train_acc:.2f}%, '\n#           f'Valid: {100 * valid_acc:.2f}% '\n#           f'Test: {100 * test_acc:.2f}%')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R2RQG_EOXJhx","outputId":"828516ac-dd53-43d1-acb5-edaf14ac358c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The final accuracies are 65.85% for the training set, 61.54% for the validation set, and 55. 36% for the test set. The test accuracy is notably lower than the training accuracy. These figures are lower compared to the performance on the undirected graph.","metadata":{"id":"Y9pEiDkSbgdA"}},{"cell_type":"code","source":"best_result = test(model, data, split_idx)\ntrain_acc, valid_acc, test_acc = best_result\nprint(f'Best model: '\n      f'Train: {100 * train_acc:.2f}%, '\n      f'Valid: {100 * valid_acc:.2f}% '\n      f'Test: {100 * test_acc:.2f}%')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hfv3vxmFfBZ3","outputId":"6622a8ed-4f92-47ab-faad-04a9c671cd1d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The accuracy plot shows a steady increase in all three datasets, while the loss plot indicates a consistent decrease.","metadata":{"id":"ZPspFFLlbgdB"}},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import numpy as np\n\n# x = np.arange(500)\n\n# plt.plot(x, train_accs, label = \"Train\")\n# plt.plot(x, test_accs, label = \"Test\")\n# plt.plot(x, valid_accs, label = \"Val\")\n\n# plt.title(\"Train, validation, and test accuracy across epoches\")\n# plt.xlabel(\"Epoch\")\n# plt.ylabel(\"Accuracy\")\n# plt.legend()\n# plt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"id":"oqkRa63PfBZ3","outputId":"02ede013-ec48-4303-df37-dc918f1bddcf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x = np.arange(500)\n\n# plt.plot(x, losses)\n\n# plt.title(\"Train loss across epoches\")\n# plt.xlabel(\"Epoch\")\n# plt.ylabel(\"Loss\")\n# plt.legend()\n# plt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":510},"id":"isazPj9tfBZ4","outputId":"f9b8a475-72f3-4202-8417-01bef37b7315"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Analyze the results:\n\n\n- **Overfitting**: A gap between training and test accuracies suggests mild overfitting. The model might be capturing some noise or specific patterns in the training data that do not generalize as well to unseen data.\n\n- **Performance Plateau**: Similar to the undirected case, the model's improvements in accuracy begin to plateau around epoch 300, suggesting that extending training beyond 500 epochs might not lead to significant performance gains.\n\n\n- The accuracies are lower **compared to** when the graph was treated as undirected. This could suggest that the undirected representation may capture more relevant information for this particular task, or that the model architecture and hyperparameters are more optimized for the undirected scenario. The decrease in performance when using a directed graph suggests that the model might rely on the symmetrical structure of undirected graphs. The UniMP model, being based on Transformer architecture, might be more suited to undirected graphs where each connection is equally informative in both directions.\n\n","metadata":{"id":"H3bvGtCFbgdB"}},{"cell_type":"code","source":"","metadata":{"id":"82ROIpg-yeYl"},"execution_count":null,"outputs":[]}]}