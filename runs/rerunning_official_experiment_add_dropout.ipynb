{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8942367,"sourceType":"datasetVersion","datasetId":5380713}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-09-30T14:30:22.758938Z","iopub.execute_input":"2024-09-30T14:30:22.759304Z","iopub.status.idle":"2024-09-30T14:30:23.157978Z","shell.execute_reply.started":"2024-09-30T14:30:22.759268Z","shell.execute_reply":"2024-09-30T14:30:23.157001Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl\n/kaggle/input/torch_geometric-2.5.3-py3-none-any.whl\n/kaggle/input/torch_cluster-1.6.3-cp310-cp310-linux_x86_64.whl\n/kaggle/input/torch_spline_conv-1.2.2-cp310-cp310-linux_x86_64.whl\n/kaggle/input/torch_sparse-0.6.18-cp310-cp310-linux_x86_64.whl\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/rampasek/GraphGPS.git","metadata":{"execution":{"iopub.status.busy":"2024-09-30T14:30:23.381208Z","iopub.execute_input":"2024-09-30T14:30:23.381691Z","iopub.status.idle":"2024-09-30T14:30:25.708335Z","shell.execute_reply.started":"2024-09-30T14:30:23.381653Z","shell.execute_reply":"2024-09-30T14:30:25.707135Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'GraphGPS'...\nremote: Enumerating objects: 526, done.\u001b[K\nremote: Counting objects: 100% (350/350), done.\u001b[K\nremote: Compressing objects: 100% (109/109), done.\u001b[K\nremote: Total 526 (delta 271), reused 241 (delta 241), pack-reused 176 (from 1)\u001b[K\nReceiving objects: 100% (526/526), 12.93 MiB | 41.49 MiB/s, done.\nResolving deltas: 100% (337/337), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working/GraphGPS\n!ls ","metadata":{"execution":{"iopub.execute_input":"2024-09-26T06:41:42.555330Z","iopub.status.busy":"2024-09-26T06:41:42.554872Z","iopub.status.idle":"2024-09-26T06:41:43.554064Z","shell.execute_reply":"2024-09-26T06:41:43.553069Z","shell.execute_reply.started":"2024-09-26T06:41:42.555282Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","output_type":"stream","text":"/kaggle/working/GraphGPS\n\nGraphGPS.png  README.md  final-results.zip  main.py  setup.py  unittests\n\nLICENSE       configs\t graphgps\t    run      tests\n"}]},{"cell_type":"markdown","source":"##  installation for slurm if needed using conda ","metadata":{}},{"cell_type":"code","source":"# # for slurm if needed using conda \n# conda create -n graphgps python=3.10\n# conda activate graphgps\n\n# conda install pytorch=1.13 torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia\n# conda install pyg=2.2 -c pyg -c conda-forge\n# pip install pyg-lib -f https://data.pyg.org/whl/torch-1.13.0+cu117.html\n\n# # RDKit is required for OGB-LSC PCQM4Mv2 and datasets derived from it.  \n# conda install openbabel fsspec rdkit -c conda-forge\n\n# pip install pytorch-lightning yacs torchmetrics\n# pip install performer-pytorch\n# pip install tensorboardX\n# pip install ogb\n# pip install wandb\n\n# conda clean --all","metadata":{"execution":{"iopub.execute_input":"2024-09-26T06:41:44.581028Z","iopub.status.busy":"2024-09-26T06:41:44.580188Z","iopub.status.idle":"2024-09-26T06:41:44.585678Z","shell.execute_reply":"2024-09-26T06:41:44.584637Z","shell.execute_reply.started":"2024-09-26T06:41:44.580983Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# installation for kaggle","metadata":{}},{"cell_type":"code","source":"# Check existing environment\nimport sys\nprint(\"Python version:\", sys.version)\nimport torch\nprint(\"PyTorch version:\", torch.__version__)\nprint(\"CUDA available:\", torch.cuda.is_available())\nprint(\"CUDA version:\", torch.version.cuda)\n\n!pip uninstall -y torch torchvision torchaudio\n!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 --index-url https://download.pytorch.org/whl/cu118\n\n!pip install torch_geometric\n\n# Optional dependencies:\n!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cu124.html\n# Install other required packages\n!pip install pytorch-lightning yacs torchmetrics\n!pip install performer-pytorch\n!pip install tensorboardX\n!pip install ogb\n!pip install wandb\n\n# Attempt to install RDKit (may have limitations)\n!pip install rdkit-pypi\n# !pip install openbabel fsspec\n!pip install  fsspec\n\n# Clean up pip cache (optional)\n!pip cache purge\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T14:30:28.091638Z","iopub.execute_input":"2024-09-30T14:30:28.092143Z","iopub.status.idle":"2024-09-30T14:36:55.894050Z","shell.execute_reply.started":"2024-09-30T14:30:28.092100Z","shell.execute_reply":"2024-09-30T14:36:55.892774Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Python version: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]\nPyTorch version: 2.4.0\nCUDA available: True\nCUDA version: 12.3\nFound existing installation: torch 2.4.0\nUninstalling torch-2.4.0:\n  Successfully uninstalled torch-2.4.0\nFound existing installation: torchvision 0.19.0\nUninstalling torchvision-0.19.0:\n  Successfully uninstalled torchvision-0.19.0\nFound existing installation: torchaudio 2.4.0\nUninstalling torchaudio-2.4.0:\n  Successfully uninstalled torchaudio-2.4.0\nLooking in indexes: https://download.pytorch.org/whl/cu118\nCollecting torch==2.0.1+cu118\n  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp310-cp310-linux_x86_64.whl (2267.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m389.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchvision==0.15.2+cu118\n  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchaudio==2.0.2+cu118\n  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp310-cp310-linux_x86_64.whl (4.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1+cu118) (3.15.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1+cu118) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1+cu118) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1+cu118) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1+cu118) (3.1.4)\nCollecting triton==2.0.0 (from torch==2.0.1+cu118)\n  Downloading https://download.pytorch.org/whl/triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.15.2+cu118) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision==0.15.2+cu118) (2.32.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.15.2+cu118) (10.3.0)\nCollecting cmake (from triton==2.0.0->torch==2.0.1+cu118)\n  Downloading https://download.pytorch.org/whl/cmake-3.25.0-py2.py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting lit (from triton==2.0.0->torch==2.0.1+cu118)\n  Downloading https://download.pytorch.org/whl/lit-15.0.7.tar.gz (132 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.0.1+cu118) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.15.2+cu118) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.15.2+cu118) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.15.2+cu118) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.15.2+cu118) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.0.1+cu118) (1.3.0)\nBuilding wheels for collected packages: lit\n  Building wheel for lit (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for lit: filename=lit-15.0.7-py3-none-any.whl size=89987 sha256=d1ae9c5da5436bbd503c4f509803770dd690ab62169f12d57fa0cffa82d3d915\n  Stored in directory: /root/.cache/pip/wheels/27/2c/b6/3ed2983b1b44fe0dea1bb35234b09f2c22fb8ebb308679c922\nSuccessfully built lit\nInstalling collected packages: lit, cmake, triton, torch, torchvision, torchaudio\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npytorch-lightning 2.4.0 requires torch>=2.1.0, but you have torch 2.0.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cmake-3.25.0 lit-15.0.7 torch-2.0.1+cu118 torchaudio-2.0.2+cu118 torchvision-0.15.2+cu118 triton-2.0.0\nCollecting torch_geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.9.5)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (2024.6.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.1.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (5.9.3)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.1.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (4.66.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch_geometric) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (2024.8.30)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.6.1\nLooking in links: https://data.pyg.org/whl/torch-2.4.0+cu124.html\nCollecting pyg_lib\n  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu124/pyg_lib-0.4.0%2Bpt24cu124-cp310-cp310-linux_x86_64.whl (2.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting torch_scatter\n  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu124/torch_scatter-2.1.2%2Bpt24cu124-cp310-cp310-linux_x86_64.whl (10.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hCollecting torch_sparse\n  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu124/torch_sparse-0.6.18%2Bpt24cu124-cp310-cp310-linux_x86_64.whl (5.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torch_cluster\n  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu124/torch_cluster-1.6.3%2Bpt24cu124-cp310-cp310-linux_x86_64.whl (3.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torch_spline_conv\n  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu124/torch_spline_conv-1.2.2%2Bpt24cu124-cp310-cp310-linux_x86_64.whl (992 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m992.4/992.4 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch_sparse) (1.14.1)\nRequirement already satisfied: numpy<2.3,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from scipy->torch_sparse) (1.26.4)\nInstalling collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\nSuccessfully installed pyg_lib-0.4.0+pt24cu124 torch_cluster-1.6.3+pt24cu124 torch_scatter-2.1.2+pt24cu124 torch_sparse-0.6.18+pt24cu124 torch_spline_conv-1.2.2+pt24cu124\nRequirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (2.4.0)\nCollecting yacs\n  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\nRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (1.4.2)\nCollecting torch>=2.1.0 (from pytorch-lightning)\n  Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.66.4)\nRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (6.0.2)\nRequirement already satisfied: fsspec>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.6.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (21.3)\nRequirement already satisfied: typing-extensions>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.12.2)\nRequirement already satisfied: lightning-utilities>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (0.11.7)\nRequirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (1.26.4)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.5)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (70.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pytorch-lightning) (3.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (3.1.4)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.1.0->pytorch-lightning)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.1.0->pytorch-lightning)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.1.0->pytorch-lightning)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.0->pytorch-lightning)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.1.0->pytorch-lightning)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.1.0->pytorch-lightning)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.1.0->pytorch-lightning)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.1.0->pytorch-lightning)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.1.0->pytorch-lightning)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch>=2.1.0->pytorch-lightning)\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.1.0->pytorch-lightning)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==3.0.0 (from torch>=2.1.0->pytorch-lightning)\n  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.0->pytorch-lightning)\n  Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.1.0->pytorch-lightning) (1.3.0)\nRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.7)\nDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\nDownloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (797.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: yacs, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n  Attempting uninstall: triton\n    Found existing installation: triton 2.0.0\n    Uninstalling triton-2.0.0:\n      Successfully uninstalled triton-2.0.0\n  Attempting uninstall: torch\n    Found existing installation: torch 2.0.1+cu118\n    Uninstalling torch-2.0.1+cu118:\n      Successfully uninstalled torch-2.0.1+cu118\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 2.4.1 which is incompatible.\ntorchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 torch-2.4.1 triton-3.0.0 yacs-0.1.8\nCollecting performer-pytorch\n  Downloading performer_pytorch-1.1.4-py3-none-any.whl.metadata (763 bytes)\nCollecting einops>=0.3 (from performer-pytorch)\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nCollecting local-attention>=1.1.1 (from performer-pytorch)\n  Downloading local_attention-1.9.15-py3-none-any.whl.metadata (683 bytes)\nRequirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.10/site-packages (from performer-pytorch) (2.4.1)\nCollecting axial-positional-embedding>=0.1.0 (from performer-pytorch)\n  Downloading axial_positional_embedding-0.2.1.tar.gz (2.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->performer-pytorch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->performer-pytorch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->performer-pytorch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->performer-pytorch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->performer-pytorch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->performer-pytorch) (2024.6.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->performer-pytorch) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->performer-pytorch) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->performer-pytorch) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->performer-pytorch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->performer-pytorch) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->performer-pytorch) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->performer-pytorch) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->performer-pytorch) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->performer-pytorch) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->performer-pytorch) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->performer-pytorch) (12.1.105)\nRequirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->performer-pytorch) (3.0.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6->performer-pytorch) (12.6.68)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6->performer-pytorch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6->performer-pytorch) (1.3.0)\nDownloading performer_pytorch-1.1.4-py3-none-any.whl (13 kB)\nDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading local_attention-1.9.15-py3-none-any.whl (9.0 kB)\nBuilding wheels for collected packages: axial-positional-embedding\n  Building wheel for axial-positional-embedding (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for axial-positional-embedding: filename=axial_positional_embedding-0.2.1-py3-none-any.whl size=2889 sha256=75becaa9a868f47efdb3115d7443f3518a17922ae47c9c29b0c10a545a6ba1cb\n  Stored in directory: /root/.cache/pip/wheels/b1/cb/39/7ce7ff2d2fd37cfe1fe7b3a3c43cf410632b2ad3b3f3986d73\nSuccessfully built axial-positional-embedding\nInstalling collected packages: einops, local-attention, axial-positional-embedding, performer-pytorch\nSuccessfully installed axial-positional-embedding-0.2.1 einops-0.8.0 local-attention-1.9.15 performer-pytorch-1.1.4\nRequirement already satisfied: tensorboardX in /opt/conda/lib/python3.10/site-packages (2.6.2.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tensorboardX) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorboardX) (21.3)\nRequirement already satisfied: protobuf>=3.20 in /opt/conda/lib/python3.10/site-packages (from tensorboardX) (3.20.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorboardX) (3.1.2)\nCollecting ogb\n  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from ogb) (2.4.1)\nRequirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from ogb) (1.26.4)\nRequirement already satisfied: tqdm>=4.29.0 in /opt/conda/lib/python3.10/site-packages (from ogb) (4.66.4)\nRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from ogb) (1.2.2)\nRequirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from ogb) (2.2.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from ogb) (1.16.0)\nRequirement already satisfied: urllib3>=1.24.0 in /opt/conda/lib/python3.10/site-packages (from ogb) (1.26.18)\nCollecting outdated>=0.2.0 (from ogb)\n  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: setuptools>=44 in /opt/conda/lib/python3.10/site-packages (from outdated>=0.2.0->ogb) (70.0.0)\nCollecting littleutils (from outdated>=0.2.0->ogb)\n  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from outdated>=0.2.0->ogb) (2.32.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.0->ogb) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.0->ogb) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.0->ogb) (2024.1)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->ogb) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->ogb) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->ogb) (3.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (2024.6.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (12.1.105)\nRequirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (3.0.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->ogb) (12.6.68)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->ogb) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb) (3.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\nDownloading ogb-1.3.6-py3-none-any.whl (78 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\nDownloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\nInstalling collected packages: littleutils, outdated, ogb\nSuccessfully installed littleutils-0.2.4 ogb-1.3.6 outdated-0.2.2\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.18.1)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.14.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (70.0.0)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nCollecting rdkit-pypi\n  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rdkit-pypi) (1.26.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from rdkit-pypi) (10.3.0)\nDownloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rdkit-pypi\nSuccessfully installed rdkit-pypi-2022.9.5\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (2024.6.1)\nFiles removed: 184\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\nprint(\"Python version:\", sys.version)\nimport torch\nprint(\"PyTorch version:\", torch.__version__)\nprint(\"CUDA available:\", torch.cuda.is_available())\nprint(\"CUDA version:\", torch.version.cuda)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T14:36:55.897216Z","iopub.execute_input":"2024-09-30T14:36:55.898162Z","iopub.status.idle":"2024-09-30T14:36:55.905541Z","shell.execute_reply.started":"2024-09-30T14:36:55.898121Z","shell.execute_reply":"2024-09-30T14:36:55.904393Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Python version: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]\nPyTorch version: 2.4.0\nCUDA available: True\nCUDA version: 12.3\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch_geometric\nprint(\"PyG version:\", torch_geometric.__version__)\n\nimport pytorch_lightning\nprint(\"PyTorch Lightning version:\", pytorch_lightning.__version__)\n\nimport rdkit\nprint(\"RDKit version:\", rdkit.__version__)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T14:36:55.907619Z","iopub.execute_input":"2024-09-30T14:36:55.908419Z","iopub.status.idle":"2024-09-30T14:37:01.153825Z","shell.execute_reply.started":"2024-09-30T14:36:55.908372Z","shell.execute_reply":"2024-09-30T14:37:01.152760Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /opt/conda/lib/python3.10/site-packages/libpyg.so: undefined symbol: _ZNK5torch8autograd4Node4nameEv\n  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n/opt/conda/lib/python3.10/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /opt/conda/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n/opt/conda/lib/python3.10/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /opt/conda/lib/python3.10/site-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n/opt/conda/lib/python3.10/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /opt/conda/lib/python3.10/site-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /opt/conda/lib/python3.10/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n","output_type":"stream"},{"name":"stdout","text":"PyG version: 2.6.1\nPyTorch Lightning version: 2.4.0\nRDKit version: 2022.09.5\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Torch version:\", torch.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T14:37:01.155819Z","iopub.execute_input":"2024-09-30T14:37:01.156295Z","iopub.status.idle":"2024-09-30T14:37:01.161860Z","shell.execute_reply.started":"2024-09-30T14:37:01.156261Z","shell.execute_reply":"2024-09-30T14:37:01.160777Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Torch version: 2.4.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Running their model- GPSConv","metadata":{}},{"cell_type":"code","source":"# %cd /kaggle/working/GraphGPS\n# !WANDB_MODE=disabled python main.py --cfg configs/GPS/ogbg-molhiv-GPS.yaml","metadata":{"execution":{"iopub.execute_input":"2024-09-26T06:48:24.761920Z","iopub.status.busy":"2024-09-26T06:48:24.761166Z","iopub.status.idle":"2024-09-26T06:48:24.859840Z","shell.execute_reply":"2024-09-26T06:48:24.859080Z","shell.execute_reply.started":"2024-09-26T06:48:24.761866Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Our Model - WeightedGraphGPS","metadata":{}},{"cell_type":"code","source":"rm -rf /kaggle/working/WeightedGraphGPS","metadata":{"execution":{"iopub.status.busy":"2024-09-30T14:48:56.446884Z","iopub.execute_input":"2024-09-30T14:48:56.447377Z","iopub.status.idle":"2024-09-30T14:48:57.555035Z","shell.execute_reply.started":"2024-09-30T14:48:56.447336Z","shell.execute_reply":"2024-09-30T14:48:57.553760Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#clone for our project\n%cd /kaggle/working\n!git clone --branch add_dropout https://github.com/omertalmi5/WeightedGraphGPS.git","metadata":{"execution":{"iopub.status.busy":"2024-09-30T14:48:57.557592Z","iopub.execute_input":"2024-09-30T14:48:57.558141Z","iopub.status.idle":"2024-09-30T14:48:59.746055Z","shell.execute_reply.started":"2024-09-30T14:48:57.558088Z","shell.execute_reply":"2024-09-30T14:48:59.744758Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"/kaggle/working\nCloning into 'WeightedGraphGPS'...\nremote: Enumerating objects: 770, done.\u001b[K\nremote: Counting objects: 100% (525/525), done.\u001b[K\nremote: Compressing objects: 100% (177/177), done.\u001b[K\nremote: Total 770 (delta 436), reused 348 (delta 348), pack-reused 245 (from 1)\u001b[K\nReceiving objects: 100% (770/770), 13.04 MiB | 37.00 MiB/s, done.\nResolving deltas: 100% (525/525), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install wandb","metadata":{"execution":{"iopub.status.busy":"2024-09-30T14:50:26.940821Z","iopub.execute_input":"2024-09-30T14:50:26.941312Z","iopub.status.idle":"2024-09-30T14:50:39.652101Z","shell.execute_reply.started":"2024-09-30T14:50:26.941266Z","shell.execute_reply":"2024-09-30T14:50:39.650907Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.18.1)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.14.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (70.0.0)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"!wandb login 5f1c292fde40243d281618fe88d712346cfe90d7","metadata":{"execution":{"iopub.status.busy":"2024-09-30T14:50:39.654305Z","iopub.execute_input":"2024-09-30T14:50:39.654675Z","iopub.status.idle":"2024-09-30T14:50:43.363938Z","shell.execute_reply.started":"2024-09-30T14:50:39.654640Z","shell.execute_reply":"2024-09-30T14:50:43.362591Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n# Set the environment variable\nos.environ['USERNAME'] = \"omertalmi-tel-aviv-university\"","metadata":{"execution":{"iopub.status.busy":"2024-09-30T14:50:43.365689Z","iopub.execute_input":"2024-09-30T14:50:43.366125Z","iopub.status.idle":"2024-09-30T14:50:43.372635Z","shell.execute_reply.started":"2024-09-30T14:50:43.366077Z","shell.execute_reply":"2024-09-30T14:50:43.371477Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/WeightedGraphGPS\nos.environ['BRANCH_NAME']= os.popen('git rev-parse --abbrev-ref HEAD').read().strip()\n!WANDB_MODE=online python main.py --cfg configs/GPS/ogbg-molhiv-GPS.yaml wandb.use True wandb.entity $USERNAME wandb.name $BRANCH_NAME","metadata":{"execution":{"iopub.status.busy":"2024-09-30T14:50:43.374835Z","iopub.execute_input":"2024-09-30T14:50:43.375132Z","iopub.status.idle":"2024-09-30T18:25:03.429388Z","shell.execute_reply.started":"2024-09-30T14:50:43.375101Z","shell.execute_reply":"2024-09-30T18:25:03.428135Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"/kaggle/working/WeightedGraphGPS\n[*] Run ID 0: seed=0, split_index=0\n    Starting now: 2024-09-30 14:51:01.782098\nDownloading http://snap.stanford.edu/ogb/data/graphproppred/csv_mol_download/hiv.zip\nDownloaded 0.00 GB: 100%|█████████████████████████| 3/3 [00:00<00:00,  6.89it/s]\nExtracting ./datasets/hiv.zip\nProcessing...\nLoading necessary files...\nThis might take a while.\nProcessing graphs...\n100%|██████████████████████████████████| 41127/41127 [00:00<00:00, 57569.12it/s]\nConverting graphs into PyG objects...\n100%|██████████████████████████████████| 41127/41127 [00:02<00:00, 17396.31it/s]\nSaving...\nDone!\n/opt/conda/lib/python3.10/site-packages/ogb/graphproppred/dataset_pyg.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.data, self.slices = torch.load(self.processed_paths[0])\n[*] Loaded dataset 'ogbg-molhiv' from 'OGB':\n/opt/conda/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n  warnings.warn(msg)\n  Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)\n  undirected: True\n  num graphs: 41127\n/opt/conda/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n  warnings.warn(msg)\n  avg num_nodes/graph: 25\n  num node features: 9\n  num edge features: 3\n  num tasks: 1\n  num classes: 2\nPrecomputing Positional Encoding statistics: ['LapPE'] for all graphs...\n  ...estimated to be undirected: True\n100%|████████████████████████████████████| 41127/41127 [00:56<00:00, 724.18it/s]\nDone! Took 00:00:58.44\nGraphGymModule(\n  (model): GPSModel(\n    (encoder): FeatureEncoder(\n      (node_encoder): Concat2NodeEncoder(\n        (encoder1): AtomEncoder(\n          (atom_embedding_list): ModuleList(\n            (0): Embedding(119, 56)\n            (1): Embedding(5, 56)\n            (2-3): 2 x Embedding(12, 56)\n            (4): Embedding(10, 56)\n            (5-6): 2 x Embedding(6, 56)\n            (7-8): 2 x Embedding(2, 56)\n          )\n        )\n        (encoder2): LapPENodeEncoder(\n          (linear_A): Linear(in_features=2, out_features=16, bias=True)\n          (pe_encoder): Sequential(\n            (0): ReLU()\n            (1): Linear(in_features=16, out_features=8, bias=True)\n            (2): ReLU()\n          )\n        )\n      )\n      (edge_encoder): BondEncoder(\n        (bond_embedding_list): ModuleList(\n          (0): Embedding(5, 64)\n          (1): Embedding(6, 64)\n          (2): Embedding(2, 64)\n        )\n      )\n    )\n    (layers): Sequential(\n      (0): GPSLayer(\n        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n        (gating_conv1): GCNConv(64, 32)\n        (gating_relu): ReLU()\n        (gating_dropout): Dropout(p=0.05, inplace=False)\n        (gating_conv2): GCNConv(32, 2)\n        (gating_softmax): Softmax(dim=1)\n        (local_model): GatedGCNLayer()\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n        )\n        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (dropout_local): Dropout(p=0.05, inplace=False)\n        (dropout_attn): Dropout(p=0.05, inplace=False)\n        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n        (act_fn_ff): ReLU()\n        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (ff_dropout1): Dropout(p=0.05, inplace=False)\n        (ff_dropout2): Dropout(p=0.05, inplace=False)\n      )\n      (1): GPSLayer(\n        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n        (gating_conv1): GCNConv(64, 32)\n        (gating_relu): ReLU()\n        (gating_dropout): Dropout(p=0.05, inplace=False)\n        (gating_conv2): GCNConv(32, 2)\n        (gating_softmax): Softmax(dim=1)\n        (local_model): GatedGCNLayer()\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n        )\n        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (dropout_local): Dropout(p=0.05, inplace=False)\n        (dropout_attn): Dropout(p=0.05, inplace=False)\n        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n        (act_fn_ff): ReLU()\n        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (ff_dropout1): Dropout(p=0.05, inplace=False)\n        (ff_dropout2): Dropout(p=0.05, inplace=False)\n      )\n      (2): GPSLayer(\n        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n        (gating_conv1): GCNConv(64, 32)\n        (gating_relu): ReLU()\n        (gating_dropout): Dropout(p=0.05, inplace=False)\n        (gating_conv2): GCNConv(32, 2)\n        (gating_softmax): Softmax(dim=1)\n        (local_model): GatedGCNLayer()\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n        )\n        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (dropout_local): Dropout(p=0.05, inplace=False)\n        (dropout_attn): Dropout(p=0.05, inplace=False)\n        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n        (act_fn_ff): ReLU()\n        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (ff_dropout1): Dropout(p=0.05, inplace=False)\n        (ff_dropout2): Dropout(p=0.05, inplace=False)\n      )\n      (3): GPSLayer(\n        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n        (gating_conv1): GCNConv(64, 32)\n        (gating_relu): ReLU()\n        (gating_dropout): Dropout(p=0.05, inplace=False)\n        (gating_conv2): GCNConv(32, 2)\n        (gating_softmax): Softmax(dim=1)\n        (local_model): GatedGCNLayer()\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n        )\n        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (dropout_local): Dropout(p=0.05, inplace=False)\n        (dropout_attn): Dropout(p=0.05, inplace=False)\n        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n        (act_fn_ff): ReLU()\n        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (ff_dropout1): Dropout(p=0.05, inplace=False)\n        (ff_dropout2): Dropout(p=0.05, inplace=False)\n      )\n      (4): GPSLayer(\n        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n        (gating_conv1): GCNConv(64, 32)\n        (gating_relu): ReLU()\n        (gating_dropout): Dropout(p=0.05, inplace=False)\n        (gating_conv2): GCNConv(32, 2)\n        (gating_softmax): Softmax(dim=1)\n        (local_model): GatedGCNLayer()\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n        )\n        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (dropout_local): Dropout(p=0.05, inplace=False)\n        (dropout_attn): Dropout(p=0.05, inplace=False)\n        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n        (act_fn_ff): ReLU()\n        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (ff_dropout1): Dropout(p=0.05, inplace=False)\n        (ff_dropout2): Dropout(p=0.05, inplace=False)\n      )\n      (5): GPSLayer(\n        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n        (gating_conv1): GCNConv(64, 32)\n        (gating_relu): ReLU()\n        (gating_dropout): Dropout(p=0.05, inplace=False)\n        (gating_conv2): GCNConv(32, 2)\n        (gating_softmax): Softmax(dim=1)\n        (local_model): GatedGCNLayer()\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n        )\n        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (dropout_local): Dropout(p=0.05, inplace=False)\n        (dropout_attn): Dropout(p=0.05, inplace=False)\n        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n        (act_fn_ff): ReLU()\n        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (ff_dropout1): Dropout(p=0.05, inplace=False)\n        (ff_dropout2): Dropout(p=0.05, inplace=False)\n      )\n      (6): GPSLayer(\n        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n        (gating_conv1): GCNConv(64, 32)\n        (gating_relu): ReLU()\n        (gating_dropout): Dropout(p=0.05, inplace=False)\n        (gating_conv2): GCNConv(32, 2)\n        (gating_softmax): Softmax(dim=1)\n        (local_model): GatedGCNLayer()\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n        )\n        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (dropout_local): Dropout(p=0.05, inplace=False)\n        (dropout_attn): Dropout(p=0.05, inplace=False)\n        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n        (act_fn_ff): ReLU()\n        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (ff_dropout1): Dropout(p=0.05, inplace=False)\n        (ff_dropout2): Dropout(p=0.05, inplace=False)\n      )\n      (7): GPSLayer(\n        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n        (gating_conv1): GCNConv(64, 32)\n        (gating_relu): ReLU()\n        (gating_dropout): Dropout(p=0.05, inplace=False)\n        (gating_conv2): GCNConv(32, 2)\n        (gating_softmax): Softmax(dim=1)\n        (local_model): GatedGCNLayer()\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n        )\n        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (dropout_local): Dropout(p=0.05, inplace=False)\n        (dropout_attn): Dropout(p=0.05, inplace=False)\n        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n        (act_fn_ff): ReLU()\n        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (ff_dropout1): Dropout(p=0.05, inplace=False)\n        (ff_dropout2): Dropout(p=0.05, inplace=False)\n      )\n      (8): GPSLayer(\n        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n        (gating_conv1): GCNConv(64, 32)\n        (gating_relu): ReLU()\n        (gating_dropout): Dropout(p=0.05, inplace=False)\n        (gating_conv2): GCNConv(32, 2)\n        (gating_softmax): Softmax(dim=1)\n        (local_model): GatedGCNLayer()\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n        )\n        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (dropout_local): Dropout(p=0.05, inplace=False)\n        (dropout_attn): Dropout(p=0.05, inplace=False)\n        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n        (act_fn_ff): ReLU()\n        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (ff_dropout1): Dropout(p=0.05, inplace=False)\n        (ff_dropout2): Dropout(p=0.05, inplace=False)\n      )\n      (9): GPSLayer(\n        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n        (gating_conv1): GCNConv(64, 32)\n        (gating_relu): ReLU()\n        (gating_dropout): Dropout(p=0.05, inplace=False)\n        (gating_conv2): GCNConv(32, 2)\n        (gating_softmax): Softmax(dim=1)\n        (local_model): GatedGCNLayer()\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n        )\n        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (dropout_local): Dropout(p=0.05, inplace=False)\n        (dropout_attn): Dropout(p=0.05, inplace=False)\n        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n        (act_fn_ff): ReLU()\n        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (ff_dropout1): Dropout(p=0.05, inplace=False)\n        (ff_dropout2): Dropout(p=0.05, inplace=False)\n      )\n    )\n    (post_mp): SANGraphHead(\n      (FC_layers): ModuleList(\n        (0): Linear(in_features=64, out_features=32, bias=True)\n        (1): Linear(in_features=32, out_features=16, bias=True)\n        (2): Linear(in_features=16, out_features=1, bias=True)\n      )\n      (activation): ReLU()\n    )\n  )\n)\naccelerator: cuda\nbenchmark: False\nbn:\n  eps: 1e-05\n  mom: 0.1\ncfg_dest: config.yaml\ncustom_metrics: []\ndataset:\n  cache_load: False\n  cache_save: False\n  dir: ./datasets\n  edge_dim: 128\n  edge_encoder: True\n  edge_encoder_bn: False\n  edge_encoder_name: Bond\n  edge_encoder_num_types: 0\n  edge_message_ratio: 0.8\n  edge_negative_sampling_ratio: 1.0\n  edge_train_mode: all\n  encoder: True\n  encoder_bn: True\n  encoder_dim: 128\n  encoder_name: db\n  format: OGB\n  infer_link_label: None\n  label_column: none\n  label_table: none\n  location: local\n  name: ogbg-molhiv\n  node_encoder: True\n  node_encoder_bn: False\n  node_encoder_name: Atom+LapPE\n  node_encoder_num_types: 0\n  remove_feature: False\n  resample_disjoint: False\n  resample_negative: False\n  shuffle_split: True\n  slic_compactness: 10\n  split: [0.8, 0.1, 0.1]\n  split_dir: ./splits\n  split_index: 0\n  split_mode: standard\n  task: graph\n  task_type: classification\n  to_undirected: False\n  transductive: False\n  transform: none\n  tu_simple: True\ndevices: 1\nexample_arg: example\nexample_group:\n  example_arg: example\ngnn:\n  act: relu\n  agg: mean\n  att_final_linear: False\n  att_final_linear_bn: False\n  att_heads: 1\n  batchnorm: True\n  clear_feature: True\n  dim_edge: 64\n  dim_inner: 64\n  dropout: 0.0\n  head: san_graph\n  keep_edge: 0.5\n  l2norm: True\n  layer_type: generalconv\n  layers_mp: 2\n  layers_post_mp: 3\n  layers_pre_mp: 0\n  msg_direction: single\n  normalize_adj: False\n  residual: False\n  self_msg: concat\n  skip_every: 1\n  stage_type: stack\ngpu_mem: False\ngraphormer:\n  attention_dropout: 0.0\n  dropout: 0.0\n  embed_dim: 80\n  input_dropout: 0.0\n  mlp_dropout: 0.0\n  num_heads: 4\n  num_layers: 6\n  use_graph_token: True\ngt:\n  attn_dropout: 0.5\n  batch_norm: True\n  bigbird:\n    add_cross_attention: False\n    attention_type: block_sparse\n    block_size: 3\n    chunk_size_feed_forward: 0\n    hidden_act: relu\n    is_decoder: False\n    layer_norm_eps: 1e-06\n    max_position_embeddings: 128\n    num_random_blocks: 3\n    use_bias: False\n  dim_hidden: 64\n  dropout: 0.05\n  full_graph: True\n  gamma: 1e-05\n  layer_norm: False\n  layer_type: CustomGatedGCN+Transformer\n  layers: 10\n  n_heads: 4\n  pna_degrees: []\n  residual: True\nmem:\n  inplace: False\nmetric_agg: argmax\nmetric_best: auc\nmodel:\n  edge_decoding: dot\n  graph_pooling: mean\n  loss_fun: cross_entropy\n  match_upper: True\n  size_average: mean\n  thresh: 0.5\n  type: GPSModel\nname_tag: \nnum_threads: 6\nnum_workers: 0\noptim:\n  base_lr: 0.0001\n  batch_accumulation: 1\n  clip_grad_norm: True\n  clip_grad_norm_value: 1.0\n  lr_decay: 0.1\n  max_epoch: 100\n  min_lr: 0.0\n  momentum: 0.9\n  num_warmup_epochs: 5\n  optimizer: adamW\n  reduce_factor: 0.1\n  schedule_patience: 10\n  scheduler: cosine_with_warmup\n  steps: [30, 60, 90]\n  weight_decay: 1e-05\nout_dir: results/ogbg-molhiv-GPS\nposenc_ElstaticSE:\n  dim_pe: 16\n  enable: False\n  kernel:\n    times: []\n    times_func: range(10)\n  layers: 3\n  model: none\n  n_heads: 4\n  pass_as_var: False\n  post_layers: 0\n  raw_norm_type: none\nposenc_EquivStableLapPE:\n  eigen:\n    eigvec_norm: L2\n    laplacian_norm: sym\n    max_freqs: 10\n  enable: False\n  raw_norm_type: none\nposenc_GraphormerBias:\n  dim_pe: 0\n  enable: False\n  node_degrees_only: False\n  num_in_degrees: None\n  num_out_degrees: None\n  num_spatial_types: None\nposenc_HKdiagSE:\n  dim_pe: 16\n  enable: False\n  kernel:\n    times: []\n    times_func: \n  layers: 3\n  model: none\n  n_heads: 4\n  pass_as_var: False\n  post_layers: 0\n  raw_norm_type: none\nposenc_LapPE:\n  dim_pe: 8\n  eigen:\n    eigvec_norm: L2\n    laplacian_norm: none\n    max_freqs: 8\n  enable: True\n  layers: 2\n  model: DeepSet\n  n_heads: 4\n  pass_as_var: False\n  post_layers: 0\n  raw_norm_type: none\nposenc_RWSE:\n  dim_pe: 16\n  enable: False\n  kernel:\n    times: []\n    times_func: \n  layers: 3\n  model: none\n  n_heads: 4\n  pass_as_var: False\n  post_layers: 0\n  raw_norm_type: none\nposenc_SignNet:\n  dim_pe: 16\n  eigen:\n    eigvec_norm: L2\n    laplacian_norm: sym\n    max_freqs: 10\n  enable: False\n  layers: 3\n  model: none\n  n_heads: 4\n  pass_as_var: False\n  phi_hidden_dim: 64\n  phi_out_dim: 4\n  post_layers: 0\n  raw_norm_type: none\npretrained:\n  dir: \n  freeze_main: False\n  reset_prediction_head: True\nprint: both\nround: 5\nrun_dir: results/ogbg-molhiv-GPS/0\nrun_id: 0\nrun_multiple_splits: []\nseed: 0\nshare:\n  dim_in: 9\n  dim_out: 2\n  num_splits: 3\ntensorboard_agg: True\ntensorboard_each_run: False\ntrain:\n  auto_resume: False\n  batch_size: 32\n  ckpt_best: False\n  ckpt_clean: True\n  ckpt_period: 100\n  enable_ckpt: True\n  epoch_resume: -1\n  eval_period: 1\n  iter_per_epoch: 32\n  mode: custom\n  neighbor_sizes: [20, 15, 10, 5]\n  node_per_graph: 32\n  radius: extend\n  sample_node: False\n  sampler: full_batch\n  skip_train_eval: False\n  walk_length: 4\nval:\n  node_per_graph: 32\n  radius: extend\n  sample_node: False\n  sampler: full_batch\nview_emb: False\nwandb:\n  entity: omertalmi-tel-aviv-university\n  name: add_dropout\n  project: molhiv\n  use: True\nNum parameters: 581405\nStart from epoch 0\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33momertalmi-\u001b[0m (\u001b[33momertalmi-tel-aviv-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.1\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/WeightedGraphGPS/wandb/run-20240930_145216-yxy7k6ky\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33madd_dropout\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/omertalmi-tel-aviv-university/molhiv\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/omertalmi-tel-aviv-university/molhiv/runs/yxy7k6ky\u001b[0m\nKey posenc_GraphormerBias.num_spatial_types with value <class 'NoneType'> is not a valid type; valid types: {<class 'list'>, <class 'str'>, <class 'bool'>, <class 'tuple'>, <class 'int'>, <class 'float'>}\nKey posenc_GraphormerBias.num_in_degrees with value <class 'NoneType'> is not a valid type; valid types: {<class 'list'>, <class 'str'>, <class 'bool'>, <class 'tuple'>, <class 'int'>, <class 'float'>}\nKey posenc_GraphormerBias.num_out_degrees with value <class 'NoneType'> is not a valid type; valid types: {<class 'list'>, <class 'str'>, <class 'bool'>, <class 'tuple'>, <class 'int'>, <class 'float'>}\ntrain: {'epoch': 0, 'time_epoch': 121.88946, 'eta': 12067.05669, 'eta_hours': 3.35196, 'loss': 0.85384444, 'lr': 0.0, 'params': 581405, 'time_iter': 0.11845, 'accuracy': 0.03745, 'precision': 0.03745, 'recall': 1.0, 'f1': 0.07219, 'auc': 0.50989}\n...computing epoch stats took: 0.10s\nval: {'epoch': 0, 'time_epoch': 7.76132, 'loss': 0.86103111, 'lr': 0, 'params': 581405, 'time_iter': 0.06017, 'accuracy': 0.01969, 'precision': 0.01969, 'recall': 1.0, 'f1': 0.03863, 'auc': 0.62384}\n...computing epoch stats took: 0.01s\ntest: {'epoch': 0, 'time_epoch': 7.38083, 'loss': 0.8529153, 'lr': 0, 'params': 581405, 'time_iter': 0.05722, 'accuracy': 0.03161, 'precision': 0.03161, 'recall': 1.0, 'f1': 0.06128, 'auc': 0.65226}\n...computing epoch stats took: 0.01s\n> Epoch 0: took 137.2s (avg 137.2s) | Best so far: epoch 0\ttrain_loss: 0.8538 train_auc: 0.5099\tval_loss: 0.8610 val_auc: 0.6238\ttest_loss: 0.8529 test_auc: 0.6523\ntrain: {'epoch': 1, 'time_epoch': 115.79491, 'eta': 11646.53404, 'eta_hours': 3.23515, 'loss': 0.5050113, 'lr': 2e-05, 'params': 581405, 'time_iter': 0.11253, 'accuracy': 0.71943, 'precision': 0.04087, 'recall': 0.28896, 'f1': 0.07161, 'auc': 0.54534}\n...computing epoch stats took: 0.08s\nval: {'epoch': 1, 'time_epoch': 6.47836, 'loss': 0.24148506, 'lr': 0, 'params': 581405, 'time_iter': 0.05022, 'accuracy': 0.98079, 'precision': 1.0, 'recall': 0.02469, 'f1': 0.04819, 'auc': 0.66401}\n...computing epoch stats took: 0.02s\ntest: {'epoch': 1, 'time_epoch': 6.46687, 'loss': 0.23648967, 'lr': 0, 'params': 581405, 'time_iter': 0.05013, 'accuracy': 0.96888, 'precision': 1.0, 'recall': 0.01538, 'f1': 0.0303, 'auc': 0.7215}\n...computing epoch stats took: 0.02s\n> Epoch 1: took 128.9s (avg 133.0s) | Best so far: epoch 1\ttrain_loss: 0.5050 train_auc: 0.5453\tval_loss: 0.2415 val_auc: 0.6640\ttest_loss: 0.2365 test_auc: 0.7215\ntrain: {'epoch': 2, 'time_epoch': 115.8599, 'eta': 11431.26471, 'eta_hours': 3.17535, 'loss': 0.16699864, 'lr': 4e-05, 'params': 581405, 'time_iter': 0.11259, 'accuracy': 0.96265, 'precision': 0.63636, 'recall': 0.00568, 'f1': 0.01126, 'auc': 0.66343}\n...computing epoch stats took: 0.08s\nval: {'epoch': 2, 'time_epoch': 6.55829, 'loss': 0.09924621, 'lr': 0, 'params': 581405, 'time_iter': 0.05084, 'accuracy': 0.98128, 'precision': 0.66667, 'recall': 0.09877, 'f1': 0.17204, 'auc': 0.74462}\n...computing epoch stats took: 0.02s\ntest: {'epoch': 2, 'time_epoch': 6.41044, 'loss': 0.12809743, 'lr': 0, 'params': 581405, 'time_iter': 0.04969, 'accuracy': 0.97058, 'precision': 0.84615, 'recall': 0.08462, 'f1': 0.15385, 'auc': 0.72735}\n...computing epoch stats took: 0.02s\n> Epoch 2: took 129.0s (avg 131.7s) | Best so far: epoch 2\ttrain_loss: 0.1670 train_auc: 0.6634\tval_loss: 0.0992 val_auc: 0.7446\ttest_loss: 0.1281 test_auc: 0.7274\ntrain: {'epoch': 3, 'time_epoch': 116.17211, 'eta': 11273.19312, 'eta_hours': 3.13144, 'loss': 0.139372, 'lr': 6e-05, 'params': 581405, 'time_iter': 0.1129, 'accuracy': 0.96389, 'precision': 0.66667, 'recall': 0.07143, 'f1': 0.12903, 'auc': 0.71846}\nval: {'epoch': 3, 'time_epoch': 6.54145, 'loss': 0.08600475, 'lr': 0, 'params': 581405, 'time_iter': 0.05071, 'accuracy': 0.98128, 'precision': 0.625, 'recall': 0.12346, 'f1': 0.20619, 'auc': 0.75792}\ntest: {'epoch': 3, 'time_epoch': 6.91942, 'loss': 0.12333712, 'lr': 0, 'params': 581405, 'time_iter': 0.05364, 'accuracy': 0.96985, 'precision': 0.65, 'recall': 0.1, 'f1': 0.17333, 'auc': 0.70007}\n> Epoch 3: took 129.8s (avg 131.2s) | Best so far: epoch 3\ttrain_loss: 0.1394 train_auc: 0.7185\tval_loss: 0.0860 val_auc: 0.7579\ttest_loss: 0.1233 test_auc: 0.7001\ntrain: {'epoch': 4, 'time_epoch': 116.36109, 'eta': 11135.4719, 'eta_hours': 3.09319, 'loss': 0.13500765, 'lr': 8e-05, 'params': 581405, 'time_iter': 0.11308, 'accuracy': 0.96429, 'precision': 0.61925, 'recall': 0.12013, 'f1': 0.20122, 'auc': 0.74485}\nval: {'epoch': 4, 'time_epoch': 6.48323, 'loss': 0.07995495, 'lr': 0, 'params': 581405, 'time_iter': 0.05026, 'accuracy': 0.98104, 'precision': 0.66667, 'recall': 0.07407, 'f1': 0.13333, 'auc': 0.80793}\ntest: {'epoch': 4, 'time_epoch': 6.42454, 'loss': 0.1259095, 'lr': 0, 'params': 581405, 'time_iter': 0.0498, 'accuracy': 0.96742, 'precision': 0.35714, 'recall': 0.03846, 'f1': 0.06944, 'auc': 0.72542}\n> Epoch 4: took 129.4s (avg 130.9s) | Best so far: epoch 4\ttrain_loss: 0.1350 train_auc: 0.7449\tval_loss: 0.0800 val_auc: 0.8079\ttest_loss: 0.1259 test_auc: 0.7254\ntrain: {'epoch': 5, 'time_epoch': 116.17004, 'eta': 11001.87757, 'eta_hours': 3.05608, 'loss': 0.12976649, 'lr': 0.0001, 'params': 581405, 'time_iter': 0.1129, 'accuracy': 0.96511, 'precision': 0.64483, 'recall': 0.15179, 'f1': 0.24573, 'auc': 0.77209}\nval: {'epoch': 5, 'time_epoch': 6.39476, 'loss': 0.080483, 'lr': 0, 'params': 581405, 'time_iter': 0.04957, 'accuracy': 0.98152, 'precision': 0.59259, 'recall': 0.19753, 'f1': 0.2963, 'auc': 0.78356}\ntest: {'epoch': 5, 'time_epoch': 6.40437, 'loss': 0.11693475, 'lr': 0, 'params': 581405, 'time_iter': 0.04965, 'accuracy': 0.97155, 'precision': 0.63265, 'recall': 0.23846, 'f1': 0.34637, 'auc': 0.71979}\n> Epoch 5: took 129.1s (avg 130.6s) | Best so far: epoch 4\ttrain_loss: 0.1350 train_auc: 0.7449\tval_loss: 0.0800 val_auc: 0.8079\ttest_loss: 0.1259 test_auc: 0.7254\ntrain: {'epoch': 6, 'time_epoch': 116.19822, 'eta': 10873.63607, 'eta_hours': 3.02045, 'loss': 0.1258253, 'lr': 9.997e-05, 'params': 581405, 'time_iter': 0.11292, 'accuracy': 0.96581, 'precision': 0.65782, 'recall': 0.18101, 'f1': 0.2839, 'auc': 0.78837}\nval: {'epoch': 6, 'time_epoch': 6.43256, 'loss': 0.07536073, 'lr': 0, 'params': 581405, 'time_iter': 0.04986, 'accuracy': 0.98079, 'precision': 0.53125, 'recall': 0.20988, 'f1': 0.30088, 'auc': 0.81592}\ntest: {'epoch': 6, 'time_epoch': 6.39683, 'loss': 0.11449268, 'lr': 0, 'params': 581405, 'time_iter': 0.04959, 'accuracy': 0.97204, 'precision': 0.69231, 'recall': 0.20769, 'f1': 0.31953, 'auc': 0.75601}\n> Epoch 6: took 129.2s (avg 130.4s) | Best so far: epoch 6\ttrain_loss: 0.1258 train_auc: 0.7884\tval_loss: 0.0754 val_auc: 0.8159\ttest_loss: 0.1145 test_auc: 0.7560\ntrain: {'epoch': 7, 'time_epoch': 116.14064, 'eta': 10747.74317, 'eta_hours': 2.98548, 'loss': 0.12238253, 'lr': 9.989e-05, 'params': 581405, 'time_iter': 0.11287, 'accuracy': 0.96635, 'precision': 0.65586, 'recall': 0.21347, 'f1': 0.32211, 'auc': 0.80127}\nval: {'epoch': 7, 'time_epoch': 6.44975, 'loss': 0.07548382, 'lr': 0, 'params': 581405, 'time_iter': 0.05, 'accuracy': 0.97982, 'precision': 0.47727, 'recall': 0.25926, 'f1': 0.336, 'auc': 0.80524}\ntest: {'epoch': 7, 'time_epoch': 6.4266, 'loss': 0.11736566, 'lr': 0, 'params': 581405, 'time_iter': 0.04982, 'accuracy': 0.97058, 'precision': 0.63636, 'recall': 0.16154, 'f1': 0.25767, 'auc': 0.75341}\n> Epoch 7: took 129.2s (avg 130.2s) | Best so far: epoch 6\ttrain_loss: 0.1258 train_auc: 0.7884\tval_loss: 0.0754 val_auc: 0.8159\ttest_loss: 0.1145 test_auc: 0.7560\ntrain: {'epoch': 8, 'time_epoch': 116.35527, 'eta': 10626.18765, 'eta_hours': 2.95172, 'loss': 0.11875529, 'lr': 9.975e-05, 'params': 581405, 'time_iter': 0.11308, 'accuracy': 0.96739, 'precision': 0.67865, 'recall': 0.24513, 'f1': 0.36017, 'auc': 0.81534}\nval: {'epoch': 8, 'time_epoch': 6.52011, 'loss': 0.07462961, 'lr': 0, 'params': 581405, 'time_iter': 0.05054, 'accuracy': 0.98152, 'precision': 0.54717, 'recall': 0.35802, 'f1': 0.43284, 'auc': 0.83298}\ntest: {'epoch': 8, 'time_epoch': 6.43325, 'loss': 0.11080372, 'lr': 0, 'params': 581405, 'time_iter': 0.04987, 'accuracy': 0.97131, 'precision': 0.60345, 'recall': 0.26923, 'f1': 0.37234, 'auc': 0.76714}\n> Epoch 8: took 129.5s (avg 130.1s) | Best so far: epoch 8\ttrain_loss: 0.1188 train_auc: 0.8153\tval_loss: 0.0746 val_auc: 0.8330\ttest_loss: 0.1108 test_auc: 0.7671\ntrain: {'epoch': 9, 'time_epoch': 116.19773, 'eta': 10504.25431, 'eta_hours': 2.91785, 'loss': 0.11722243, 'lr': 9.956e-05, 'params': 581405, 'time_iter': 0.11292, 'accuracy': 0.9672, 'precision': 0.66173, 'recall': 0.25406, 'f1': 0.36716, 'auc': 0.82583}\nval: {'epoch': 9, 'time_epoch': 6.48547, 'loss': 0.07380445, 'lr': 0, 'params': 581405, 'time_iter': 0.05027, 'accuracy': 0.98201, 'precision': 0.5814, 'recall': 0.30864, 'f1': 0.40323, 'auc': 0.83766}\ntest: {'epoch': 9, 'time_epoch': 6.42482, 'loss': 0.11265735, 'lr': 0, 'params': 581405, 'time_iter': 0.0498, 'accuracy': 0.97082, 'precision': 0.58065, 'recall': 0.27692, 'f1': 0.375, 'auc': 0.78827}\n> Epoch 9: took 129.3s (avg 130.0s) | Best so far: epoch 9\ttrain_loss: 0.1172 train_auc: 0.8258\tval_loss: 0.0738 val_auc: 0.8377\ttest_loss: 0.1127 test_auc: 0.7883\ntrain: {'epoch': 10, 'time_epoch': 115.87173, 'eta': 10380.72613, 'eta_hours': 2.88354, 'loss': 0.11484346, 'lr': 9.932e-05, 'params': 581405, 'time_iter': 0.11261, 'accuracy': 0.96763, 'precision': 0.66405, 'recall': 0.27435, 'f1': 0.38828, 'auc': 0.82844}\nval: {'epoch': 10, 'time_epoch': 6.39812, 'loss': 0.07841607, 'lr': 0, 'params': 581405, 'time_iter': 0.0496, 'accuracy': 0.98079, 'precision': 0.52083, 'recall': 0.30864, 'f1': 0.3876, 'auc': 0.80616}\ntest: {'epoch': 10, 'time_epoch': 6.32481, 'loss': 0.11873523, 'lr': 0, 'params': 581405, 'time_iter': 0.04903, 'accuracy': 0.97034, 'precision': 0.57407, 'recall': 0.23846, 'f1': 0.33696, 'auc': 0.76797}\n> Epoch 10: took 128.7s (avg 129.9s) | Best so far: epoch 9\ttrain_loss: 0.1172 train_auc: 0.8258\tval_loss: 0.0738 val_auc: 0.8377\ttest_loss: 0.1127 test_auc: 0.7883\ntrain: {'epoch': 11, 'time_epoch': 116.42603, 'eta': 10262.53892, 'eta_hours': 2.85071, 'loss': 0.11217665, 'lr': 9.902e-05, 'params': 581405, 'time_iter': 0.11314, 'accuracy': 0.96839, 'precision': 0.68824, 'recall': 0.2849, 'f1': 0.40299, 'auc': 0.84278}\nval: {'epoch': 11, 'time_epoch': 6.42672, 'loss': 0.07119207, 'lr': 0, 'params': 581405, 'time_iter': 0.04982, 'accuracy': 0.98201, 'precision': 0.59459, 'recall': 0.2716, 'f1': 0.37288, 'auc': 0.8384}\ntest: {'epoch': 11, 'time_epoch': 6.56413, 'loss': 0.11026811, 'lr': 0, 'params': 581405, 'time_iter': 0.05088, 'accuracy': 0.97204, 'precision': 0.62712, 'recall': 0.28462, 'f1': 0.39153, 'auc': 0.78666}\n> Epoch 11: took 129.6s (avg 129.9s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 12, 'time_epoch': 117.34998, 'eta': 10150.80602, 'eta_hours': 2.81967, 'loss': 0.11014968, 'lr': 9.867e-05, 'params': 581405, 'time_iter': 0.11404, 'accuracy': 0.96857, 'precision': 0.69336, 'recall': 0.28815, 'f1': 0.40711, 'auc': 0.85219}\nval: {'epoch': 12, 'time_epoch': 6.39232, 'loss': 0.07222467, 'lr': 0, 'params': 581405, 'time_iter': 0.04955, 'accuracy': 0.98104, 'precision': 0.53659, 'recall': 0.2716, 'f1': 0.36066, 'auc': 0.80887}\ntest: {'epoch': 12, 'time_epoch': 6.53707, 'loss': 0.11149174, 'lr': 0, 'params': 581405, 'time_iter': 0.05067, 'accuracy': 0.9718, 'precision': 0.62069, 'recall': 0.27692, 'f1': 0.38298, 'auc': 0.77514}\n> Epoch 12: took 130.4s (avg 129.9s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 13, 'time_epoch': 115.15103, 'eta': 10024.76282, 'eta_hours': 2.78466, 'loss': 0.10873586, 'lr': 9.826e-05, 'params': 581405, 'time_iter': 0.11191, 'accuracy': 0.96936, 'precision': 0.70664, 'recall': 0.31088, 'f1': 0.43179, 'auc': 0.86025}\nval: {'epoch': 13, 'time_epoch': 6.4376, 'loss': 0.07357525, 'lr': 0, 'params': 581405, 'time_iter': 0.0499, 'accuracy': 0.98152, 'precision': 0.55556, 'recall': 0.30864, 'f1': 0.39683, 'auc': 0.80027}\ntest: {'epoch': 13, 'time_epoch': 6.34678, 'loss': 0.11018395, 'lr': 0, 'params': 581405, 'time_iter': 0.0492, 'accuracy': 0.97107, 'precision': 0.6, 'recall': 0.25385, 'f1': 0.35676, 'auc': 0.79929}\n> Epoch 13: took 128.1s (avg 129.8s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 14, 'time_epoch': 114.35983, 'eta': 9895.68846, 'eta_hours': 2.7488, 'loss': 0.1071265, 'lr': 9.78e-05, 'params': 581405, 'time_iter': 0.11114, 'accuracy': 0.96942, 'precision': 0.70849, 'recall': 0.31169, 'f1': 0.43292, 'auc': 0.86016}\nval: {'epoch': 14, 'time_epoch': 6.56313, 'loss': 0.07254308, 'lr': 0, 'params': 581405, 'time_iter': 0.05088, 'accuracy': 0.98152, 'precision': 0.55102, 'recall': 0.33333, 'f1': 0.41538, 'auc': 0.81226}\ntest: {'epoch': 14, 'time_epoch': 6.37634, 'loss': 0.11241325, 'lr': 0, 'params': 581405, 'time_iter': 0.04943, 'accuracy': 0.97155, 'precision': 0.61404, 'recall': 0.26923, 'f1': 0.37433, 'auc': 0.78257}\n> Epoch 14: took 127.5s (avg 129.7s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 15, 'time_epoch': 114.46947, 'eta': 9769.02901, 'eta_hours': 2.71362, 'loss': 0.10516913, 'lr': 9.729e-05, 'params': 581405, 'time_iter': 0.11124, 'accuracy': 0.96973, 'precision': 0.70557, 'recall': 0.32873, 'f1': 0.4485, 'auc': 0.86842}\nval: {'epoch': 15, 'time_epoch': 6.48974, 'loss': 0.07460131, 'lr': 0, 'params': 581405, 'time_iter': 0.05031, 'accuracy': 0.98152, 'precision': 0.54386, 'recall': 0.38272, 'f1': 0.44928, 'auc': 0.80526}\ntest: {'epoch': 15, 'time_epoch': 6.31595, 'loss': 0.11207931, 'lr': 0, 'params': 581405, 'time_iter': 0.04896, 'accuracy': 0.97107, 'precision': 0.58462, 'recall': 0.29231, 'f1': 0.38974, 'auc': 0.79226}\n> Epoch 15: took 127.4s (avg 129.5s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 16, 'time_epoch': 115.2646, 'eta': 9647.68579, 'eta_hours': 2.67991, 'loss': 0.10295625, 'lr': 9.673e-05, 'params': 581405, 'time_iter': 0.11202, 'accuracy': 0.97079, 'precision': 0.7189, 'recall': 0.3612, 'f1': 0.48082, 'auc': 0.87931}\nval: {'epoch': 16, 'time_epoch': 6.5025, 'loss': 0.07254401, 'lr': 0, 'params': 581405, 'time_iter': 0.05041, 'accuracy': 0.98152, 'precision': 0.54902, 'recall': 0.34568, 'f1': 0.42424, 'auc': 0.82495}\ntest: {'epoch': 16, 'time_epoch': 6.36493, 'loss': 0.11546073, 'lr': 0, 'params': 581405, 'time_iter': 0.04934, 'accuracy': 0.97082, 'precision': 0.6, 'recall': 0.23077, 'f1': 0.33333, 'auc': 0.77846}\n> Epoch 16: took 128.3s (avg 129.4s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 17, 'time_epoch': 114.78502, 'eta': 9524.83323, 'eta_hours': 2.64579, 'loss': 0.10217336, 'lr': 9.611e-05, 'params': 581405, 'time_iter': 0.11155, 'accuracy': 0.97052, 'precision': 0.70994, 'recall': 0.35958, 'f1': 0.47737, 'auc': 0.88428}\nval: {'epoch': 17, 'time_epoch': 6.45853, 'loss': 0.08383914, 'lr': 0, 'params': 581405, 'time_iter': 0.05007, 'accuracy': 0.97788, 'precision': 0.42647, 'recall': 0.35802, 'f1': 0.38926, 'auc': 0.7997}\ntest: {'epoch': 17, 'time_epoch': 6.33529, 'loss': 0.12114717, 'lr': 0, 'params': 581405, 'time_iter': 0.04911, 'accuracy': 0.96791, 'precision': 0.48611, 'recall': 0.26923, 'f1': 0.34653, 'auc': 0.77062}\n> Epoch 17: took 127.7s (avg 129.3s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 18, 'time_epoch': 114.93821, 'eta': 9403.48297, 'eta_hours': 2.61208, 'loss': 0.09991288, 'lr': 9.545e-05, 'params': 581405, 'time_iter': 0.1117, 'accuracy': 0.97085, 'precision': 0.7191, 'recall': 0.36364, 'f1': 0.48302, 'auc': 0.89059}\nval: {'epoch': 18, 'time_epoch': 6.43644, 'loss': 0.07004381, 'lr': 0, 'params': 581405, 'time_iter': 0.04989, 'accuracy': 0.98347, 'precision': 0.67568, 'recall': 0.30864, 'f1': 0.42373, 'auc': 0.82915}\ntest: {'epoch': 18, 'time_epoch': 6.36481, 'loss': 0.11712161, 'lr': 0, 'params': 581405, 'time_iter': 0.04934, 'accuracy': 0.97082, 'precision': 0.64706, 'recall': 0.16923, 'f1': 0.26829, 'auc': 0.79188}\n> Epoch 18: took 127.9s (avg 129.3s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 19, 'time_epoch': 114.76809, 'eta': 9282.09342, 'eta_hours': 2.57836, 'loss': 0.09838933, 'lr': 9.474e-05, 'params': 581405, 'time_iter': 0.11153, 'accuracy': 0.97192, 'precision': 0.74367, 'recall': 0.38149, 'f1': 0.50429, 'auc': 0.891}\nval: {'epoch': 19, 'time_epoch': 6.39575, 'loss': 0.07077049, 'lr': 0, 'params': 581405, 'time_iter': 0.04958, 'accuracy': 0.98322, 'precision': 0.6875, 'recall': 0.2716, 'f1': 0.38938, 'auc': 0.81407}\ntest: {'epoch': 19, 'time_epoch': 6.38279, 'loss': 0.12040576, 'lr': 0, 'params': 581405, 'time_iter': 0.04948, 'accuracy': 0.96937, 'precision': 0.58333, 'recall': 0.10769, 'f1': 0.18182, 'auc': 0.7747}\n> Epoch 19: took 127.7s (avg 129.2s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 20, 'time_epoch': 114.79874, 'eta': 9161.44977, 'eta_hours': 2.54485, 'loss': 0.09609272, 'lr': 9.397e-05, 'params': 581405, 'time_iter': 0.11156, 'accuracy': 0.97249, 'precision': 0.7481, 'recall': 0.40016, 'f1': 0.52142, 'auc': 0.89886}\nval: {'epoch': 20, 'time_epoch': 6.38427, 'loss': 0.08496612, 'lr': 0, 'params': 581405, 'time_iter': 0.04949, 'accuracy': 0.97885, 'precision': 0.45161, 'recall': 0.34568, 'f1': 0.39161, 'auc': 0.78704}\ntest: {'epoch': 20, 'time_epoch': 6.35766, 'loss': 0.12292682, 'lr': 0, 'params': 581405, 'time_iter': 0.04928, 'accuracy': 0.96572, 'precision': 0.43373, 'recall': 0.27692, 'f1': 0.33803, 'auc': 0.78473}\n> Epoch 20: took 127.7s (avg 129.1s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 21, 'time_epoch': 114.83216, 'eta': 9041.45597, 'eta_hours': 2.51152, 'loss': 0.09490673, 'lr': 9.316e-05, 'params': 581405, 'time_iter': 0.1116, 'accuracy': 0.97155, 'precision': 0.72222, 'recall': 0.39042, 'f1': 0.50685, 'auc': 0.90861}\nval: {'epoch': 21, 'time_epoch': 6.38432, 'loss': 0.08269824, 'lr': 0, 'params': 581405, 'time_iter': 0.04949, 'accuracy': 0.97715, 'precision': 0.41096, 'recall': 0.37037, 'f1': 0.38961, 'auc': 0.8199}\ntest: {'epoch': 21, 'time_epoch': 6.39289, 'loss': 0.12437401, 'lr': 0, 'params': 581405, 'time_iter': 0.04956, 'accuracy': 0.96742, 'precision': 0.47872, 'recall': 0.34615, 'f1': 0.40179, 'auc': 0.79653}\n> Epoch 21: took 127.8s (avg 129.1s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 22, 'time_epoch': 114.7551, 'eta': 8921.65302, 'eta_hours': 2.47824, 'loss': 0.09323576, 'lr': 9.23e-05, 'params': 581405, 'time_iter': 0.11152, 'accuracy': 0.97219, 'precision': 0.73621, 'recall': 0.40097, 'f1': 0.51918, 'auc': 0.91326}\nval: {'epoch': 22, 'time_epoch': 6.37916, 'loss': 0.07828018, 'lr': 0, 'params': 581405, 'time_iter': 0.04945, 'accuracy': 0.98152, 'precision': 0.55102, 'recall': 0.33333, 'f1': 0.41538, 'auc': 0.80226}\ntest: {'epoch': 22, 'time_epoch': 6.4119, 'loss': 0.11858964, 'lr': 0, 'params': 581405, 'time_iter': 0.0497, 'accuracy': 0.97058, 'precision': 0.56522, 'recall': 0.3, 'f1': 0.39196, 'auc': 0.79825}\n> Epoch 22: took 127.7s (avg 129.0s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 23, 'time_epoch': 114.8019, 'eta': 8802.41893, 'eta_hours': 2.44512, 'loss': 0.09178082, 'lr': 9.14e-05, 'params': 581405, 'time_iter': 0.11157, 'accuracy': 0.97271, 'precision': 0.75457, 'recall': 0.40179, 'f1': 0.52436, 'auc': 0.91766}\nval: {'epoch': 23, 'time_epoch': 6.39218, 'loss': 0.07641381, 'lr': 0, 'params': 581405, 'time_iter': 0.04955, 'accuracy': 0.98225, 'precision': 0.6, 'recall': 0.2963, 'f1': 0.39669, 'auc': 0.80232}\ntest: {'epoch': 23, 'time_epoch': 6.35443, 'loss': 0.11919467, 'lr': 0, 'params': 581405, 'time_iter': 0.04926, 'accuracy': 0.97155, 'precision': 0.62745, 'recall': 0.24615, 'f1': 0.35359, 'auc': 0.78492}\n> Epoch 23: took 127.7s (avg 128.9s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 24, 'time_epoch': 115.52485, 'eta': 8685.70828, 'eta_hours': 2.4127, 'loss': 0.09026981, 'lr': 9.045e-05, 'params': 581405, 'time_iter': 0.11227, 'accuracy': 0.97341, 'precision': 0.76211, 'recall': 0.42127, 'f1': 0.5426, 'auc': 0.92017}\nval: {'epoch': 24, 'time_epoch': 6.37831, 'loss': 0.07563901, 'lr': 0, 'params': 581405, 'time_iter': 0.04944, 'accuracy': 0.98249, 'precision': 0.59574, 'recall': 0.34568, 'f1': 0.4375, 'auc': 0.81268}\ntest: {'epoch': 24, 'time_epoch': 6.32279, 'loss': 0.11958079, 'lr': 0, 'params': 581405, 'time_iter': 0.04901, 'accuracy': 0.97058, 'precision': 0.56923, 'recall': 0.28462, 'f1': 0.37949, 'auc': 0.78377}\n> Epoch 24: took 128.4s (avg 128.9s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 25, 'time_epoch': 114.68858, 'eta': 8566.70867, 'eta_hours': 2.37964, 'loss': 0.08887794, 'lr': 8.946e-05, 'params': 581405, 'time_iter': 0.11146, 'accuracy': 0.97371, 'precision': 0.77347, 'recall': 0.42127, 'f1': 0.54545, 'auc': 0.92435}\nval: {'epoch': 25, 'time_epoch': 6.42445, 'loss': 0.0775692, 'lr': 0, 'params': 581405, 'time_iter': 0.0498, 'accuracy': 0.98201, 'precision': 0.57447, 'recall': 0.33333, 'f1': 0.42188, 'auc': 0.82233}\ntest: {'epoch': 25, 'time_epoch': 6.3217, 'loss': 0.12687348, 'lr': 0, 'params': 581405, 'time_iter': 0.04901, 'accuracy': 0.97034, 'precision': 0.56897, 'recall': 0.25385, 'f1': 0.35106, 'auc': 0.78886}\n> Epoch 25: took 127.6s (avg 128.9s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 26, 'time_epoch': 114.7598, 'eta': 8448.22096, 'eta_hours': 2.34673, 'loss': 0.08796099, 'lr': 8.842e-05, 'params': 581405, 'time_iter': 0.11153, 'accuracy': 0.97374, 'precision': 0.76822, 'recall': 0.42776, 'f1': 0.54953, 'auc': 0.92748}\nval: {'epoch': 26, 'time_epoch': 6.38325, 'loss': 0.07988011, 'lr': 0, 'params': 581405, 'time_iter': 0.04948, 'accuracy': 0.97958, 'precision': 0.47458, 'recall': 0.34568, 'f1': 0.4, 'auc': 0.8044}\ntest: {'epoch': 26, 'time_epoch': 6.3835, 'loss': 0.12316595, 'lr': 0, 'params': 581405, 'time_iter': 0.04948, 'accuracy': 0.96961, 'precision': 0.52688, 'recall': 0.37692, 'f1': 0.43946, 'auc': 0.79397}\n> Epoch 26: took 127.7s (avg 128.8s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 27, 'time_epoch': 114.47374, 'eta': 8329.26396, 'eta_hours': 2.31368, 'loss': 0.08853746, 'lr': 8.734e-05, 'params': 581405, 'time_iter': 0.11125, 'accuracy': 0.97344, 'precision': 0.76017, 'recall': 0.42451, 'f1': 0.54479, 'auc': 0.92351}\nval: {'epoch': 27, 'time_epoch': 6.38664, 'loss': 0.07827218, 'lr': 0, 'params': 581405, 'time_iter': 0.04951, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.34568, 'f1': 0.40876, 'auc': 0.81632}\ntest: {'epoch': 27, 'time_epoch': 6.33883, 'loss': 0.12295308, 'lr': 0, 'params': 581405, 'time_iter': 0.04914, 'accuracy': 0.97131, 'precision': 0.6, 'recall': 0.27692, 'f1': 0.37895, 'auc': 0.80031}\n> Epoch 27: took 127.4s (avg 128.8s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 28, 'time_epoch': 114.7183, 'eta': 8211.2149, 'eta_hours': 2.28089, 'loss': 0.08630831, 'lr': 8.622e-05, 'params': 581405, 'time_iter': 0.11149, 'accuracy': 0.9745, 'precision': 0.7733, 'recall': 0.4513, 'f1': 0.56996, 'auc': 0.93182}\nval: {'epoch': 28, 'time_epoch': 6.34254, 'loss': 0.08014487, 'lr': 0, 'params': 581405, 'time_iter': 0.04917, 'accuracy': 0.97909, 'precision': 0.46032, 'recall': 0.35802, 'f1': 0.40278, 'auc': 0.81295}\ntest: {'epoch': 28, 'time_epoch': 6.3349, 'loss': 0.12625432, 'lr': 0, 'params': 581405, 'time_iter': 0.04911, 'accuracy': 0.96791, 'precision': 0.48529, 'recall': 0.25385, 'f1': 0.33333, 'auc': 0.79236}\n> Epoch 28: took 127.5s (avg 128.7s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 29, 'time_epoch': 114.25125, 'eta': 8092.29811, 'eta_hours': 2.24786, 'loss': 0.08366437, 'lr': 8.506e-05, 'params': 581405, 'time_iter': 0.11103, 'accuracy': 0.97404, 'precision': 0.75962, 'recall': 0.44886, 'f1': 0.56429, 'auc': 0.93894}\nval: {'epoch': 29, 'time_epoch': 6.37573, 'loss': 0.07758552, 'lr': 0, 'params': 581405, 'time_iter': 0.04942, 'accuracy': 0.98152, 'precision': 0.55102, 'recall': 0.33333, 'f1': 0.41538, 'auc': 0.8169}\ntest: {'epoch': 29, 'time_epoch': 6.28367, 'loss': 0.12739366, 'lr': 0, 'params': 581405, 'time_iter': 0.04871, 'accuracy': 0.96961, 'precision': 0.53425, 'recall': 0.3, 'f1': 0.38424, 'auc': 0.8055}\n> Epoch 29: took 127.1s (avg 128.7s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 30, 'time_epoch': 114.41847, 'eta': 7974.05451, 'eta_hours': 2.21502, 'loss': 0.08107751, 'lr': 8.386e-05, 'params': 581405, 'time_iter': 0.11119, 'accuracy': 0.97483, 'precision': 0.77671, 'recall': 0.46023, 'f1': 0.57798, 'auc': 0.94173}\nval: {'epoch': 30, 'time_epoch': 6.32205, 'loss': 0.08388268, 'lr': 0, 'params': 581405, 'time_iter': 0.04901, 'accuracy': 0.98079, 'precision': 0.51724, 'recall': 0.37037, 'f1': 0.43165, 'auc': 0.79019}\ntest: {'epoch': 30, 'time_epoch': 6.31305, 'loss': 0.12609943, 'lr': 0, 'params': 581405, 'time_iter': 0.04894, 'accuracy': 0.97009, 'precision': 0.55224, 'recall': 0.28462, 'f1': 0.37563, 'auc': 0.7956}\n> Epoch 30: took 127.2s (avg 128.6s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 31, 'time_epoch': 114.47214, 'eta': 7856.16404, 'eta_hours': 2.18227, 'loss': 0.08058495, 'lr': 8.263e-05, 'params': 581405, 'time_iter': 0.11125, 'accuracy': 0.97407, 'precision': 0.76066, 'recall': 0.44886, 'f1': 0.56457, 'auc': 0.94798}\nval: {'epoch': 31, 'time_epoch': 6.31495, 'loss': 0.08746337, 'lr': 0, 'params': 581405, 'time_iter': 0.04895, 'accuracy': 0.97739, 'precision': 0.4, 'recall': 0.2963, 'f1': 0.34043, 'auc': 0.80571}\ntest: {'epoch': 31, 'time_epoch': 6.30853, 'loss': 0.13067024, 'lr': 0, 'params': 581405, 'time_iter': 0.0489, 'accuracy': 0.96645, 'precision': 0.4375, 'recall': 0.21538, 'f1': 0.28866, 'auc': 0.79405}\n> Epoch 31: took 127.2s (avg 128.6s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 32, 'time_epoch': 114.48717, 'eta': 7738.51125, 'eta_hours': 2.14959, 'loss': 0.07926889, 'lr': 8.136e-05, 'params': 581405, 'time_iter': 0.11126, 'accuracy': 0.97483, 'precision': 0.76579, 'recall': 0.4724, 'f1': 0.58434, 'auc': 0.94865}\nval: {'epoch': 32, 'time_epoch': 6.38365, 'loss': 0.08658722, 'lr': 0, 'params': 581405, 'time_iter': 0.04949, 'accuracy': 0.98128, 'precision': 0.53448, 'recall': 0.38272, 'f1': 0.44604, 'auc': 0.7997}\ntest: {'epoch': 32, 'time_epoch': 6.29849, 'loss': 0.14183448, 'lr': 0, 'params': 581405, 'time_iter': 0.04883, 'accuracy': 0.96961, 'precision': 0.53623, 'recall': 0.28462, 'f1': 0.37186, 'auc': 0.77721}\n> Epoch 32: took 127.3s (avg 128.5s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 33, 'time_epoch': 114.89275, 'eta': 7621.83197, 'eta_hours': 2.11718, 'loss': 0.078724, 'lr': 8.005e-05, 'params': 581405, 'time_iter': 0.11165, 'accuracy': 0.97486, 'precision': 0.76062, 'recall': 0.47971, 'f1': 0.58835, 'auc': 0.94974}\nval: {'epoch': 33, 'time_epoch': 6.38775, 'loss': 0.0865921, 'lr': 0, 'params': 581405, 'time_iter': 0.04952, 'accuracy': 0.98177, 'precision': 0.56818, 'recall': 0.30864, 'f1': 0.4, 'auc': 0.78552}\ntest: {'epoch': 33, 'time_epoch': 6.43822, 'loss': 0.13787923, 'lr': 0, 'params': 581405, 'time_iter': 0.04991, 'accuracy': 0.96791, 'precision': 0.48276, 'recall': 0.21538, 'f1': 0.29787, 'auc': 0.78475}\n> Epoch 33: took 127.9s (avg 128.5s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 34, 'time_epoch': 115.01832, 'eta': 7505.48799, 'eta_hours': 2.08486, 'loss': 0.07728767, 'lr': 7.872e-05, 'params': 581405, 'time_iter': 0.11178, 'accuracy': 0.97565, 'precision': 0.78244, 'recall': 0.48458, 'f1': 0.5985, 'auc': 0.95243}\nval: {'epoch': 34, 'time_epoch': 6.37613, 'loss': 0.08474759, 'lr': 0, 'params': 581405, 'time_iter': 0.04943, 'accuracy': 0.98128, 'precision': 0.54, 'recall': 0.33333, 'f1': 0.41221, 'auc': 0.81535}\ntest: {'epoch': 34, 'time_epoch': 6.3767, 'loss': 0.13668977, 'lr': 0, 'params': 581405, 'time_iter': 0.04943, 'accuracy': 0.96985, 'precision': 0.55357, 'recall': 0.23846, 'f1': 0.33333, 'auc': 0.8114}\n> Epoch 34: took 127.9s (avg 128.5s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 35, 'time_epoch': 114.60141, 'eta': 7388.47648, 'eta_hours': 2.05235, 'loss': 0.07618349, 'lr': 7.735e-05, 'params': 581405, 'time_iter': 0.11137, 'accuracy': 0.9752, 'precision': 0.76463, 'recall': 0.48782, 'f1': 0.59564, 'auc': 0.95605}\nval: {'epoch': 35, 'time_epoch': 6.39956, 'loss': 0.09021548, 'lr': 0, 'params': 581405, 'time_iter': 0.04961, 'accuracy': 0.97836, 'precision': 0.44595, 'recall': 0.40741, 'f1': 0.42581, 'auc': 0.8161}\ntest: {'epoch': 35, 'time_epoch': 6.35497, 'loss': 0.14750971, 'lr': 0, 'params': 581405, 'time_iter': 0.04926, 'accuracy': 0.96693, 'precision': 0.45161, 'recall': 0.21538, 'f1': 0.29167, 'auc': 0.79299}\n> Epoch 35: took 127.5s (avg 128.5s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 36, 'time_epoch': 114.43007, 'eta': 7271.30351, 'eta_hours': 2.01981, 'loss': 0.0759928, 'lr': 7.595e-05, 'params': 581405, 'time_iter': 0.11121, 'accuracy': 0.97575, 'precision': 0.77679, 'recall': 0.49432, 'f1': 0.60417, 'auc': 0.9533}\nval: {'epoch': 36, 'time_epoch': 6.33304, 'loss': 0.08692651, 'lr': 0, 'params': 581405, 'time_iter': 0.04909, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.40741, 'f1': 0.44898, 'auc': 0.81904}\ntest: {'epoch': 36, 'time_epoch': 6.40636, 'loss': 0.13827197, 'lr': 0, 'params': 581405, 'time_iter': 0.04966, 'accuracy': 0.96548, 'precision': 0.43617, 'recall': 0.31538, 'f1': 0.36607, 'auc': 0.8018}\n> Epoch 36: took 127.3s (avg 128.5s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 37, 'time_epoch': 115.10036, 'eta': 7155.36853, 'eta_hours': 1.9876, 'loss': 0.07385243, 'lr': 7.452e-05, 'params': 581405, 'time_iter': 0.11186, 'accuracy': 0.97629, 'precision': 0.78535, 'recall': 0.50487, 'f1': 0.61462, 'auc': 0.95705}\nval: {'epoch': 37, 'time_epoch': 6.36095, 'loss': 0.08561449, 'lr': 0, 'params': 581405, 'time_iter': 0.04931, 'accuracy': 0.97958, 'precision': 0.47458, 'recall': 0.34568, 'f1': 0.4, 'auc': 0.82259}\ntest: {'epoch': 37, 'time_epoch': 6.41049, 'loss': 0.14155758, 'lr': 0, 'params': 581405, 'time_iter': 0.04969, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.25385, 'f1': 0.33673, 'auc': 0.80692}\n> Epoch 37: took 128.0s (avg 128.4s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 38, 'time_epoch': 114.77914, 'eta': 7038.97393, 'eta_hours': 1.95527, 'loss': 0.07169246, 'lr': 7.307e-05, 'params': 581405, 'time_iter': 0.11154, 'accuracy': 0.97708, 'precision': 0.78452, 'recall': 0.5349, 'f1': 0.6361, 'auc': 0.96263}\nval: {'epoch': 38, 'time_epoch': 6.38173, 'loss': 0.08892043, 'lr': 0, 'params': 581405, 'time_iter': 0.04947, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.37037, 'f1': 0.42553, 'auc': 0.81046}\ntest: {'epoch': 38, 'time_epoch': 6.47752, 'loss': 0.14926392, 'lr': 0, 'params': 581405, 'time_iter': 0.05021, 'accuracy': 0.96523, 'precision': 0.43434, 'recall': 0.33077, 'f1': 0.37555, 'auc': 0.79258}\n> Epoch 38: took 127.8s (avg 128.4s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 39, 'time_epoch': 114.36245, 'eta': 6922.03507, 'eta_hours': 1.92279, 'loss': 0.07114677, 'lr': 7.159e-05, 'params': 581405, 'time_iter': 0.11114, 'accuracy': 0.9773, 'precision': 0.79112, 'recall': 0.5349, 'f1': 0.63826, 'auc': 0.96244}\nval: {'epoch': 39, 'time_epoch': 6.36737, 'loss': 0.09182759, 'lr': 0, 'params': 581405, 'time_iter': 0.04936, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.37037, 'f1': 0.42553, 'auc': 0.81068}\ntest: {'epoch': 39, 'time_epoch': 6.38282, 'loss': 0.14512478, 'lr': 0, 'params': 581405, 'time_iter': 0.04948, 'accuracy': 0.96572, 'precision': 0.44086, 'recall': 0.31538, 'f1': 0.36771, 'auc': 0.79826}\n> Epoch 39: took 127.3s (avg 128.4s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 40, 'time_epoch': 114.36058, 'eta': 6805.2192, 'eta_hours': 1.89034, 'loss': 0.0688912, 'lr': 7.008e-05, 'params': 581405, 'time_iter': 0.11114, 'accuracy': 0.97736, 'precision': 0.79162, 'recall': 0.53653, 'f1': 0.63957, 'auc': 0.96605}\nval: {'epoch': 40, 'time_epoch': 6.35279, 'loss': 0.0887217, 'lr': 0, 'params': 581405, 'time_iter': 0.04925, 'accuracy': 0.98177, 'precision': 0.55357, 'recall': 0.38272, 'f1': 0.45255, 'auc': 0.81767}\ntest: {'epoch': 40, 'time_epoch': 6.40008, 'loss': 0.15638738, 'lr': 0, 'params': 581405, 'time_iter': 0.04961, 'accuracy': 0.96912, 'precision': 0.54054, 'recall': 0.15385, 'f1': 0.23952, 'auc': 0.78346}\n> Epoch 40: took 127.3s (avg 128.4s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 41, 'time_epoch': 114.52064, 'eta': 6688.74128, 'eta_hours': 1.85798, 'loss': 0.07002229, 'lr': 6.856e-05, 'params': 581405, 'time_iter': 0.11129, 'accuracy': 0.9779, 'precision': 0.80755, 'recall': 0.53815, 'f1': 0.64588, 'auc': 0.96421}\nval: {'epoch': 41, 'time_epoch': 6.38711, 'loss': 0.08838529, 'lr': 0, 'params': 581405, 'time_iter': 0.04951, 'accuracy': 0.98177, 'precision': 0.5625, 'recall': 0.33333, 'f1': 0.4186, 'auc': 0.81197}\ntest: {'epoch': 41, 'time_epoch': 6.42596, 'loss': 0.1563184, 'lr': 0, 'params': 581405, 'time_iter': 0.04981, 'accuracy': 0.97009, 'precision': 0.56604, 'recall': 0.23077, 'f1': 0.32787, 'auc': 0.77396}\n> Epoch 41: took 127.5s (avg 128.3s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 42, 'time_epoch': 114.07243, 'eta': 6571.76026, 'eta_hours': 1.82549, 'loss': 0.06887064, 'lr': 6.701e-05, 'params': 581405, 'time_iter': 0.11086, 'accuracy': 0.97775, 'precision': 0.79206, 'recall': 0.55032, 'f1': 0.64943, 'auc': 0.9676}\nval: {'epoch': 42, 'time_epoch': 6.42877, 'loss': 0.08439822, 'lr': 0, 'params': 581405, 'time_iter': 0.04984, 'accuracy': 0.98104, 'precision': 0.53061, 'recall': 0.32099, 'f1': 0.4, 'auc': 0.81198}\ntest: {'epoch': 42, 'time_epoch': 6.4336, 'loss': 0.13473088, 'lr': 0, 'params': 581405, 'time_iter': 0.04987, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.31538, 'f1': 0.38679, 'auc': 0.81258}\n> Epoch 42: took 127.1s (avg 128.3s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 43, 'time_epoch': 114.11451, 'eta': 6454.965, 'eta_hours': 1.79305, 'loss': 0.06765701, 'lr': 6.545e-05, 'params': 581405, 'time_iter': 0.1109, 'accuracy': 0.97827, 'precision': 0.8081, 'recall': 0.55032, 'f1': 0.65476, 'auc': 0.96731}\nval: {'epoch': 43, 'time_epoch': 6.36508, 'loss': 0.09491832, 'lr': 0, 'params': 581405, 'time_iter': 0.04934, 'accuracy': 0.97812, 'precision': 0.42857, 'recall': 0.33333, 'f1': 0.375, 'auc': 0.79724}\ntest: {'epoch': 43, 'time_epoch': 6.34924, 'loss': 0.14965912, 'lr': 0, 'params': 581405, 'time_iter': 0.04922, 'accuracy': 0.96888, 'precision': 0.51351, 'recall': 0.29231, 'f1': 0.37255, 'auc': 0.80229}\n> Epoch 43: took 127.0s (avg 128.3s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 44, 'time_epoch': 113.85283, 'eta': 6337.96905, 'eta_hours': 1.76055, 'loss': 0.06866783, 'lr': 6.387e-05, 'params': 581405, 'time_iter': 0.11064, 'accuracy': 0.97778, 'precision': 0.80364, 'recall': 0.53815, 'f1': 0.64463, 'auc': 0.96576}\nval: {'epoch': 44, 'time_epoch': 6.42502, 'loss': 0.09393744, 'lr': 0, 'params': 581405, 'time_iter': 0.04981, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.35802, 'f1': 0.41727, 'auc': 0.82016}\ntest: {'epoch': 44, 'time_epoch': 6.2761, 'loss': 0.15331221, 'lr': 0, 'params': 581405, 'time_iter': 0.04865, 'accuracy': 0.96766, 'precision': 0.48315, 'recall': 0.33077, 'f1': 0.39269, 'auc': 0.80427}\n> Epoch 44: took 126.7s (avg 128.3s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 45, 'time_epoch': 114.76314, 'eta': 6222.17838, 'eta_hours': 1.72838, 'loss': 0.06491897, 'lr': 6.227e-05, 'params': 581405, 'time_iter': 0.11153, 'accuracy': 0.97894, 'precision': 0.80871, 'recall': 0.57305, 'f1': 0.67078, 'auc': 0.97017}\nval: {'epoch': 45, 'time_epoch': 6.40125, 'loss': 0.08903337, 'lr': 0, 'params': 581405, 'time_iter': 0.04962, 'accuracy': 0.98079, 'precision': 0.51852, 'recall': 0.34568, 'f1': 0.41481, 'auc': 0.8291}\ntest: {'epoch': 45, 'time_epoch': 6.3361, 'loss': 0.1557786, 'lr': 0, 'params': 581405, 'time_iter': 0.04912, 'accuracy': 0.96912, 'precision': 0.52174, 'recall': 0.27692, 'f1': 0.36181, 'auc': 0.79118}\n> Epoch 45: took 127.6s (avg 128.2s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 46, 'time_epoch': 114.52756, 'eta': 6106.16579, 'eta_hours': 1.69616, 'loss': 0.0652663, 'lr': 6.066e-05, 'params': 581405, 'time_iter': 0.1113, 'accuracy': 0.979, 'precision': 0.80844, 'recall': 0.57549, 'f1': 0.67236, 'auc': 0.97093}\nval: {'epoch': 46, 'time_epoch': 6.43107, 'loss': 0.09626362, 'lr': 0, 'params': 581405, 'time_iter': 0.04985, 'accuracy': 0.9786, 'precision': 0.44928, 'recall': 0.38272, 'f1': 0.41333, 'auc': 0.81258}\ntest: {'epoch': 46, 'time_epoch': 6.37846, 'loss': 0.15811351, 'lr': 0, 'params': 581405, 'time_iter': 0.04945, 'accuracy': 0.96791, 'precision': 0.4881, 'recall': 0.31538, 'f1': 0.38318, 'auc': 0.78974}\n> Epoch 46: took 127.5s (avg 128.2s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 47, 'time_epoch': 113.81327, 'eta': 5989.44126, 'eta_hours': 1.66373, 'loss': 0.06363527, 'lr': 5.904e-05, 'params': 581405, 'time_iter': 0.11061, 'accuracy': 0.9779, 'precision': 0.79056, 'recall': 0.55763, 'f1': 0.65397, 'auc': 0.97592}\nval: {'epoch': 47, 'time_epoch': 6.3636, 'loss': 0.09298992, 'lr': 0, 'params': 581405, 'time_iter': 0.04933, 'accuracy': 0.97982, 'precision': 0.48438, 'recall': 0.38272, 'f1': 0.42759, 'auc': 0.81575}\ntest: {'epoch': 47, 'time_epoch': 6.34177, 'loss': 0.15648545, 'lr': 0, 'params': 581405, 'time_iter': 0.04916, 'accuracy': 0.9662, 'precision': 0.44944, 'recall': 0.30769, 'f1': 0.3653, 'auc': 0.79333}\n> Epoch 47: took 126.7s (avg 128.2s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 48, 'time_epoch': 113.66849, 'eta': 5872.68487, 'eta_hours': 1.6313, 'loss': 0.06258984, 'lr': 5.741e-05, 'params': 581405, 'time_iter': 0.11047, 'accuracy': 0.97894, 'precision': 0.80045, 'recall': 0.58279, 'f1': 0.6745, 'auc': 0.97477}\nval: {'epoch': 48, 'time_epoch': 6.34925, 'loss': 0.09741471, 'lr': 0, 'params': 581405, 'time_iter': 0.04922, 'accuracy': 0.97812, 'precision': 0.43478, 'recall': 0.37037, 'f1': 0.4, 'auc': 0.81302}\ntest: {'epoch': 48, 'time_epoch': 6.3773, 'loss': 0.16567578, 'lr': 0, 'params': 581405, 'time_iter': 0.04944, 'accuracy': 0.96377, 'precision': 0.41739, 'recall': 0.36923, 'f1': 0.39184, 'auc': 0.78855}\n> Epoch 48: took 126.5s (avg 128.2s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 49, 'time_epoch': 114.99539, 'eta': 5757.37889, 'eta_hours': 1.59927, 'loss': 0.06136888, 'lr': 5.577e-05, 'params': 581405, 'time_iter': 0.11175, 'accuracy': 0.97997, 'precision': 0.81728, 'recall': 0.59903, 'f1': 0.69133, 'auc': 0.97303}\nval: {'epoch': 49, 'time_epoch': 6.38456, 'loss': 0.09124162, 'lr': 0, 'params': 581405, 'time_iter': 0.04949, 'accuracy': 0.98055, 'precision': 0.50909, 'recall': 0.34568, 'f1': 0.41176, 'auc': 0.82309}\ntest: {'epoch': 49, 'time_epoch': 6.34942, 'loss': 0.15976324, 'lr': 0, 'params': 581405, 'time_iter': 0.04922, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.29231, 'f1': 0.36893, 'auc': 0.79444}\n> Epoch 49: took 127.9s (avg 128.1s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 50, 'time_epoch': 114.33051, 'eta': 5641.44628, 'eta_hours': 1.56707, 'loss': 0.06155439, 'lr': 5.413e-05, 'params': 581405, 'time_iter': 0.11111, 'accuracy': 0.97918, 'precision': 0.80288, 'recall': 0.58847, 'f1': 0.67916, 'auc': 0.9761}\nval: {'epoch': 50, 'time_epoch': 6.33088, 'loss': 0.0986039, 'lr': 0, 'params': 581405, 'time_iter': 0.04908, 'accuracy': 0.97812, 'precision': 0.43077, 'recall': 0.34568, 'f1': 0.38356, 'auc': 0.81689}\ntest: {'epoch': 50, 'time_epoch': 6.30316, 'loss': 0.16736852, 'lr': 0, 'params': 581405, 'time_iter': 0.04886, 'accuracy': 0.96548, 'precision': 0.42857, 'recall': 0.27692, 'f1': 0.33645, 'auc': 0.77883}\n> Epoch 50: took 127.1s (avg 128.1s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 51, 'time_epoch': 114.06591, 'eta': 5525.33106, 'eta_hours': 1.53481, 'loss': 0.05840156, 'lr': 5.248e-05, 'params': 581405, 'time_iter': 0.11085, 'accuracy': 0.98018, 'precision': 0.81116, 'recall': 0.61364, 'f1': 0.69871, 'auc': 0.97776}\nval: {'epoch': 51, 'time_epoch': 6.33846, 'loss': 0.10813703, 'lr': 0, 'params': 581405, 'time_iter': 0.04914, 'accuracy': 0.97909, 'precision': 0.45283, 'recall': 0.2963, 'f1': 0.35821, 'auc': 0.80945}\ntest: {'epoch': 51, 'time_epoch': 6.29358, 'loss': 0.18674749, 'lr': 0, 'params': 581405, 'time_iter': 0.04879, 'accuracy': 0.96937, 'precision': 0.53448, 'recall': 0.23846, 'f1': 0.32979, 'auc': 0.78123}\n> Epoch 51: took 126.9s (avg 128.1s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 52, 'time_epoch': 114.52607, 'eta': 5409.70123, 'eta_hours': 1.50269, 'loss': 0.05928809, 'lr': 5.083e-05, 'params': 581405, 'time_iter': 0.1113, 'accuracy': 0.98091, 'precision': 0.8326, 'recall': 0.61364, 'f1': 0.70654, 'auc': 0.97552}\nval: {'epoch': 52, 'time_epoch': 6.34282, 'loss': 0.09468725, 'lr': 0, 'params': 581405, 'time_iter': 0.04917, 'accuracy': 0.97958, 'precision': 0.47368, 'recall': 0.33333, 'f1': 0.3913, 'auc': 0.8157}\ntest: {'epoch': 52, 'time_epoch': 6.36401, 'loss': 0.16640058, 'lr': 0, 'params': 581405, 'time_iter': 0.04933, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.32308, 'f1': 0.39252, 'auc': 0.78887}\n> Epoch 52: took 127.4s (avg 128.1s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 53, 'time_epoch': 115.027, 'eta': 5294.539, 'eta_hours': 1.47071, 'loss': 0.05821737, 'lr': 4.917e-05, 'params': 581405, 'time_iter': 0.11179, 'accuracy': 0.98037, 'precision': 0.81104, 'recall': 0.62013, 'f1': 0.70285, 'auc': 0.98113}\nval: {'epoch': 53, 'time_epoch': 6.34649, 'loss': 0.09740471, 'lr': 0, 'params': 581405, 'time_iter': 0.0492, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.35802, 'f1': 0.41727, 'auc': 0.82104}\ntest: {'epoch': 53, 'time_epoch': 6.3462, 'loss': 0.16629244, 'lr': 0, 'params': 581405, 'time_iter': 0.0492, 'accuracy': 0.96937, 'precision': 0.52632, 'recall': 0.30769, 'f1': 0.38835, 'auc': 0.7914}\n> Epoch 53: took 127.9s (avg 128.1s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 54, 'time_epoch': 114.06472, 'eta': 5178.59436, 'eta_hours': 1.4385, 'loss': 0.05724821, 'lr': 4.752e-05, 'params': 581405, 'time_iter': 0.11085, 'accuracy': 0.98073, 'precision': 0.82359, 'recall': 0.61769, 'f1': 0.70594, 'auc': 0.98016}\nval: {'epoch': 54, 'time_epoch': 6.35867, 'loss': 0.10087581, 'lr': 0, 'params': 581405, 'time_iter': 0.04929, 'accuracy': 0.98006, 'precision': 0.4918, 'recall': 0.37037, 'f1': 0.42254, 'auc': 0.8178}\ntest: {'epoch': 54, 'time_epoch': 6.32914, 'loss': 0.17088365, 'lr': 0, 'params': 581405, 'time_iter': 0.04906, 'accuracy': 0.96596, 'precision': 0.44186, 'recall': 0.29231, 'f1': 0.35185, 'auc': 0.80105}\n> Epoch 54: took 126.9s (avg 128.1s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 55, 'time_epoch': 113.98668, 'eta': 5062.65555, 'eta_hours': 1.40629, 'loss': 0.05577872, 'lr': 4.587e-05, 'params': 581405, 'time_iter': 0.11077, 'accuracy': 0.98113, 'precision': 0.83535, 'recall': 0.61769, 'f1': 0.71022, 'auc': 0.98093}\nval: {'epoch': 55, 'time_epoch': 6.32926, 'loss': 0.09944552, 'lr': 0, 'params': 581405, 'time_iter': 0.04906, 'accuracy': 0.9786, 'precision': 0.44615, 'recall': 0.35802, 'f1': 0.39726, 'auc': 0.83504}\ntest: {'epoch': 55, 'time_epoch': 6.29743, 'loss': 0.17649575, 'lr': 0, 'params': 581405, 'time_iter': 0.04882, 'accuracy': 0.96693, 'precision': 0.4625, 'recall': 0.28462, 'f1': 0.35238, 'auc': 0.80664}\n> Epoch 55: took 126.8s (avg 128.0s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 56, 'time_epoch': 114.04891, 'eta': 4946.83218, 'eta_hours': 1.37412, 'loss': 0.05424898, 'lr': 4.423e-05, 'params': 581405, 'time_iter': 0.11083, 'accuracy': 0.9814, 'precision': 0.82495, 'recall': 0.6388, 'f1': 0.72004, 'auc': 0.98201}\nval: {'epoch': 56, 'time_epoch': 6.3726, 'loss': 0.10761905, 'lr': 0, 'params': 581405, 'time_iter': 0.0494, 'accuracy': 0.97885, 'precision': 0.45312, 'recall': 0.35802, 'f1': 0.4, 'auc': 0.81272}\ntest: {'epoch': 56, 'time_epoch': 6.35098, 'loss': 0.17940797, 'lr': 0, 'params': 581405, 'time_iter': 0.04923, 'accuracy': 0.9662, 'precision': 0.44828, 'recall': 0.3, 'f1': 0.35945, 'auc': 0.78763}\n> Epoch 56: took 126.9s (avg 128.0s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 57, 'time_epoch': 114.41287, 'eta': 4831.33355, 'eta_hours': 1.34204, 'loss': 0.0543465, 'lr': 4.259e-05, 'params': 581405, 'time_iter': 0.11119, 'accuracy': 0.98189, 'precision': 0.83403, 'recall': 0.64448, 'f1': 0.72711, 'auc': 0.98281}\nval: {'epoch': 57, 'time_epoch': 6.3813, 'loss': 0.10635048, 'lr': 0, 'params': 581405, 'time_iter': 0.04947, 'accuracy': 0.97812, 'precision': 0.43478, 'recall': 0.37037, 'f1': 0.4, 'auc': 0.82059}\ntest: {'epoch': 57, 'time_epoch': 6.36574, 'loss': 0.19251994, 'lr': 0, 'params': 581405, 'time_iter': 0.04935, 'accuracy': 0.96693, 'precision': 0.4625, 'recall': 0.28462, 'f1': 0.35238, 'auc': 0.7791}\n> Epoch 57: took 127.3s (avg 128.0s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 58, 'time_epoch': 115.52102, 'eta': 4716.6418, 'eta_hours': 1.31018, 'loss': 0.05499411, 'lr': 4.096e-05, 'params': 581405, 'time_iter': 0.11227, 'accuracy': 0.98122, 'precision': 0.82521, 'recall': 0.63231, 'f1': 0.71599, 'auc': 0.98329}\nval: {'epoch': 58, 'time_epoch': 6.35905, 'loss': 0.10652346, 'lr': 0, 'params': 581405, 'time_iter': 0.04929, 'accuracy': 0.97982, 'precision': 0.48387, 'recall': 0.37037, 'f1': 0.41958, 'auc': 0.81534}\ntest: {'epoch': 58, 'time_epoch': 6.2973, 'loss': 0.18720658, 'lr': 0, 'params': 581405, 'time_iter': 0.04882, 'accuracy': 0.9645, 'precision': 0.41489, 'recall': 0.3, 'f1': 0.34821, 'auc': 0.79322}\n> Epoch 58: took 128.3s (avg 128.0s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 59, 'time_epoch': 114.00732, 'eta': 4600.91328, 'eta_hours': 1.27803, 'loss': 0.05242293, 'lr': 3.934e-05, 'params': 581405, 'time_iter': 0.11079, 'accuracy': 0.98219, 'precision': 0.8323, 'recall': 0.65666, 'f1': 0.73412, 'auc': 0.98427}\nval: {'epoch': 59, 'time_epoch': 6.39107, 'loss': 0.10945743, 'lr': 0, 'params': 581405, 'time_iter': 0.04954, 'accuracy': 0.98055, 'precision': 0.50909, 'recall': 0.34568, 'f1': 0.41176, 'auc': 0.80745}\ntest: {'epoch': 59, 'time_epoch': 6.36215, 'loss': 0.19136974, 'lr': 0, 'params': 581405, 'time_iter': 0.04932, 'accuracy': 0.96693, 'precision': 0.45833, 'recall': 0.25385, 'f1': 0.32673, 'auc': 0.78669}\n> Epoch 59: took 126.9s (avg 128.0s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 60, 'time_epoch': 113.65194, 'eta': 4485.01397, 'eta_hours': 1.24584, 'loss': 0.05281731, 'lr': 3.773e-05, 'params': 581405, 'time_iter': 0.11045, 'accuracy': 0.98201, 'precision': 0.8272, 'recall': 0.65666, 'f1': 0.73213, 'auc': 0.98387}\nval: {'epoch': 60, 'time_epoch': 6.35045, 'loss': 0.10796873, 'lr': 0, 'params': 581405, 'time_iter': 0.04923, 'accuracy': 0.97909, 'precision': 0.46154, 'recall': 0.37037, 'f1': 0.41096, 'auc': 0.82504}\ntest: {'epoch': 60, 'time_epoch': 6.31551, 'loss': 0.18983359, 'lr': 0, 'params': 581405, 'time_iter': 0.04896, 'accuracy': 0.96693, 'precision': 0.46739, 'recall': 0.33077, 'f1': 0.38739, 'auc': 0.80451}\n> Epoch 60: took 126.5s (avg 128.0s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 61, 'time_epoch': 113.87427, 'eta': 4369.32343, 'eta_hours': 1.2137, 'loss': 0.05159136, 'lr': 3.613e-05, 'params': 581405, 'time_iter': 0.11066, 'accuracy': 0.98268, 'precision': 0.83502, 'recall': 0.66964, 'f1': 0.74324, 'auc': 0.98518}\nval: {'epoch': 61, 'time_epoch': 6.37824, 'loss': 0.1112758, 'lr': 0, 'params': 581405, 'time_iter': 0.04944, 'accuracy': 0.97836, 'precision': 0.4375, 'recall': 0.34568, 'f1': 0.38621, 'auc': 0.80632}\ntest: {'epoch': 61, 'time_epoch': 6.33478, 'loss': 0.19765652, 'lr': 0, 'params': 581405, 'time_iter': 0.04911, 'accuracy': 0.96523, 'precision': 0.41975, 'recall': 0.26154, 'f1': 0.32227, 'auc': 0.78672}\n> Epoch 61: took 126.7s (avg 128.0s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 62, 'time_epoch': 113.90244, 'eta': 4253.70709, 'eta_hours': 1.18159, 'loss': 0.05169633, 'lr': 3.455e-05, 'params': 581405, 'time_iter': 0.11069, 'accuracy': 0.98261, 'precision': 0.83537, 'recall': 0.66721, 'f1': 0.74188, 'auc': 0.98407}\nval: {'epoch': 62, 'time_epoch': 6.33254, 'loss': 0.11307109, 'lr': 0, 'params': 581405, 'time_iter': 0.04909, 'accuracy': 0.97788, 'precision': 0.43056, 'recall': 0.38272, 'f1': 0.40523, 'auc': 0.80475}\ntest: {'epoch': 62, 'time_epoch': 6.30664, 'loss': 0.18617673, 'lr': 0, 'params': 581405, 'time_iter': 0.04889, 'accuracy': 0.96304, 'precision': 0.40351, 'recall': 0.35385, 'f1': 0.37705, 'auc': 0.79008}\n> Epoch 62: took 126.7s (avg 127.9s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 63, 'time_epoch': 113.77657, 'eta': 4138.07351, 'eta_hours': 1.14946, 'loss': 0.04986907, 'lr': 3.299e-05, 'params': 581405, 'time_iter': 0.11057, 'accuracy': 0.98277, 'precision': 0.83484, 'recall': 0.67289, 'f1': 0.74517, 'auc': 0.98599}\nval: {'epoch': 63, 'time_epoch': 6.30762, 'loss': 0.11642679, 'lr': 0, 'params': 581405, 'time_iter': 0.0489, 'accuracy': 0.97739, 'precision': 0.41892, 'recall': 0.38272, 'f1': 0.4, 'auc': 0.81584}\ntest: {'epoch': 63, 'time_epoch': 6.33657, 'loss': 0.20221949, 'lr': 0, 'params': 581405, 'time_iter': 0.04912, 'accuracy': 0.96159, 'precision': 0.3871, 'recall': 0.36923, 'f1': 0.37795, 'auc': 0.7915}\n> Epoch 63: took 126.6s (avg 127.9s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 64, 'time_epoch': 113.59466, 'eta': 4022.39912, 'eta_hours': 1.11733, 'loss': 0.04982246, 'lr': 3.144e-05, 'params': 581405, 'time_iter': 0.11039, 'accuracy': 0.9831, 'precision': 0.84073, 'recall': 0.67695, 'f1': 0.75, 'auc': 0.98571}\nval: {'epoch': 64, 'time_epoch': 6.34947, 'loss': 0.11266246, 'lr': 0, 'params': 581405, 'time_iter': 0.04922, 'accuracy': 0.97909, 'precision': 0.46269, 'recall': 0.38272, 'f1': 0.41892, 'auc': 0.8176}\ntest: {'epoch': 64, 'time_epoch': 6.21691, 'loss': 0.19475975, 'lr': 0, 'params': 581405, 'time_iter': 0.04819, 'accuracy': 0.96426, 'precision': 0.40659, 'recall': 0.28462, 'f1': 0.33484, 'auc': 0.79363}\n> Epoch 64: took 126.3s (avg 127.9s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 65, 'time_epoch': 113.8271, 'eta': 3906.90749, 'eta_hours': 1.08525, 'loss': 0.05011445, 'lr': 2.992e-05, 'params': 581405, 'time_iter': 0.11062, 'accuracy': 0.98325, 'precision': 0.84995, 'recall': 0.67127, 'f1': 0.75011, 'auc': 0.98621}\nval: {'epoch': 65, 'time_epoch': 6.32422, 'loss': 0.11607926, 'lr': 0, 'params': 581405, 'time_iter': 0.04902, 'accuracy': 0.97569, 'precision': 0.37975, 'recall': 0.37037, 'f1': 0.375, 'auc': 0.81301}\ntest: {'epoch': 65, 'time_epoch': 6.33742, 'loss': 0.20158375, 'lr': 0, 'params': 581405, 'time_iter': 0.04913, 'accuracy': 0.96159, 'precision': 0.36275, 'recall': 0.28462, 'f1': 0.31897, 'auc': 0.77827}\n> Epoch 65: took 126.6s (avg 127.9s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 66, 'time_epoch': 117.33522, 'eta': 3793.19343, 'eta_hours': 1.05366, 'loss': 0.04771656, 'lr': 2.841e-05, 'params': 581405, 'time_iter': 0.11403, 'accuracy': 0.98313, 'precision': 0.83482, 'recall': 0.68506, 'f1': 0.75256, 'auc': 0.98828}\nval: {'epoch': 66, 'time_epoch': 6.34004, 'loss': 0.11006059, 'lr': 0, 'params': 581405, 'time_iter': 0.04915, 'accuracy': 0.97788, 'precision': 0.42647, 'recall': 0.35802, 'f1': 0.38926, 'auc': 0.81796}\ntest: {'epoch': 66, 'time_epoch': 6.35825, 'loss': 0.18878185, 'lr': 0, 'params': 581405, 'time_iter': 0.04929, 'accuracy': 0.96329, 'precision': 0.38462, 'recall': 0.26923, 'f1': 0.31674, 'auc': 0.79652}\n> Epoch 66: took 130.2s (avg 127.9s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 67, 'time_epoch': 114.07503, 'eta': 3677.83865, 'eta_hours': 1.02162, 'loss': 0.04855267, 'lr': 2.693e-05, 'params': 581405, 'time_iter': 0.11086, 'accuracy': 0.98301, 'precision': 0.83819, 'recall': 0.67695, 'f1': 0.74899, 'auc': 0.98708}\nval: {'epoch': 67, 'time_epoch': 6.35587, 'loss': 0.11551557, 'lr': 0, 'params': 581405, 'time_iter': 0.04927, 'accuracy': 0.97909, 'precision': 0.45902, 'recall': 0.34568, 'f1': 0.39437, 'auc': 0.81054}\ntest: {'epoch': 67, 'time_epoch': 6.30984, 'loss': 0.20356093, 'lr': 0, 'params': 581405, 'time_iter': 0.04891, 'accuracy': 0.96377, 'precision': 0.40404, 'recall': 0.30769, 'f1': 0.34934, 'auc': 0.79045}\n> Epoch 67: took 126.9s (avg 127.9s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 68, 'time_epoch': 113.8031, 'eta': 3562.3988, 'eta_hours': 0.98956, 'loss': 0.04523277, 'lr': 2.548e-05, 'params': 581405, 'time_iter': 0.1106, 'accuracy': 0.98407, 'precision': 0.84236, 'recall': 0.70698, 'f1': 0.76876, 'auc': 0.98911}\nval: {'epoch': 68, 'time_epoch': 6.30345, 'loss': 0.11646878, 'lr': 0, 'params': 581405, 'time_iter': 0.04886, 'accuracy': 0.97812, 'precision': 0.43284, 'recall': 0.35802, 'f1': 0.39189, 'auc': 0.82045}\ntest: {'epoch': 68, 'time_epoch': 6.31362, 'loss': 0.20157544, 'lr': 0, 'params': 581405, 'time_iter': 0.04894, 'accuracy': 0.96596, 'precision': 0.43902, 'recall': 0.27692, 'f1': 0.33962, 'auc': 0.78403}\n> Epoch 68: took 126.6s (avg 127.9s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 69, 'time_epoch': 113.68926, 'eta': 3446.95692, 'eta_hours': 0.95749, 'loss': 0.04905821, 'lr': 2.405e-05, 'params': 581405, 'time_iter': 0.11049, 'accuracy': 0.98435, 'precision': 0.8546, 'recall': 0.7013, 'f1': 0.7704, 'auc': 0.9862}\nval: {'epoch': 69, 'time_epoch': 6.2744, 'loss': 0.12229141, 'lr': 0, 'params': 581405, 'time_iter': 0.04864, 'accuracy': 0.9769, 'precision': 0.40278, 'recall': 0.35802, 'f1': 0.37908, 'auc': 0.79826}\ntest: {'epoch': 69, 'time_epoch': 6.32806, 'loss': 0.20569112, 'lr': 0, 'params': 581405, 'time_iter': 0.04905, 'accuracy': 0.96426, 'precision': 0.38667, 'recall': 0.22308, 'f1': 0.28293, 'auc': 0.77728}\n> Epoch 69: took 126.4s (avg 127.8s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 70, 'time_epoch': 114.08196, 'eta': 3331.72482, 'eta_hours': 0.92548, 'loss': 0.04614436, 'lr': 2.265e-05, 'params': 581405, 'time_iter': 0.11087, 'accuracy': 0.98441, 'precision': 0.84869, 'recall': 0.71023, 'f1': 0.77331, 'auc': 0.9887}\nval: {'epoch': 70, 'time_epoch': 6.33902, 'loss': 0.12029214, 'lr': 0, 'params': 581405, 'time_iter': 0.04914, 'accuracy': 0.97812, 'precision': 0.43284, 'recall': 0.35802, 'f1': 0.39189, 'auc': 0.80785}\ntest: {'epoch': 70, 'time_epoch': 6.33394, 'loss': 0.20748384, 'lr': 0, 'params': 581405, 'time_iter': 0.0491, 'accuracy': 0.96329, 'precision': 0.37037, 'recall': 0.23077, 'f1': 0.28436, 'auc': 0.77704}\n> Epoch 70: took 126.9s (avg 127.8s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 71, 'time_epoch': 113.7602, 'eta': 3216.39953, 'eta_hours': 0.89344, 'loss': 0.04558662, 'lr': 2.128e-05, 'params': 581405, 'time_iter': 0.11055, 'accuracy': 0.98395, 'precision': 0.84375, 'recall': 0.7013, 'f1': 0.76596, 'auc': 0.98866}\nval: {'epoch': 71, 'time_epoch': 6.33959, 'loss': 0.11678543, 'lr': 0, 'params': 581405, 'time_iter': 0.04914, 'accuracy': 0.97933, 'precision': 0.46774, 'recall': 0.35802, 'f1': 0.40559, 'auc': 0.8188}\ntest: {'epoch': 71, 'time_epoch': 6.25166, 'loss': 0.20596493, 'lr': 0, 'params': 581405, 'time_iter': 0.04846, 'accuracy': 0.9645, 'precision': 0.40244, 'recall': 0.25385, 'f1': 0.31132, 'auc': 0.79023}\n> Epoch 71: took 126.5s (avg 127.8s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 72, 'time_epoch': 113.8935, 'eta': 3101.16643, 'eta_hours': 0.86144, 'loss': 0.04350696, 'lr': 1.995e-05, 'params': 581405, 'time_iter': 0.11068, 'accuracy': 0.98465, 'precision': 0.85189, 'recall': 0.71429, 'f1': 0.77704, 'auc': 0.98983}\nval: {'epoch': 72, 'time_epoch': 6.30964, 'loss': 0.12087335, 'lr': 0, 'params': 581405, 'time_iter': 0.04891, 'accuracy': 0.97982, 'precision': 0.48333, 'recall': 0.35802, 'f1': 0.41135, 'auc': 0.80978}\ntest: {'epoch': 72, 'time_epoch': 6.35486, 'loss': 0.2169095, 'lr': 0, 'params': 581405, 'time_iter': 0.04926, 'accuracy': 0.96377, 'precision': 0.38824, 'recall': 0.25385, 'f1': 0.30698, 'auc': 0.78302}\n> Epoch 72: took 126.7s (avg 127.8s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 73, 'time_epoch': 114.04707, 'eta': 2986.02348, 'eta_hours': 0.82945, 'loss': 0.04454306, 'lr': 1.864e-05, 'params': 581405, 'time_iter': 0.11083, 'accuracy': 0.98468, 'precision': 0.85, 'recall': 0.71753, 'f1': 0.77817, 'auc': 0.98989}\nval: {'epoch': 73, 'time_epoch': 6.35669, 'loss': 0.11424821, 'lr': 0, 'params': 581405, 'time_iter': 0.04928, 'accuracy': 0.97982, 'precision': 0.48485, 'recall': 0.39506, 'f1': 0.43537, 'auc': 0.81708}\ntest: {'epoch': 73, 'time_epoch': 6.35837, 'loss': 0.20782484, 'lr': 0, 'params': 581405, 'time_iter': 0.04929, 'accuracy': 0.9645, 'precision': 0.40244, 'recall': 0.25385, 'f1': 0.31132, 'auc': 0.78473}\n> Epoch 73: took 126.9s (avg 127.8s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 74, 'time_epoch': 114.73903, 'eta': 2871.14042, 'eta_hours': 0.79754, 'loss': 0.04283367, 'lr': 1.737e-05, 'params': 581405, 'time_iter': 0.11151, 'accuracy': 0.98495, 'precision': 0.84995, 'recall': 0.72646, 'f1': 0.78337, 'auc': 0.99068}\nval: {'epoch': 74, 'time_epoch': 6.36052, 'loss': 0.11741298, 'lr': 0, 'params': 581405, 'time_iter': 0.04931, 'accuracy': 0.9786, 'precision': 0.44776, 'recall': 0.37037, 'f1': 0.40541, 'auc': 0.81173}\ntest: {'epoch': 74, 'time_epoch': 6.32287, 'loss': 0.20651388, 'lr': 0, 'params': 581405, 'time_iter': 0.04901, 'accuracy': 0.96256, 'precision': 0.375, 'recall': 0.27692, 'f1': 0.31858, 'auc': 0.77939}\n> Epoch 74: took 127.6s (avg 127.8s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 75, 'time_epoch': 114.63472, 'eta': 2756.2282, 'eta_hours': 0.76562, 'loss': 0.04474076, 'lr': 1.614e-05, 'params': 581405, 'time_iter': 0.1114, 'accuracy': 0.98447, 'precision': 0.84697, 'recall': 0.71429, 'f1': 0.77499, 'auc': 0.9893}\nval: {'epoch': 75, 'time_epoch': 6.38303, 'loss': 0.1126291, 'lr': 0, 'params': 581405, 'time_iter': 0.04948, 'accuracy': 0.97909, 'precision': 0.46032, 'recall': 0.35802, 'f1': 0.40278, 'auc': 0.81692}\ntest: {'epoch': 75, 'time_epoch': 6.3293, 'loss': 0.20252915, 'lr': 0, 'params': 581405, 'time_iter': 0.04906, 'accuracy': 0.96499, 'precision': 0.42222, 'recall': 0.29231, 'f1': 0.34545, 'auc': 0.79042}\n> Epoch 75: took 127.5s (avg 127.8s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 76, 'time_epoch': 114.43016, 'eta': 2641.26209, 'eta_hours': 0.73368, 'loss': 0.04452377, 'lr': 1.494e-05, 'params': 581405, 'time_iter': 0.11121, 'accuracy': 0.98447, 'precision': 0.84697, 'recall': 0.71429, 'f1': 0.77499, 'auc': 0.99021}\nval: {'epoch': 76, 'time_epoch': 6.34945, 'loss': 0.11477739, 'lr': 0, 'params': 581405, 'time_iter': 0.04922, 'accuracy': 0.97909, 'precision': 0.46032, 'recall': 0.35802, 'f1': 0.40278, 'auc': 0.81911}\ntest: {'epoch': 76, 'time_epoch': 6.37653, 'loss': 0.21232826, 'lr': 0, 'params': 581405, 'time_iter': 0.04943, 'accuracy': 0.96402, 'precision': 0.40625, 'recall': 0.3, 'f1': 0.34513, 'auc': 0.78303}\n> Epoch 76: took 127.3s (avg 127.8s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 77, 'time_epoch': 113.99363, 'eta': 2526.1866, 'eta_hours': 0.70172, 'loss': 0.04517444, 'lr': 1.378e-05, 'params': 581405, 'time_iter': 0.11078, 'accuracy': 0.98401, 'precision': 0.84008, 'recall': 0.70779, 'f1': 0.76828, 'auc': 0.99016}\nval: {'epoch': 77, 'time_epoch': 6.34825, 'loss': 0.11541385, 'lr': 0, 'params': 581405, 'time_iter': 0.04921, 'accuracy': 0.97958, 'precision': 0.47619, 'recall': 0.37037, 'f1': 0.41667, 'auc': 0.81416}\ntest: {'epoch': 77, 'time_epoch': 6.31341, 'loss': 0.20934802, 'lr': 0, 'params': 581405, 'time_iter': 0.04894, 'accuracy': 0.96256, 'precision': 0.38462, 'recall': 0.30769, 'f1': 0.34188, 'auc': 0.78269}\n> Epoch 77: took 126.8s (avg 127.8s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 78, 'time_epoch': 114.43523, 'eta': 2411.25588, 'eta_hours': 0.66979, 'loss': 0.04374744, 'lr': 1.266e-05, 'params': 581405, 'time_iter': 0.11121, 'accuracy': 0.98483, 'precision': 0.85072, 'recall': 0.72159, 'f1': 0.78085, 'auc': 0.9904}\nval: {'epoch': 78, 'time_epoch': 6.29546, 'loss': 0.11864492, 'lr': 0, 'params': 581405, 'time_iter': 0.0488, 'accuracy': 0.97885, 'precision': 0.45455, 'recall': 0.37037, 'f1': 0.40816, 'auc': 0.81143}\ntest: {'epoch': 78, 'time_epoch': 6.27694, 'loss': 0.21305443, 'lr': 0, 'params': 581405, 'time_iter': 0.04866, 'accuracy': 0.96475, 'precision': 0.41379, 'recall': 0.27692, 'f1': 0.3318, 'auc': 0.78064}\n> Epoch 78: took 127.2s (avg 127.8s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 79, 'time_epoch': 114.0062, 'eta': 2296.2303, 'eta_hours': 0.63784, 'loss': 0.04446485, 'lr': 1.158e-05, 'params': 581405, 'time_iter': 0.11079, 'accuracy': 0.98486, 'precision': 0.84171, 'recall': 0.73377, 'f1': 0.78404, 'auc': 0.98975}\nval: {'epoch': 79, 'time_epoch': 6.35761, 'loss': 0.11796664, 'lr': 0, 'params': 581405, 'time_iter': 0.04928, 'accuracy': 0.97958, 'precision': 0.47619, 'recall': 0.37037, 'f1': 0.41667, 'auc': 0.81644}\ntest: {'epoch': 79, 'time_epoch': 6.39891, 'loss': 0.2111037, 'lr': 0, 'params': 581405, 'time_iter': 0.0496, 'accuracy': 0.96402, 'precision': 0.39286, 'recall': 0.25385, 'f1': 0.30841, 'auc': 0.78128}\n> Epoch 79: took 126.9s (avg 127.7s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 80, 'time_epoch': 114.29776, 'eta': 2181.29827, 'eta_hours': 0.60592, 'loss': 0.04193386, 'lr': 1.054e-05, 'params': 581405, 'time_iter': 0.11108, 'accuracy': 0.98529, 'precision': 0.874, 'recall': 0.70942, 'f1': 0.78315, 'auc': 0.991}\nval: {'epoch': 80, 'time_epoch': 6.30848, 'loss': 0.12146255, 'lr': 0, 'params': 581405, 'time_iter': 0.0489, 'accuracy': 0.98006, 'precision': 0.49153, 'recall': 0.35802, 'f1': 0.41429, 'auc': 0.80714}\ntest: {'epoch': 80, 'time_epoch': 6.31327, 'loss': 0.21358847, 'lr': 0, 'params': 581405, 'time_iter': 0.04894, 'accuracy': 0.96693, 'precision': 0.45946, 'recall': 0.26154, 'f1': 0.33333, 'auc': 0.78526}\n> Epoch 80: took 127.1s (avg 127.7s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 81, 'time_epoch': 113.73246, 'eta': 2066.25763, 'eta_hours': 0.57396, 'loss': 0.04025504, 'lr': 9.55e-06, 'params': 581405, 'time_iter': 0.11053, 'accuracy': 0.98559, 'precision': 0.86372, 'recall': 0.73052, 'f1': 0.79156, 'auc': 0.99241}\nval: {'epoch': 81, 'time_epoch': 6.32177, 'loss': 0.12716078, 'lr': 0, 'params': 581405, 'time_iter': 0.04901, 'accuracy': 0.9769, 'precision': 0.40278, 'recall': 0.35802, 'f1': 0.37908, 'auc': 0.81078}\ntest: {'epoch': 81, 'time_epoch': 6.28342, 'loss': 0.21846633, 'lr': 0, 'params': 581405, 'time_iter': 0.04871, 'accuracy': 0.96207, 'precision': 0.36735, 'recall': 0.27692, 'f1': 0.31579, 'auc': 0.78193}\n> Epoch 81: took 126.5s (avg 127.7s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 82, 'time_epoch': 113.92067, 'eta': 1951.28705, 'eta_hours': 0.54202, 'loss': 0.04122479, 'lr': 8.6e-06, 'params': 581405, 'time_iter': 0.11071, 'accuracy': 0.98599, 'precision': 0.87032, 'recall': 0.73539, 'f1': 0.79718, 'auc': 0.99096}\nval: {'epoch': 82, 'time_epoch': 6.32332, 'loss': 0.12195259, 'lr': 0, 'params': 581405, 'time_iter': 0.04902, 'accuracy': 0.97836, 'precision': 0.43939, 'recall': 0.35802, 'f1': 0.39456, 'auc': 0.81935}\ntest: {'epoch': 82, 'time_epoch': 6.29041, 'loss': 0.2148943, 'lr': 0, 'params': 581405, 'time_iter': 0.04876, 'accuracy': 0.96353, 'precision': 0.38636, 'recall': 0.26154, 'f1': 0.31193, 'auc': 0.78243}\n> Epoch 82: took 126.7s (avg 127.7s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 83, 'time_epoch': 113.87234, 'eta': 1836.33227, 'eta_hours': 0.51009, 'loss': 0.04159438, 'lr': 7.7e-06, 'params': 581405, 'time_iter': 0.11066, 'accuracy': 0.98608, 'precision': 0.86509, 'recall': 0.74432, 'f1': 0.80017, 'auc': 0.99048}\nval: {'epoch': 83, 'time_epoch': 6.33421, 'loss': 0.12546169, 'lr': 0, 'params': 581405, 'time_iter': 0.0491, 'accuracy': 0.97836, 'precision': 0.43939, 'recall': 0.35802, 'f1': 0.39456, 'auc': 0.81817}\ntest: {'epoch': 83, 'time_epoch': 6.33999, 'loss': 0.22665517, 'lr': 0, 'params': 581405, 'time_iter': 0.04915, 'accuracy': 0.96402, 'precision': 0.3875, 'recall': 0.23846, 'f1': 0.29524, 'auc': 0.77952}\n> Epoch 83: took 126.7s (avg 127.7s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 84, 'time_epoch': 113.39506, 'eta': 1721.31873, 'eta_hours': 0.47814, 'loss': 0.04029552, 'lr': 6.84e-06, 'params': 581405, 'time_iter': 0.1102, 'accuracy': 0.98599, 'precision': 0.86749, 'recall': 0.73864, 'f1': 0.7979, 'auc': 0.99208}\nval: {'epoch': 84, 'time_epoch': 6.34995, 'loss': 0.12020785, 'lr': 0, 'params': 581405, 'time_iter': 0.04922, 'accuracy': 0.97617, 'precision': 0.38667, 'recall': 0.35802, 'f1': 0.37179, 'auc': 0.81887}\ntest: {'epoch': 84, 'time_epoch': 6.28749, 'loss': 0.21684065, 'lr': 0, 'params': 581405, 'time_iter': 0.04874, 'accuracy': 0.95867, 'precision': 0.33333, 'recall': 0.30769, 'f1': 0.32, 'auc': 0.78141}\n> Epoch 84: took 126.2s (avg 127.7s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 85, 'time_epoch': 113.91315, 'eta': 1606.42717, 'eta_hours': 0.44623, 'loss': 0.03942649, 'lr': 6.03e-06, 'params': 581405, 'time_iter': 0.1107, 'accuracy': 0.98614, 'precision': 0.86882, 'recall': 0.74188, 'f1': 0.80035, 'auc': 0.99246}\nval: {'epoch': 85, 'time_epoch': 6.2659, 'loss': 0.11969067, 'lr': 0, 'params': 581405, 'time_iter': 0.04857, 'accuracy': 0.97958, 'precision': 0.47541, 'recall': 0.35802, 'f1': 0.40845, 'auc': 0.81564}\ntest: {'epoch': 85, 'time_epoch': 6.27088, 'loss': 0.21562185, 'lr': 0, 'params': 581405, 'time_iter': 0.04861, 'accuracy': 0.96523, 'precision': 0.41772, 'recall': 0.25385, 'f1': 0.31579, 'auc': 0.78345}\n> Epoch 85: took 126.6s (avg 127.7s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 86, 'time_epoch': 113.21454, 'eta': 1491.45372, 'eta_hours': 0.41429, 'loss': 0.03878615, 'lr': 5.26e-06, 'params': 581405, 'time_iter': 0.11002, 'accuracy': 0.98611, 'precision': 0.8687, 'recall': 0.74107, 'f1': 0.79982, 'auc': 0.99248}\nval: {'epoch': 86, 'time_epoch': 6.35851, 'loss': 0.12170828, 'lr': 0, 'params': 581405, 'time_iter': 0.04929, 'accuracy': 0.9786, 'precision': 0.44615, 'recall': 0.35802, 'f1': 0.39726, 'auc': 0.81604}\ntest: {'epoch': 86, 'time_epoch': 6.33055, 'loss': 0.21769949, 'lr': 0, 'params': 581405, 'time_iter': 0.04907, 'accuracy': 0.96329, 'precision': 0.37931, 'recall': 0.25385, 'f1': 0.30415, 'auc': 0.78415}\n> Epoch 86: took 126.1s (avg 127.6s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 87, 'time_epoch': 114.16812, 'eta': 1376.65027, 'eta_hours': 0.3824, 'loss': 0.03897541, 'lr': 4.55e-06, 'params': 581405, 'time_iter': 0.11095, 'accuracy': 0.9869, 'precision': 0.87819, 'recall': 0.75487, 'f1': 0.81187, 'auc': 0.99212}\nval: {'epoch': 87, 'time_epoch': 6.33205, 'loss': 0.12289728, 'lr': 0, 'params': 581405, 'time_iter': 0.04909, 'accuracy': 0.97933, 'precision': 0.46774, 'recall': 0.35802, 'f1': 0.40559, 'auc': 0.8154}\ntest: {'epoch': 87, 'time_epoch': 6.30415, 'loss': 0.22193204, 'lr': 0, 'params': 581405, 'time_iter': 0.04887, 'accuracy': 0.96377, 'precision': 0.38824, 'recall': 0.25385, 'f1': 0.30698, 'auc': 0.783}\n> Epoch 87: took 127.0s (avg 127.6s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 88, 'time_epoch': 113.99604, 'eta': 1261.83983, 'eta_hours': 0.35051, 'loss': 0.04150362, 'lr': 3.89e-06, 'params': 581405, 'time_iter': 0.11078, 'accuracy': 0.98556, 'precision': 0.85014, 'recall': 0.74594, 'f1': 0.79464, 'auc': 0.991}\nval: {'epoch': 88, 'time_epoch': 6.33957, 'loss': 0.12096413, 'lr': 0, 'params': 581405, 'time_iter': 0.04914, 'accuracy': 0.97909, 'precision': 0.46032, 'recall': 0.35802, 'f1': 0.40278, 'auc': 0.81733}\ntest: {'epoch': 88, 'time_epoch': 6.33252, 'loss': 0.21924841, 'lr': 0, 'params': 581405, 'time_iter': 0.04909, 'accuracy': 0.96329, 'precision': 0.37931, 'recall': 0.25385, 'f1': 0.30415, 'auc': 0.78303}\n> Epoch 88: took 126.8s (avg 127.6s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 89, 'time_epoch': 113.95028, 'eta': 1147.0424, 'eta_hours': 0.31862, 'loss': 0.04164522, 'lr': 3.27e-06, 'params': 581405, 'time_iter': 0.11074, 'accuracy': 0.98532, 'precision': 0.8543, 'recall': 0.73295, 'f1': 0.78899, 'auc': 0.9924}\nval: {'epoch': 89, 'time_epoch': 6.37019, 'loss': 0.12887738, 'lr': 0, 'params': 581405, 'time_iter': 0.04938, 'accuracy': 0.97958, 'precision': 0.47541, 'recall': 0.35802, 'f1': 0.40845, 'auc': 0.81768}\ntest: {'epoch': 89, 'time_epoch': 6.27462, 'loss': 0.23036362, 'lr': 0, 'params': 581405, 'time_iter': 0.04864, 'accuracy': 0.96499, 'precision': 0.41026, 'recall': 0.24615, 'f1': 0.30769, 'auc': 0.78573}\n> Epoch 89: took 126.8s (avg 127.6s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 90, 'time_epoch': 114.03007, 'eta': 1032.27148, 'eta_hours': 0.28674, 'loss': 0.03906272, 'lr': 2.71e-06, 'params': 581405, 'time_iter': 0.11082, 'accuracy': 0.98723, 'precision': 0.89341, 'recall': 0.74838, 'f1': 0.81449, 'auc': 0.99153}\nval: {'epoch': 90, 'time_epoch': 6.33444, 'loss': 0.12251255, 'lr': 0, 'params': 581405, 'time_iter': 0.0491, 'accuracy': 0.9786, 'precision': 0.44615, 'recall': 0.35802, 'f1': 0.39726, 'auc': 0.82321}\ntest: {'epoch': 90, 'time_epoch': 6.27762, 'loss': 0.223455, 'lr': 0, 'params': 581405, 'time_iter': 0.04866, 'accuracy': 0.96402, 'precision': 0.39535, 'recall': 0.26154, 'f1': 0.31481, 'auc': 0.78461}\n> Epoch 90: took 126.8s (avg 127.6s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 91, 'time_epoch': 114.62128, 'eta': 917.56808, 'eta_hours': 0.25488, 'loss': 0.03993632, 'lr': 2.2e-06, 'params': 581405, 'time_iter': 0.11139, 'accuracy': 0.98605, 'precision': 0.86088, 'recall': 0.74838, 'f1': 0.80069, 'auc': 0.99198}\nval: {'epoch': 91, 'time_epoch': 6.40986, 'loss': 0.12661127, 'lr': 0, 'params': 581405, 'time_iter': 0.04969, 'accuracy': 0.97982, 'precision': 0.48485, 'recall': 0.39506, 'f1': 0.43537, 'auc': 0.80983}\ntest: {'epoch': 91, 'time_epoch': 6.30556, 'loss': 0.22421306, 'lr': 0, 'params': 581405, 'time_iter': 0.04888, 'accuracy': 0.96548, 'precision': 0.42105, 'recall': 0.24615, 'f1': 0.31068, 'auc': 0.78249}\n> Epoch 91: took 127.5s (avg 127.6s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 92, 'time_epoch': 114.10462, 'eta': 802.82756, 'eta_hours': 0.22301, 'loss': 0.0377358, 'lr': 1.74e-06, 'params': 581405, 'time_iter': 0.11089, 'accuracy': 0.98666, 'precision': 0.8737, 'recall': 0.75244, 'f1': 0.80855, 'auc': 0.99297}\nval: {'epoch': 92, 'time_epoch': 6.36482, 'loss': 0.12041516, 'lr': 0, 'params': 581405, 'time_iter': 0.04934, 'accuracy': 0.97958, 'precision': 0.47619, 'recall': 0.37037, 'f1': 0.41667, 'auc': 0.8199}\ntest: {'epoch': 92, 'time_epoch': 6.35766, 'loss': 0.21908281, 'lr': 0, 'params': 581405, 'time_iter': 0.04928, 'accuracy': 0.9645, 'precision': 0.39744, 'recall': 0.23846, 'f1': 0.29808, 'auc': 0.78437}\n> Epoch 92: took 127.0s (avg 127.6s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 93, 'time_epoch': 114.54384, 'eta': 688.1286, 'eta_hours': 0.19115, 'loss': 0.03865145, 'lr': 1.33e-06, 'params': 581405, 'time_iter': 0.11132, 'accuracy': 0.98641, 'precision': 0.87345, 'recall': 0.74513, 'f1': 0.8042, 'auc': 0.99191}\nval: {'epoch': 93, 'time_epoch': 6.27048, 'loss': 0.1228501, 'lr': 0, 'params': 581405, 'time_iter': 0.04861, 'accuracy': 0.98079, 'precision': 0.51786, 'recall': 0.35802, 'f1': 0.42336, 'auc': 0.82323}\ntest: {'epoch': 93, 'time_epoch': 6.35511, 'loss': 0.22027279, 'lr': 0, 'params': 581405, 'time_iter': 0.04926, 'accuracy': 0.96693, 'precision': 0.45714, 'recall': 0.24615, 'f1': 0.32, 'auc': 0.78835}\n> Epoch 93: took 127.3s (avg 127.6s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 94, 'time_epoch': 114.2345, 'eta': 573.41663, 'eta_hours': 0.15928, 'loss': 0.03865368, 'lr': 9.8e-07, 'params': 581405, 'time_iter': 0.11102, 'accuracy': 0.98687, 'precision': 0.87951, 'recall': 0.75244, 'f1': 0.81102, 'auc': 0.99246}\nval: {'epoch': 94, 'time_epoch': 6.36889, 'loss': 0.12263467, 'lr': 0, 'params': 581405, 'time_iter': 0.04937, 'accuracy': 0.97763, 'precision': 0.42029, 'recall': 0.35802, 'f1': 0.38667, 'auc': 0.81948}\ntest: {'epoch': 94, 'time_epoch': 6.36944, 'loss': 0.22012161, 'lr': 0, 'params': 581405, 'time_iter': 0.04938, 'accuracy': 0.96231, 'precision': 0.37113, 'recall': 0.27692, 'f1': 0.31718, 'auc': 0.78224}\n> Epoch 94: took 127.1s (avg 127.6s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 95, 'time_epoch': 114.25086, 'eta': 458.71528, 'eta_hours': 0.12742, 'loss': 0.03722235, 'lr': 6.8e-07, 'params': 581405, 'time_iter': 0.11103, 'accuracy': 0.98702, 'precision': 0.87442, 'recall': 0.76299, 'f1': 0.81491, 'auc': 0.99227}\nval: {'epoch': 95, 'time_epoch': 6.3295, 'loss': 0.12713224, 'lr': 0, 'params': 581405, 'time_iter': 0.04907, 'accuracy': 0.9786, 'precision': 0.44615, 'recall': 0.35802, 'f1': 0.39726, 'auc': 0.8168}\ntest: {'epoch': 95, 'time_epoch': 6.27443, 'loss': 0.22481691, 'lr': 0, 'params': 581405, 'time_iter': 0.04864, 'accuracy': 0.96475, 'precision': 0.41176, 'recall': 0.26923, 'f1': 0.32558, 'auc': 0.78554}\n> Epoch 95: took 127.0s (avg 127.6s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 96, 'time_epoch': 113.93184, 'eta': 344.01336, 'eta_hours': 0.09556, 'loss': 0.03713279, 'lr': 4.4e-07, 'params': 581405, 'time_iter': 0.11072, 'accuracy': 0.98711, 'precision': 0.87546, 'recall': 0.76461, 'f1': 0.81629, 'auc': 0.99333}\nval: {'epoch': 96, 'time_epoch': 6.3451, 'loss': 0.12899676, 'lr': 0, 'params': 581405, 'time_iter': 0.04919, 'accuracy': 0.97909, 'precision': 0.46032, 'recall': 0.35802, 'f1': 0.40278, 'auc': 0.80914}\ntest: {'epoch': 96, 'time_epoch': 6.38546, 'loss': 0.22984814, 'lr': 0, 'params': 581405, 'time_iter': 0.0495, 'accuracy': 0.96499, 'precision': 0.41026, 'recall': 0.24615, 'f1': 0.30769, 'auc': 0.77808}\n> Epoch 96: took 126.8s (avg 127.6s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 97, 'time_epoch': 113.94359, 'eta': 229.32739, 'eta_hours': 0.0637, 'loss': 0.03803435, 'lr': 2.5e-07, 'params': 581405, 'time_iter': 0.11073, 'accuracy': 0.98723, 'precision': 0.88374, 'recall': 0.75893, 'f1': 0.81659, 'auc': 0.99215}\nval: {'epoch': 97, 'time_epoch': 6.3398, 'loss': 0.12682554, 'lr': 0, 'params': 581405, 'time_iter': 0.04915, 'accuracy': 0.97788, 'precision': 0.42647, 'recall': 0.35802, 'f1': 0.38926, 'auc': 0.8184}\ntest: {'epoch': 97, 'time_epoch': 6.29752, 'loss': 0.22412684, 'lr': 0, 'params': 581405, 'time_iter': 0.04882, 'accuracy': 0.96353, 'precision': 0.38889, 'recall': 0.26923, 'f1': 0.31818, 'auc': 0.7878}\n> Epoch 97: took 126.7s (avg 127.6s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 98, 'time_epoch': 113.79731, 'eta': 114.65494, 'eta_hours': 0.03185, 'loss': 0.03988604, 'lr': 1.1e-07, 'params': 581405, 'time_iter': 0.11059, 'accuracy': 0.98608, 'precision': 0.86236, 'recall': 0.74756, 'f1': 0.80087, 'auc': 0.99263}\nval: {'epoch': 98, 'time_epoch': 6.35009, 'loss': 0.12411755, 'lr': 0, 'params': 581405, 'time_iter': 0.04923, 'accuracy': 0.97909, 'precision': 0.45902, 'recall': 0.34568, 'f1': 0.39437, 'auc': 0.81071}\ntest: {'epoch': 98, 'time_epoch': 6.33417, 'loss': 0.22436006, 'lr': 0, 'params': 581405, 'time_iter': 0.0491, 'accuracy': 0.96329, 'precision': 0.37931, 'recall': 0.25385, 'f1': 0.30415, 'auc': 0.77974}\n> Epoch 98: took 126.6s (avg 127.6s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\ntrain: {'epoch': 99, 'time_epoch': 114.93806, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.03675794, 'lr': 3e-08, 'params': 581405, 'time_iter': 0.1117, 'accuracy': 0.98766, 'precision': 0.88598, 'recall': 0.76948, 'f1': 0.82363, 'auc': 0.99329}\nval: {'epoch': 99, 'time_epoch': 6.32787, 'loss': 0.11975621, 'lr': 0, 'params': 581405, 'time_iter': 0.04905, 'accuracy': 0.97933, 'precision': 0.46875, 'recall': 0.37037, 'f1': 0.41379, 'auc': 0.8176}\ntest: {'epoch': 99, 'time_epoch': 6.29257, 'loss': 0.21726508, 'lr': 0, 'params': 581405, 'time_iter': 0.04878, 'accuracy': 0.96256, 'precision': 0.37234, 'recall': 0.26923, 'f1': 0.3125, 'auc': 0.78392}\n> Epoch 99: took 127.7s (avg 127.6s) | Best so far: epoch 11\ttrain_loss: 0.1122 train_auc: 0.8428\tval_loss: 0.0712 val_auc: 0.8384\ttest_loss: 0.1103 test_auc: 0.7867\nAvg time per epoch: 127.57s\nTotal train loop time: 3.54h\n\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n\u001b[34m\u001b[1mwandb\u001b[0m:       best/epoch ▁▃▃█████████████████████████████████████\n\u001b[34m\u001b[1mwandb\u001b[0m:    best/test_auc ▃▃▁▆▆███████████████████████████████████\n\u001b[34m\u001b[1mwandb\u001b[0m:   best/test_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n\u001b[34m\u001b[1mwandb\u001b[0m:   best/train_auc ▁▆▇█████████████████████████████████████\n\u001b[34m\u001b[1mwandb\u001b[0m:  best/train_loss ██▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n\u001b[34m\u001b[1mwandb\u001b[0m:     best/val_auc ▁▇██████████████████████████████████████\n\u001b[34m\u001b[1mwandb\u001b[0m:    best/val_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n\u001b[34m\u001b[1mwandb\u001b[0m:    test/accuracy ▁███████████████████████████████████████\n\u001b[34m\u001b[1mwandb\u001b[0m:         test/auc ▁▄▅▆▇█▇▇█▇█▇▇▇█▇█████▇▇▇█▇▇█▇▇▇▇▇▇▇▇▇▇▇▇\n\u001b[34m\u001b[1mwandb\u001b[0m:       test/epoch ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n\u001b[34m\u001b[1mwandb\u001b[0m:          test/f1 ▁▂▅▇▇▅▄▇███▆▆▇▇▇▇█▇█▇█▇▇▇▇█▆▇▆▆▆▇▆▆▆▆▆▆▆\n\u001b[34m\u001b[1mwandb\u001b[0m:        test/loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂\n\u001b[34m\u001b[1mwandb\u001b[0m:          test/lr ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n\u001b[34m\u001b[1mwandb\u001b[0m:      test/params ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n\u001b[34m\u001b[1mwandb\u001b[0m:   test/precision █▅▅▆▄▅▄▅▂▅▃▃▄▂▃▂▃▂▂▄▃▃▂▂▂▁▂▁▂▁▁▁▁▂▁▁▂▁▂▂\n\u001b[34m\u001b[1mwandb\u001b[0m:      test/recall █▁▁▁▂▃▃▂▃▃▃▃▃▃▃▂▃▂▃▃▃▃▃▃▃▃▃▃▂▃▃▃▃▃▂▃▃▃▃▃\n\u001b[34m\u001b[1mwandb\u001b[0m:  test/time_epoch ▆▅█▇▃▄▅▅▃▃▃▃▃▄▅▄▂▃▄▄▃▄▃▃▃▃▃▁▃▃▄▃▃▂▅▂▂▃▂▃\n\u001b[34m\u001b[1mwandb\u001b[0m:   test/time_iter █▂▅▂▂▂▃▁▂▂▂▂▁▂▁▁▂▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▂▂\n\u001b[34m\u001b[1mwandb\u001b[0m:   train/accuracy ▁▇▇▇▇███████████████████████████████████\n\u001b[34m\u001b[1mwandb\u001b[0m:        train/auc ▁▅▅▅▆▆▇▇▇▇▇▇▇▇▇█████████████████████████\n\u001b[34m\u001b[1mwandb\u001b[0m:      train/epoch ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇█\n\u001b[34m\u001b[1mwandb\u001b[0m:        train/eta ███▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁\n\u001b[34m\u001b[1mwandb\u001b[0m:  train/eta_hours ██▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁\n\u001b[34m\u001b[1mwandb\u001b[0m:         train/f1 ▁▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██████████\n\u001b[34m\u001b[1mwandb\u001b[0m:       train/loss ██▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁\n\u001b[34m\u001b[1mwandb\u001b[0m:         train/lr ▇███████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁\n\u001b[34m\u001b[1mwandb\u001b[0m:     train/params ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n\u001b[34m\u001b[1mwandb\u001b[0m:  train/precision ▁▁▂▂▂▃▃▃▄▄▅▅▅▅▅▅▅▆▆▆▆▅▆▆▆▇▇▇▇▇█▇██▇█████\n\u001b[34m\u001b[1mwandb\u001b[0m:     train/recall █▁▁▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆\n\u001b[34m\u001b[1mwandb\u001b[0m: train/time_epoch ▇███▄▄▄▅▄▅▄▅▅▄▄▃▄▂▅▃▄▅▃▃▃▃▂▃▂▃▄▄▃▃▁▃▄▃▃▂\n\u001b[34m\u001b[1mwandb\u001b[0m:  train/time_iter █▃▃▃▃▃▄▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▁▁▁▁▄▁▂▁▁▁▂▂▂▁▁\n\u001b[34m\u001b[1mwandb\u001b[0m:     val/accuracy ▁███████████████████████████████████████\n\u001b[34m\u001b[1mwandb\u001b[0m:          val/auc ▁▅▆▇█▇▇█▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇█▇\n\u001b[34m\u001b[1mwandb\u001b[0m:        val/epoch ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇████\n\u001b[34m\u001b[1mwandb\u001b[0m:           val/f1 ▁▃▄▅█▇▆▇█▇▇█▆█▇██▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇\n\u001b[34m\u001b[1mwandb\u001b[0m:         val/loss ▃▂▂▂▁▃▁▁▂▂▂▃▃▃▃▃▄▄▅▅▆▆▆▇▆▆▇▇▇▆▇▇▇▇▇█▇▇█▇\n\u001b[34m\u001b[1mwandb\u001b[0m:           val/lr ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n\u001b[34m\u001b[1mwandb\u001b[0m:       val/params ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n\u001b[34m\u001b[1mwandb\u001b[0m:    val/precision ▁█▆▅▅▅▅▄▆▄▅▄▄▅▅▄▄▄▄▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n\u001b[34m\u001b[1mwandb\u001b[0m:       val/recall █▁▁▂▃▃▃▃▃▃▃▃▃▃▃▄▃▃▃▃▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃\n\u001b[34m\u001b[1mwandb\u001b[0m:   val/time_epoch █▂▂▂▂▂▂▂▂▂▁▁▁▁▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁\n\u001b[34m\u001b[1mwandb\u001b[0m:    val/time_iter ▇▆▄▇▆█▇▄▄▄▃▅▄▃▃▄▄▃▅▅▄▂▃▂▃▃▃▂▁▃▂▃▃▃▁▂▂▃▃▃\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n\u001b[34m\u001b[1mwandb\u001b[0m:          best/epoch 11\n\u001b[34m\u001b[1mwandb\u001b[0m:       best/test_auc 0.78666\n\u001b[34m\u001b[1mwandb\u001b[0m:      best/test_loss 0.11027\n\u001b[34m\u001b[1mwandb\u001b[0m:      best/train_auc 0.84278\n\u001b[34m\u001b[1mwandb\u001b[0m:     best/train_loss 0.11218\n\u001b[34m\u001b[1mwandb\u001b[0m:        best/val_auc 0.8384\n\u001b[34m\u001b[1mwandb\u001b[0m:       best/val_loss 0.07119\n\u001b[34m\u001b[1mwandb\u001b[0m:      best_test_perf 0.78666\n\u001b[34m\u001b[1mwandb\u001b[0m:     best_train_perf 0.84278\n\u001b[34m\u001b[1mwandb\u001b[0m:       best_val_perf 0.8384\n\u001b[34m\u001b[1mwandb\u001b[0m: full_epoch_time_avg 127.56532\n\u001b[34m\u001b[1mwandb\u001b[0m: full_epoch_time_sum 12756.53188\n\u001b[34m\u001b[1mwandb\u001b[0m:       test/accuracy 0.96256\n\u001b[34m\u001b[1mwandb\u001b[0m:            test/auc 0.78392\n\u001b[34m\u001b[1mwandb\u001b[0m:          test/epoch 99\n\u001b[34m\u001b[1mwandb\u001b[0m:             test/f1 0.3125\n\u001b[34m\u001b[1mwandb\u001b[0m:           test/loss 0.21727\n\u001b[34m\u001b[1mwandb\u001b[0m:             test/lr 0\n\u001b[34m\u001b[1mwandb\u001b[0m:         test/params 581405\n\u001b[34m\u001b[1mwandb\u001b[0m:      test/precision 0.37234\n\u001b[34m\u001b[1mwandb\u001b[0m:         test/recall 0.26923\n\u001b[34m\u001b[1mwandb\u001b[0m:     test/time_epoch 6.29257\n\u001b[34m\u001b[1mwandb\u001b[0m:      test/time_iter 0.04878\n\u001b[34m\u001b[1mwandb\u001b[0m:      train/accuracy 0.98766\n\u001b[34m\u001b[1mwandb\u001b[0m:           train/auc 0.99329\n\u001b[34m\u001b[1mwandb\u001b[0m:         train/epoch 99\n\u001b[34m\u001b[1mwandb\u001b[0m:           train/eta 0\n\u001b[34m\u001b[1mwandb\u001b[0m:     train/eta_hours 0\n\u001b[34m\u001b[1mwandb\u001b[0m:            train/f1 0.82363\n\u001b[34m\u001b[1mwandb\u001b[0m:          train/loss 0.03676\n\u001b[34m\u001b[1mwandb\u001b[0m:            train/lr 0.0\n\u001b[34m\u001b[1mwandb\u001b[0m:        train/params 581405\n\u001b[34m\u001b[1mwandb\u001b[0m:     train/precision 0.88598\n\u001b[34m\u001b[1mwandb\u001b[0m:        train/recall 0.76948\n\u001b[34m\u001b[1mwandb\u001b[0m:    train/time_epoch 114.93806\n\u001b[34m\u001b[1mwandb\u001b[0m:     train/time_iter 0.1117\n\u001b[34m\u001b[1mwandb\u001b[0m:        val/accuracy 0.97933\n\u001b[34m\u001b[1mwandb\u001b[0m:             val/auc 0.8176\n\u001b[34m\u001b[1mwandb\u001b[0m:           val/epoch 99\n\u001b[34m\u001b[1mwandb\u001b[0m:              val/f1 0.41379\n\u001b[34m\u001b[1mwandb\u001b[0m:            val/loss 0.11976\n\u001b[34m\u001b[1mwandb\u001b[0m:              val/lr 0\n\u001b[34m\u001b[1mwandb\u001b[0m:          val/params 581405\n\u001b[34m\u001b[1mwandb\u001b[0m:       val/precision 0.46875\n\u001b[34m\u001b[1mwandb\u001b[0m:          val/recall 0.37037\n\u001b[34m\u001b[1mwandb\u001b[0m:      val/time_epoch 6.32787\n\u001b[34m\u001b[1mwandb\u001b[0m:       val/time_iter 0.04905\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33madd_dropout\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/omertalmi-tel-aviv-university/molhiv/runs/yxy7k6ky\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/omertalmi-tel-aviv-university/molhiv\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240930_145216-yxy7k6ky/logs\u001b[0m\nTask done, results saved in results/ogbg-molhiv-GPS/0\n11\n{'epoch': 11, 'time_epoch': 6.56413, 'loss': 0.11026811, 'lr': 0, 'params': 581405, 'time_iter': 0.05088, 'accuracy': 0.97204, 'precision': 0.62712, 'recall': 0.28462, 'f1': 0.39153, 'auc': 0.78666}\n{'epoch': 11, 'time_epoch': 6.42672, 'loss': 0.07119207, 'lr': 0, 'params': 581405, 'time_iter': 0.04982, 'accuracy': 0.98201, 'precision': 0.59459, 'recall': 0.2716, 'f1': 0.37288, 'auc': 0.8384}\n{'epoch': 11, 'time_epoch': 116.42603, 'eta': 10262.53892, 'eta_hours': 2.85071, 'loss': 0.11217665, 'lr': 9.902e-05, 'params': 581405, 'time_iter': 0.11314, 'accuracy': 0.96839, 'precision': 0.68824, 'recall': 0.2849, 'f1': 0.40299, 'auc': 0.84278}\nResults aggregated across runs saved in results/ogbg-molhiv-GPS/agg\n[*] All done: 2024-09-30 18:25:01.032384\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}