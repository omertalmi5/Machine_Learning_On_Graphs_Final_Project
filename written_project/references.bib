
@misc{gilmer2017neuralmessagepassingquantum,
      title={Neural Message Passing for Quantum Chemistry}, 
      author={Justin Gilmer and Samuel S. Schoenholz and Patrick F. Riley and Oriol Vinyals and George E. Dahl},
      year={2017},
      eprint={1704.01212},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1704.01212}, 
}

@misc{alon2021bottleneckgraphneuralnetworks,
      title={On the Bottleneck of Graph Neural Networks and its Practical Implications}, 
      author={Uri Alon and Eran Yahav},
      year={2021},
      eprint={2006.05205},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2006.05205}, 
}

@misc{oono2021graphneuralnetworksexponentially,
      title={Graph Neural Networks Exponentially Lose Expressive Power for Node Classification}, 
      author={Kenta Oono and Taiji Suzuki},
      year={2021},
      eprint={1905.10947},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1905.10947}, 
}

@misc{dwivedi2022benchmarkinggraphneuralnetworks,
      title={Benchmarking Graph Neural Networks}, 
      author={Vijay Prakash Dwivedi and Chaitanya K. Joshi and Anh Tuan Luu and Thomas Laurent and Yoshua Bengio and Xavier Bresson},
      year={2022},
      eprint={2003.00982},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2003.00982}, 
}

@misc{topping2022understandingoversquashingbottlenecksgraphs,
      title={Understanding over-squashing and bottlenecks on graphs via curvature}, 
      author={Jake Topping and Francesco Di Giovanni and Benjamin Paul Chamberlain and Xiaowen Dong and Michael M. Bronstein},
      year={2022},
      eprint={2111.14522},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/2111.14522}, 
}

@misc{xu2019powerfulgraphneuralnetworks,
      title={How Powerful are Graph Neural Networks?}, 
      author={Keyulu Xu and Weihua Hu and Jure Leskovec and Stefanie Jegelka},
      year={2019},
      eprint={1810.00826},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1810.00826}, 
}

@misc{morris2021weisfeilerlemanneuralhigherorder,
      title={Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks}, 
      author={Christopher Morris and Martin Ritzert and Matthias Fey and William L. Hamilton and Jan Eric Lenssen and Gaurav Rattan and Martin Grohe},
      year={2021},
      eprint={1810.02244},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1810.02244}, 
}

@misc{vaswani2023attentionneed,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1706.03762}, 
}

@article{Bronstein_2017,
   title={Geometric Deep Learning: Going beyond Euclidean data},
   volume={34},
   ISSN={1558-0792},
   url={http://dx.doi.org/10.1109/MSP.2017.2693418},
   DOI={10.1109/msp.2017.2693418},
   number={4},
   journal={IEEE Signal Processing Magazine},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Bronstein, Michael M. and Bruna, Joan and LeCun, Yann and Szlam, Arthur and Vandergheynst, Pierre},
   year={2017},
   month=jul, pages={18–42} 
}

@misc{ying2021transformersreallyperformbad,
      title={Do Transformers Really Perform Bad for Graph Representation?}, 
      author={Chengxuan Ying and Tianle Cai and Shengjie Luo and Shuxin Zheng and Guolin Ke and Di He and Yanming Shen and Tie-Yan Liu},
      year={2021},
      eprint={2106.05234},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2106.05234}, 
}

@misc{shi2023benchmarkinggraphormerlargescalemolecular,
      title={Benchmarking Graphormer on Large-Scale Molecular Modeling Datasets}, 
      author={Yu Shi and Shuxin Zheng and Guolin Ke and Yifei Shen and Jiacheng You and Jiyan He and Shengjie Luo and Chang Liu and Di He and Tie-Yan Liu},
      year={2023},
      eprint={2203.04810},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2203.04810}, 
}

@misc{kreuzer2021rethinkinggraphtransformersspectral,
      title={Rethinking Graph Transformers with Spectral Attention}, 
      author={Devin Kreuzer and Dominique Beaini and William L. Hamilton and Vincent Létourneau and Prudencio Tossou},
      year={2021},
      eprint={2106.03893},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2106.03893}, 
}

@misc{rampášek2023recipegeneralpowerfulscalable,
      title={Recipe for a General, Powerful, Scalable Graph Transformer}, 
      author={Ladislav Rampášek and Mikhail Galkin and Vijay Prakash Dwivedi and Anh Tuan Luu and Guy Wolf and Dominique Beaini},
      year={2023},
      eprint={2205.12454},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2205.12454}, 
}

@misc{hu2021opengraphbenchmarkdatasets,
      title={Open Graph Benchmark: Datasets for Machine Learning on Graphs}, 
      author={Weihua Hu and Matthias Fey and Marinka Zitnik and Yuxiao Dong and Hongyu Ren and Bowen Liu and Michele Catasta and Jure Leskovec},
      year={2021},
      eprint={2005.00687},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2005.00687}, 
}




